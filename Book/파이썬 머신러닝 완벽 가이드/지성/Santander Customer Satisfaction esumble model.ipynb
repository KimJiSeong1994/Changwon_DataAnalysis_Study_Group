{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\knuser\\Anaconda3\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "# ================================================== [ setting ] =======================================================\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold \n",
    "from xgboost import XGBClassifier\n",
    "import lightgbm as lgb \n",
    "from bayes_opt import BayesianOptimization\n",
    "from functools import partial \n",
    "\n",
    "import os \n",
    "os.chdir(\"C:/Users/knuser/Desktop/Santander Customer Satisfaction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================== [ preprocessing ] ====================================================\n",
    "def Preprocessing(file_path) : \n",
    "    df = pd.read_csv(file_path)\n",
    "    df[\"var3\"] = df[\"var3\"].replace(-999999, np.median(df[\"var3\"]))\n",
    "    df.drop(\"ID\", axis = 1, inplace = True)\n",
    "    \n",
    "    X_features = df.iloc[:, :-1]\n",
    "    y_labels = df.iloc[:, -1]\n",
    "    \n",
    "    return df, X_features, y_labels  \n",
    "\n",
    "train_df, X_features, y_labels = Preprocessing(\"train.csv\")\n",
    "test_df, _, _ = Preprocessing(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================= [ modeling ] =======================================================\n",
    "def lgb_cv(num_leaves, learning_rate, n_estimators, subsample, colsample_bytree, reg_alpha, reg_lambda, x_data = None, y_data = None, n_splits = 5, output = \"socre\") :\n",
    "    score = 0\n",
    "    kf = StratifiedKFold(n_splits = n_splits)\n",
    "    models = []\n",
    "    \n",
    "    for train_index, valid_index in kf.split(x_data, y_data) : \n",
    "        x_train, y_train = x_data.iloc[train_index], y_data[train_index]\n",
    "        x_valid, y_valid = x_data.iloc[valid_index], y_data[valid_index]\n",
    "        \n",
    "        model = lgb.LGBMClassifier(num_leaves = int(num_leaves), \n",
    "                                   learning_rate = learning_rate, \n",
    "                                   n_estimators = int(n_estimators), \n",
    "                                   subsample = np.clip(subsample, 0, 1), \n",
    "                                   colsample_bytree = np.clip(colsample_bytree, 0, 1), \n",
    "                                   reg_alpha = reg_alpha, \n",
    "                                   reg_lambda = reg_lambda,)\n",
    "        \n",
    "        model.fit(x_train, y_train)\n",
    "        models.append(model)\n",
    "    \n",
    "        pred = model.predict_proba(x_valid)[:, 1]    \n",
    "        true = y_valid\n",
    "        score += roc_auc_score(true, pred) / n_splits\n",
    "        \n",
    "    if output == \"score\" :\n",
    "        return score\n",
    "    if output == \"model\" :\n",
    "        return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | colsam... | learni... | n_esti... | num_le... | reg_alpha | reg_la... | subsample |\n",
      "-------------------------------------------------------------------------------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m 0.8187  \u001b[0m | \u001b[0m 0.6128  \u001b[0m | \u001b[0m 0.09316 \u001b[0m | \u001b[0m 1.001e+0\u001b[0m | \u001b[0m 436.0   \u001b[0m | \u001b[0m 3.19    \u001b[0m | \u001b[0m 22.89   \u001b[0m | \u001b[0m 0.5532  \u001b[0m |\n",
      "| \u001b[0m 2       \u001b[0m | \u001b[0m 0.8035  \u001b[0m | \u001b[0m 0.3464  \u001b[0m | \u001b[0m 0.01621 \u001b[0m | \u001b[0m 20.21   \u001b[0m | \u001b[0m 71.48   \u001b[0m | \u001b[0m 1.063   \u001b[0m | \u001b[0m 37.63   \u001b[0m | \u001b[0m 0.2233  \u001b[0m |\n",
      "| \u001b[95m 3       \u001b[0m | \u001b[95m 0.8332  \u001b[0m | \u001b[95m 0.09816 \u001b[0m | \u001b[95m 0.02952 \u001b[0m | \u001b[95m 492.0   \u001b[0m | \u001b[95m 128.9   \u001b[0m | \u001b[95m 8.813   \u001b[0m | \u001b[95m 7.464   \u001b[0m | \u001b[95m 0.5725  \u001b[0m |\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m 0.8219  \u001b[0m | \u001b[0m 0.02332 \u001b[0m | \u001b[0m 0.07836 \u001b[0m | \u001b[0m 498.4   \u001b[0m | \u001b[0m 833.4   \u001b[0m | \u001b[0m 0.4697  \u001b[0m | \u001b[0m 23.6    \u001b[0m | \u001b[0m 0.2591  \u001b[0m |\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m 0.8124  \u001b[0m | \u001b[0m 0.0683  \u001b[0m | \u001b[0m 0.09826 \u001b[0m | \u001b[0m 81.96   \u001b[0m | \u001b[0m 432.0   \u001b[0m | \u001b[0m 4.108   \u001b[0m | \u001b[0m 35.45   \u001b[0m | \u001b[0m 0.5594  \u001b[0m |\n",
      "| \u001b[95m 6       \u001b[0m | \u001b[95m 0.8366  \u001b[0m | \u001b[95m 0.7139  \u001b[0m | \u001b[95m 0.01559 \u001b[0m | \u001b[95m 495.9   \u001b[0m | \u001b[95m 123.3   \u001b[0m | \u001b[95m 2.686   \u001b[0m | \u001b[95m 9.645   \u001b[0m | \u001b[95m 0.2485  \u001b[0m |\n",
      "| \u001b[95m 7       \u001b[0m | \u001b[95m 0.8389  \u001b[0m | \u001b[95m 0.3051  \u001b[0m | \u001b[95m 0.00787 \u001b[0m | \u001b[95m 987.6   \u001b[0m | \u001b[95m 25.63   \u001b[0m | \u001b[95m 2.371   \u001b[0m | \u001b[95m 47.98   \u001b[0m | \u001b[95m 0.01353 \u001b[0m |\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m 0.7918  \u001b[0m | \u001b[0m 0.0518  \u001b[0m | \u001b[0m 0.02687 \u001b[0m | \u001b[0m 46.85   \u001b[0m | \u001b[0m 1.003e+0\u001b[0m | \u001b[0m 3.812   \u001b[0m | \u001b[0m 2.117   \u001b[0m | \u001b[0m 0.2946  \u001b[0m |\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m 0.8298  \u001b[0m | \u001b[0m 0.4521  \u001b[0m | \u001b[0m 0.07218 \u001b[0m | \u001b[0m 629.9   \u001b[0m | \u001b[0m 39.18   \u001b[0m | \u001b[0m 0.4466  \u001b[0m | \u001b[0m 48.87   \u001b[0m | \u001b[0m 0.1648  \u001b[0m |\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m 0.8181  \u001b[0m | \u001b[0m 0.7015  \u001b[0m | \u001b[0m 0.07445 \u001b[0m | \u001b[0m 879.7   \u001b[0m | \u001b[0m 18.43   \u001b[0m | \u001b[0m 0.482   \u001b[0m | \u001b[0m 0.6991  \u001b[0m | \u001b[0m 0.4433  \u001b[0m |\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m 0.8174  \u001b[0m | \u001b[0m 0.00988 \u001b[0m | \u001b[0m 0.09463 \u001b[0m | \u001b[0m 1.023e+0\u001b[0m | \u001b[0m 991.7   \u001b[0m | \u001b[0m 6.693   \u001b[0m | \u001b[0m 43.18   \u001b[0m | \u001b[0m 0.7544  \u001b[0m |\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m 0.8275  \u001b[0m | \u001b[0m 0.7124  \u001b[0m | \u001b[0m 0.06354 \u001b[0m | \u001b[0m 400.8   \u001b[0m | \u001b[0m 387.5   \u001b[0m | \u001b[0m 0.2062  \u001b[0m | \u001b[0m 49.97   \u001b[0m | \u001b[0m 0.7398  \u001b[0m |\n",
      "| \u001b[0m 13      \u001b[0m | \u001b[0m 0.8304  \u001b[0m | \u001b[0m 0.1989  \u001b[0m | \u001b[0m 0.09927 \u001b[0m | \u001b[0m 546.9   \u001b[0m | \u001b[0m 1.023e+0\u001b[0m | \u001b[0m 2.729   \u001b[0m | \u001b[0m 48.86   \u001b[0m | \u001b[0m 0.5149  \u001b[0m |\n",
      "| \u001b[0m 14      \u001b[0m | \u001b[0m 0.8387  \u001b[0m | \u001b[0m 0.936   \u001b[0m | \u001b[0m 0.02406 \u001b[0m | \u001b[0m 317.1   \u001b[0m | \u001b[0m 19.49   \u001b[0m | \u001b[0m 0.9662  \u001b[0m | \u001b[0m 48.29   \u001b[0m | \u001b[0m 0.2662  \u001b[0m |\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m 0.8388  \u001b[0m | \u001b[0m 0.459   \u001b[0m | \u001b[0m 0.0562  \u001b[0m | \u001b[0m 483.6   \u001b[0m | \u001b[0m 128.6   \u001b[0m | \u001b[0m 9.176   \u001b[0m | \u001b[0m 12.73   \u001b[0m | \u001b[0m 0.5172  \u001b[0m |\n",
      "| \u001b[0m 16      \u001b[0m | \u001b[0m 0.8154  \u001b[0m | \u001b[0m 0.5984  \u001b[0m | \u001b[0m 0.01769 \u001b[0m | \u001b[0m 631.2   \u001b[0m | \u001b[0m 1.023e+0\u001b[0m | \u001b[0m 1.18    \u001b[0m | \u001b[0m 0.7823  \u001b[0m | \u001b[0m 0.793   \u001b[0m |\n",
      "| \u001b[0m 17      \u001b[0m | \u001b[0m 0.8075  \u001b[0m | \u001b[0m 0.7357  \u001b[0m | \u001b[0m 0.07621 \u001b[0m | \u001b[0m 1.015e+0\u001b[0m | \u001b[0m 200.9   \u001b[0m | \u001b[0m 0.4126  \u001b[0m | \u001b[0m 47.01   \u001b[0m | \u001b[0m 0.136   \u001b[0m |\n",
      "| \u001b[0m 18      \u001b[0m | \u001b[0m 0.8287  \u001b[0m | \u001b[0m 0.5368  \u001b[0m | \u001b[0m 0.05465 \u001b[0m | \u001b[0m 858.2   \u001b[0m | \u001b[0m 756.7   \u001b[0m | \u001b[0m 4.083   \u001b[0m | \u001b[0m 48.59   \u001b[0m | \u001b[0m 0.07046 \u001b[0m |\n",
      "| \u001b[0m 19      \u001b[0m | \u001b[0m 0.8047  \u001b[0m | \u001b[0m 0.2855  \u001b[0m | \u001b[0m 0.0896  \u001b[0m | \u001b[0m 1.022e+0\u001b[0m | \u001b[0m 729.7   \u001b[0m | \u001b[0m 0.4122  \u001b[0m | \u001b[0m 30.81   \u001b[0m | \u001b[0m 0.795   \u001b[0m |\n",
      "| \u001b[0m 20      \u001b[0m | \u001b[0m 0.8383  \u001b[0m | \u001b[0m 0.4657  \u001b[0m | \u001b[0m 0.02836 \u001b[0m | \u001b[0m 730.1   \u001b[0m | \u001b[0m 491.8   \u001b[0m | \u001b[0m 7.522   \u001b[0m | \u001b[0m 49.13   \u001b[0m | \u001b[0m 0.05596 \u001b[0m |\n",
      "| \u001b[0m 21      \u001b[0m | \u001b[0m 0.7869  \u001b[0m | \u001b[0m 0.1014  \u001b[0m | \u001b[0m 0.01934 \u001b[0m | \u001b[0m 31.92   \u001b[0m | \u001b[0m 779.9   \u001b[0m | \u001b[0m 4.777   \u001b[0m | \u001b[0m 46.68   \u001b[0m | \u001b[0m 0.3129  \u001b[0m |\n",
      "| \u001b[0m 22      \u001b[0m | \u001b[0m 0.8275  \u001b[0m | \u001b[0m 0.3335  \u001b[0m | \u001b[0m 0.007936\u001b[0m | \u001b[0m 297.2   \u001b[0m | \u001b[0m 174.0   \u001b[0m | \u001b[0m 3.035   \u001b[0m | \u001b[0m 49.7    \u001b[0m | \u001b[0m 0.2943  \u001b[0m |\n",
      "| \u001b[0m 23      \u001b[0m | \u001b[0m 0.8339  \u001b[0m | \u001b[0m 0.326   \u001b[0m | \u001b[0m 0.09411 \u001b[0m | \u001b[0m 410.0   \u001b[0m | \u001b[0m 21.71   \u001b[0m | \u001b[0m 5.39    \u001b[0m | \u001b[0m 1.856   \u001b[0m | \u001b[0m 0.377   \u001b[0m |\n",
      "| \u001b[0m 24      \u001b[0m | \u001b[0m 0.8369  \u001b[0m | \u001b[0m 0.8815  \u001b[0m | \u001b[0m 0.09334 \u001b[0m | \u001b[0m 287.0   \u001b[0m | \u001b[0m 1.017e+0\u001b[0m | \u001b[0m 9.401   \u001b[0m | \u001b[0m 47.73   \u001b[0m | \u001b[0m 0.7327  \u001b[0m |\n",
      "| \u001b[0m 25      \u001b[0m | \u001b[0m 0.8381  \u001b[0m | \u001b[0m 0.5886  \u001b[0m | \u001b[0m 0.02316 \u001b[0m | \u001b[0m 1.012e+0\u001b[0m | \u001b[0m 28.07   \u001b[0m | \u001b[0m 7.694   \u001b[0m | \u001b[0m 9.628   \u001b[0m | \u001b[0m 0.587   \u001b[0m |\n",
      "| \u001b[0m 26      \u001b[0m | \u001b[0m 0.8385  \u001b[0m | \u001b[0m 0.2565  \u001b[0m | \u001b[0m 0.04803 \u001b[0m | \u001b[0m 450.0   \u001b[0m | \u001b[0m 43.31   \u001b[0m | \u001b[0m 4.788   \u001b[0m | \u001b[0m 48.85   \u001b[0m | \u001b[0m 0.7214  \u001b[0m |\n",
      "| \u001b[0m 27      \u001b[0m | \u001b[0m 0.8389  \u001b[0m | \u001b[0m 0.4679  \u001b[0m | \u001b[0m 0.006673\u001b[0m | \u001b[0m 691.4   \u001b[0m | \u001b[0m 585.9   \u001b[0m | \u001b[0m 9.604   \u001b[0m | \u001b[0m 4.159   \u001b[0m | \u001b[0m 0.8888  \u001b[0m |\n",
      "| \u001b[0m 28      \u001b[0m | \u001b[0m 0.8359  \u001b[0m | \u001b[0m 0.9657  \u001b[0m | \u001b[0m 0.07747 \u001b[0m | \u001b[0m 660.5   \u001b[0m | \u001b[0m 675.3   \u001b[0m | \u001b[0m 8.931   \u001b[0m | \u001b[0m 45.7    \u001b[0m | \u001b[0m 0.06581 \u001b[0m |\n",
      "| \u001b[95m 29      \u001b[0m | \u001b[95m 0.8391  \u001b[0m | \u001b[95m 0.539   \u001b[0m | \u001b[95m 0.007357\u001b[0m | \u001b[95m 607.6   \u001b[0m | \u001b[95m 363.7   \u001b[0m | \u001b[95m 9.69    \u001b[0m | \u001b[95m 3.605   \u001b[0m | \u001b[95m 0.1435  \u001b[0m |\n",
      "| \u001b[0m 30      \u001b[0m | \u001b[0m 0.8311  \u001b[0m | \u001b[0m 0.9686  \u001b[0m | \u001b[0m 0.09135 \u001b[0m | \u001b[0m 488.2   \u001b[0m | \u001b[0m 123.7   \u001b[0m | \u001b[0m 6.124   \u001b[0m | \u001b[0m 8.329   \u001b[0m | \u001b[0m 0.9033  \u001b[0m |\n",
      "| \u001b[0m 31      \u001b[0m | \u001b[0m 0.792   \u001b[0m | \u001b[0m 0.07033 \u001b[0m | \u001b[0m 0.001694\u001b[0m | \u001b[0m 864.0   \u001b[0m | \u001b[0m 1.012e+0\u001b[0m | \u001b[0m 9.971   \u001b[0m | \u001b[0m 46.37   \u001b[0m | \u001b[0m 0.5433  \u001b[0m |\n",
      "| \u001b[0m 32      \u001b[0m | \u001b[0m 0.8375  \u001b[0m | \u001b[0m 0.3585  \u001b[0m | \u001b[0m 0.04656 \u001b[0m | \u001b[0m 403.3   \u001b[0m | \u001b[0m 1.018e+0\u001b[0m | \u001b[0m 7.642   \u001b[0m | \u001b[0m 4.065   \u001b[0m | \u001b[0m 0.03793 \u001b[0m |\n",
      "| \u001b[0m 33      \u001b[0m | \u001b[0m 0.8388  \u001b[0m | \u001b[0m 0.6858  \u001b[0m | \u001b[0m 0.01091 \u001b[0m | \u001b[0m 529.6   \u001b[0m | \u001b[0m 249.4   \u001b[0m | \u001b[0m 7.04    \u001b[0m | \u001b[0m 48.55   \u001b[0m | \u001b[0m 0.1136  \u001b[0m |\n",
      "| \u001b[0m 34      \u001b[0m | \u001b[0m 0.786   \u001b[0m | \u001b[0m 0.004698\u001b[0m | \u001b[0m 0.05958 \u001b[0m | \u001b[0m 281.9   \u001b[0m | \u001b[0m 1.019e+0\u001b[0m | \u001b[0m 6.231   \u001b[0m | \u001b[0m 46.19   \u001b[0m | \u001b[0m 0.8391  \u001b[0m |\n",
      "| \u001b[0m 35      \u001b[0m | \u001b[0m 0.817   \u001b[0m | \u001b[0m 0.03261 \u001b[0m | \u001b[0m 0.07781 \u001b[0m | \u001b[0m 311.8   \u001b[0m | \u001b[0m 674.2   \u001b[0m | \u001b[0m 9.983   \u001b[0m | \u001b[0m 48.78   \u001b[0m | \u001b[0m 0.2826  \u001b[0m |\n",
      "=============================================================================================================\n"
     ]
    }
   ],
   "source": [
    "func_fixed = partial(lgb_cv, x_data = X_features, y_data = y_labels, n_splits = 5, output = 'score') \n",
    "\n",
    "lgbBO = BayesianOptimization(\n",
    "    func_fixed, \n",
    "    {'num_leaves': (16, 1024),\n",
    "     'learning_rate': (0.0001, 0.1),\n",
    "     'n_estimators': (16, 1024),\n",
    "     'subsample': (0, 1),\n",
    "     'colsample_bytree': (0, 1),\n",
    "     'reg_alpha': (0, 10),\n",
    "     'reg_lambda': (0, 50),}, \n",
    "    random_state = 2109\n",
    ")\n",
    "\n",
    "lgbBO.maximize(init_points = 5, n_iter = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = lgbBO.max['params']\n",
    "models = lgb_cv(\n",
    "    params['num_leaves'], \n",
    "    params['learning_rate'], \n",
    "    params['n_estimators'], \n",
    "    params['subsample'], \n",
    "    params['colsample_bytree'], \n",
    "    params['reg_alpha'], \n",
    "    params['reg_lambda'], \n",
    "    x_data = X_features, y_data = y_labels, n_splits = 5, output = 'model') # ROC-AUC : 0.839"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = []\n",
    "for model in models :\n",
    "    pred = model.predict_proba(test_df)[:, 1]\n",
    "    preds.append(pred)\n",
    "    \n",
    "pred = np.mean(preds, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================= [ modeling (2) ] ===================================================\n",
    "def xgb_cv(max_leaves, eta, n_estimators, subsample, colsample_bytree, reg_alpha, reg_lambda, x_data = None, y_data = None, n_splits = 5, output = \"socre\") :\n",
    "    score = 0\n",
    "    kf = StratifiedKFold(n_splits = n_splits)\n",
    "    models = []\n",
    "    \n",
    "    for train_index, valid_index in kf.split(x_data, y_data) : \n",
    "        x_train, y_train = x_data.iloc[train_index], y_data[train_index]\n",
    "        x_valid, y_valid = x_data.iloc[valid_index], y_data[valid_index]\n",
    "        \n",
    "        model = XGBClassifier(max_leaves = int(max_leaves),\n",
    "                              eta = eta,\n",
    "                              n_estimators = int(n_estimators),\n",
    "                              subsample = np.clip(subsample, 0, 1),\n",
    "                              colsample_bytree = np.clip(colsample_bytree, 0, 1),\n",
    "                              reg_alpha = reg_alpha,\n",
    "                              reg_lambda = reg_lambda, )\n",
    "        \n",
    "        model.fit(x_train, y_train)\n",
    "        models.append(model)\n",
    "    \n",
    "        pred = model.predict_proba(x_valid)[:, 1]    \n",
    "        true = y_valid\n",
    "        score += roc_auc_score(true, pred) / n_splits\n",
    "        \n",
    "    if output == \"score\" :\n",
    "        return score\n",
    "    if output == \"model\" :\n",
    "        return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | colsam... |    eta    | max_le... | n_esti... | reg_alpha | reg_la... | subsample |\n",
      "-------------------------------------------------------------------------------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m 0.8388  \u001b[0m | \u001b[0m 0.6128  \u001b[0m | \u001b[0m 0.09316 \u001b[0m | \u001b[0m 1.001e+0\u001b[0m | \u001b[0m 436.0   \u001b[0m | \u001b[0m 3.19    \u001b[0m | \u001b[0m 22.89   \u001b[0m | \u001b[0m 0.5532  \u001b[0m |\n",
      "| \u001b[0m 2       \u001b[0m | \u001b[0m 0.8298  \u001b[0m | \u001b[0m 0.3464  \u001b[0m | \u001b[0m 0.01621 \u001b[0m | \u001b[0m 20.21   \u001b[0m | \u001b[0m 71.48   \u001b[0m | \u001b[0m 1.063   \u001b[0m | \u001b[0m 37.63   \u001b[0m | \u001b[0m 0.2233  \u001b[0m |\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m 0.8267  \u001b[0m | \u001b[0m 0.09816 \u001b[0m | \u001b[0m 0.02952 \u001b[0m | \u001b[0m 492.0   \u001b[0m | \u001b[0m 128.9   \u001b[0m | \u001b[0m 8.813   \u001b[0m | \u001b[0m 7.464   \u001b[0m | \u001b[0m 0.5725  \u001b[0m |\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m 0.8222  \u001b[0m | \u001b[0m 0.02332 \u001b[0m | \u001b[0m 0.07836 \u001b[0m | \u001b[0m 498.4   \u001b[0m | \u001b[0m 833.4   \u001b[0m | \u001b[0m 0.4697  \u001b[0m | \u001b[0m 23.6    \u001b[0m | \u001b[0m 0.2591  \u001b[0m |\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m 0.8355  \u001b[0m | \u001b[0m 0.0683  \u001b[0m | \u001b[0m 0.09826 \u001b[0m | \u001b[0m 81.96   \u001b[0m | \u001b[0m 432.0   \u001b[0m | \u001b[0m 4.108   \u001b[0m | \u001b[0m 35.45   \u001b[0m | \u001b[0m 0.5594  \u001b[0m |\n",
      "| \u001b[95m 6       \u001b[0m | \u001b[95m 0.8393  \u001b[0m | \u001b[95m 0.6629  \u001b[0m | \u001b[95m 0.02764 \u001b[0m | \u001b[95m 89.29   \u001b[0m | \u001b[95m 425.3   \u001b[0m | \u001b[95m 7.843   \u001b[0m | \u001b[95m 40.21   \u001b[0m | \u001b[95m 0.3008  \u001b[0m |\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m 0.8063  \u001b[0m | \u001b[0m 0.3534  \u001b[0m | \u001b[0m 0.02754 \u001b[0m | \u001b[0m 1.016e+0\u001b[0m | \u001b[0m 26.33   \u001b[0m | \u001b[0m 9.544   \u001b[0m | \u001b[0m 43.1    \u001b[0m | \u001b[0m 0.9474  \u001b[0m |\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m 0.8382  \u001b[0m | \u001b[0m 0.8941  \u001b[0m | \u001b[0m 0.04022 \u001b[0m | \u001b[0m 1e+03   \u001b[0m | \u001b[0m 1.002e+0\u001b[0m | \u001b[0m 6.417   \u001b[0m | \u001b[0m 45.36   \u001b[0m | \u001b[0m 0.1712  \u001b[0m |\n",
      "| \u001b[95m 9       \u001b[0m | \u001b[95m 0.8396  \u001b[0m | \u001b[95m 0.2191  \u001b[0m | \u001b[95m 0.08081 \u001b[0m | \u001b[95m 621.7   \u001b[0m | \u001b[95m 435.0   \u001b[0m | \u001b[95m 9.7     \u001b[0m | \u001b[95m 49.57   \u001b[0m | \u001b[95m 0.5266  \u001b[0m |\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m 0.8392  \u001b[0m | \u001b[0m 0.2502  \u001b[0m | \u001b[0m 0.0249  \u001b[0m | \u001b[0m 1.005e+0\u001b[0m | \u001b[0m 692.3   \u001b[0m | \u001b[0m 9.597   \u001b[0m | \u001b[0m 44.89   \u001b[0m | \u001b[0m 0.8333  \u001b[0m |\n"
     ]
    }
   ],
   "source": [
    "xgb_func_fixed = partial(xgb_cv, x_data = X_features, y_data = y_labels, n_splits = 5, output = 'score') \n",
    "\n",
    "xgbBO = BayesianOptimization(\n",
    "    xgb_func_fixed, \n",
    "    {'max_leaves': (16, 1024),\n",
    "     'eta': (0.0001, 0.1),\n",
    "     'n_estimators': (16, 1024),\n",
    "     'subsample': (0, 1),\n",
    "     'colsample_bytree': (0, 1),\n",
    "     'reg_alpha': (0, 10),\n",
    "     'reg_lambda': (0, 50),}, \n",
    "    random_state = 2109\n",
    ")\n",
    "\n",
    "xgbBO.maximize(init_points = 5, n_iter = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_2 = []\n",
    "for model in models :\n",
    "    pred = model.predict_proba(test_df)[:, 1]\n",
    "    preds.append(pred)\n",
    "    \n",
    "preds_2 = np.mean(preds, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_preds = preds * 0.7 + preds_2 * 0.3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.cortest(preds, preds_2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
