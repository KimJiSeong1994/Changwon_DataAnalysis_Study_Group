{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CHAPTER 08. 텍스트 분석\n",
    "## 05. 감성분석\n",
    "### 감성분석 소개\n",
    ": 문서의 주관적인 감성/의견/기분 등을 파악하기 위한 방법으로 소셜 미디어, 여론조사, 온라인 리뷰, 피드백 등 다양한 분야에서 활용되고 있다.\n",
    "- 문서 내 텍스트가 나타내는 여러가지 주관적인 단어와 문맥을 기반으로 감성 수치 계산하는 방법을 이용한다.\n",
    "- 감성 지수는 긍정 감성지수와 부정 감성 지수로 구성되며 이들 지수를 합산해 긍정 감성 또는 부정 감성을 결합한다.\n",
    "- 감성분석은 머신러닝 관점에서 지도학습과 비지도학습 방식으로 나눌 수 있다.\n",
    "\t- 지도학습 : 학습 데이터와 타깃 레이블 값을 기반으로 감성 분석 학습을 수행한 뒤 이를 기반으로 다른 데이터의 감성 분석을  예측하는 방법\n",
    "\t- 비지도학습 : ‘Lexicon’이라는 일종의 감성 어휘 사전을 이용한다. Lexicon은 감성 분석을 위한 용어와 문맥에 대한 다양한 정보를 가지고 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 지도학습 기반 감성 분석 실습 - IMDB 영화평\n",
    "지도학습 기반으로 영화평의 텍스트를 분석해 감성 분석 결과가 긍정 또는 부정인지 예측하는 모델 만들어보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"5814_8\"</td>\n",
       "      <td>1</td>\n",
       "      <td>\"With all this stuff going down at the moment ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"2381_9\"</td>\n",
       "      <td>1</td>\n",
       "      <td>\"\\\"The Classic War of the Worlds\\\" by Timothy ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"7759_3\"</td>\n",
       "      <td>0</td>\n",
       "      <td>\"The film starts with a manager (Nicholas Bell...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  sentiment                                             review\n",
       "0  \"5814_8\"          1  \"With all this stuff going down at the moment ...\n",
       "1  \"2381_9\"          1  \"\\\"The Classic War of the Worlds\\\" by Timothy ...\n",
       "2  \"7759_3\"          0  \"The film starts with a manager (Nicholas Bell..."
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "review_df = pd.read_csv('/Users/wizdom/Desktop/data_analysis/파이썬 머신러닝 완벽가이드/실습 데이터/word2vec-nlp-tutorial/labeledTrainData.tsv', header=0, sep=\"\\t\", quoting=3)\n",
    "review_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"With all this stuff going down at the moment with MJ i've started listening to his music, watching the odd documentary here and there, watched The Wiz and watched Moonwalker again. Maybe i just want to get a certain insight into this guy who i thought was really cool in the eighties just to maybe make up my mind whether he is guilty or innocent. Moonwalker is part biography, part feature film which i remember going to see at the cinema when it was originally released. Some of it has subtle messages about MJ's feeling towards the press and also the obvious message of drugs are bad m'kay.<br /><br />Visually impressive but of course this is all about Michael Jackson so unless you remotely like MJ in anyway then you are going to hate this and find it boring. Some may call MJ an egotist for consenting to the making of this movie BUT MJ and most of his fans would say that he made it for the fans which if true is really nice of him.<br /><br />The actual feature film bit when it finally starts is only on for 20 minutes or so excluding the Smooth Criminal sequence and Joe Pesci is convincing as a psychopathic all powerful drug lord. Why he wants MJ dead so bad is beyond me. Because MJ overheard his plans? Nah, Joe Pesci's character ranted that he wanted people to know it is he who is supplying drugs etc so i dunno, maybe he just hates MJ's music.<br /><br />Lots of cool things in this like MJ turning into a car and a robot and the whole Speed Demon sequence. Also, the director must have had the patience of a saint when it came to filming the kiddy Bad sequence as usually directors hate working with one kid let alone a whole bunch of them performing a complex dance scene.<br /><br />Bottom line, this movie is for people who like MJ on one level or another (which i think is most people). If not, then stay away. It does try and give off a wholesome message and ironically MJ's bestest buddy in this movie is a girl! Michael Jackson is truly one of the most talented people ever to grace this planet but is he guilty? Well, with all the attention i've gave this subject....hmmm well i don't know because people can be different behind closed doors, i know this for a fact. He is either an extremely nice but stupid guy or one of the most sickest liars. I hope he is not the latter.\"\n"
     ]
    }
   ],
   "source": [
    "# 텍스트 구성 확인하기\n",
    "\n",
    "print(review_df['review'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# <br> html 태그는 replace 함수로 공백으로 변환\n",
    "review_df['review'] = review_df['review'].str.replace('<br />',' ')\n",
    "\n",
    "# 파이썬의 정규 표현식 모듈인 re를 이용해 영어 문자열이 아닌 문자는 모두 공백으로 변환\n",
    "review_df['review'] = review_df['review'].apply(lambda x : re.sub(\"[^a-zA-Z]\", \" \", x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((17500, 1), (7500, 1))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 결정 값 데이터 세트 생성\n",
    "class_df = review_df['sentiment']\n",
    "# 피처 데이터 세트 생성\n",
    "feature_df = review_df.drop(['id', 'sentiment'], axis=1, inplace=False)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(feature_df, class_df, test_size=0.3, random_state=156)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측 정확도는 0.8860, ROC-AUC는 0.9503\n"
     ]
    }
   ],
   "source": [
    "# 감상평 텍스트를 피처 벡터화한 후에 ML 분류 알고리즘을 적용해 예측 성능 측정\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "\n",
    "# 스톱워드는 English, filtering, ngram은 (1, 2)로 설정해 CountVectorization 수행\n",
    "# LogisticRegression의 C는 10으로 설정\n",
    "pipeline = Pipeline([\n",
    "    ('cnt_vect', CountVectorizer(stop_words='english', ngram_range=(1, 2))),\n",
    "    ('lr_clf', LogisticRegression(C=10))])\n",
    "\n",
    "# Pipeline 객체를 이용해 fit(), predict()로 학습/예측 수행. predict_proba는 roc_auc때문에 수행\n",
    "pipeline.fit(X_train['review'], y_train)\n",
    "pred = pipeline.predict(X_test['review'])\n",
    "pred_probs = pipeline.predict_proba(X_test['review'])[:, 1]\n",
    "\n",
    "print('예측 정확도는 {0:.4f}, ROC-AUC는 {1:.4f}'.format(accuracy_score(y_test, pred),\n",
    "                                                roc_auc_score(y_test, pred_probs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측 정확도는 0.8936, ROC-AUC는 0.9598\n"
     ]
    }
   ],
   "source": [
    "# TF-IDF 벡터화를 적용해 다시 예측 성능 측정\n",
    "\n",
    "# 스톱워드는 English, filtering, ngram은 (1, 2)로 설정해 TF-IDF수행\n",
    "# LogisticRegression의 C는 10으로 설정\n",
    "pipeline = Pipeline([\n",
    "    ('tfidf_vect', TfidfVectorizer(stop_words='english', ngram_range=(1, 2))),\n",
    "    ('lr_clf', LogisticRegression(C=10))])\n",
    "\n",
    "# Pipeline 객체를 이용해 fit(), predict()로 학습/예측 수행. predict_proba는 roc_auc때문에 수행\n",
    "pipeline.fit(X_train['review'], y_train)\n",
    "pred = pipeline.predict(X_test['review'])\n",
    "pred_probs = pipeline.predict_proba(X_test['review'])[:, 1]\n",
    "\n",
    "print('예측 정확도는 {0:.4f}, ROC-AUC는 {1:.4f}'.format(accuracy_score(y_test, pred),\n",
    "                                                roc_auc_score(y_test, pred_probs)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TF-IDF 기반 피처 벡터화의 예측 성능이 조금 더 높다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 비지도학습 기반 감성 분석 소개\n",
    "- 많은 감성 분석용 데이터는 결정된 레이블 값을 가지고 있지 않다. 이러한 경우에 Lexicon은 유용하게 사용될 수 있다. \n",
    "- **Lexicon** : 일반적으로 어휘집을 의미하지만, 여기서는 주로 감성만을 분석하기 위해 지원하는 감성 어휘 사전이다.\n",
    "- **감성 사전**은 긍정 감성 또는 부정 감성의 정도를 의미하는 수치를 가지고 있으며 이를 감성 지수라고 한다.\n",
    "\t- **감성 지수**는 단어의 위치나 주변 단어, 문맥, POS(Part of Speech) 등을 참고해 결정된다.\n",
    "\t- 대표적인 패키지는 NLTK이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- NLP 패키지의 **WordNet** : 방대한 어휘 사전. 단순한 어휘사전이 아닌 시맨틱 분석을 제공하는 어휘 사전\n",
    "\t- 시맨틱(Semantic) : ‘문맥상 의미’\n",
    "\t- NLP 패키지는 시맨틱을 프로그램적으로 인터페이스할 수 있는 다양한 방법을 제공한다.\n",
    "    \n",
    "    \n",
    "- 이처럼 **WordNet**은 **다양한 상황에서 같은 어휘라도 다르게 사용되는 어휘의 시맨틱 정보를 제공한다.**이를 위해 각각의 품사로 구성된 개별 단어를 Synset이라는 개념을 이용해 표현한다.\n",
    "\t- **Synset(Sets of cognitive synonyms)** : 단순한 하나의 단어가 아니라 그 단어가 가지는 문맥, 시맨틱 정보를 제공하는 WordNet의 핵심 개념"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- NLTK 감성 사전의 **단점**\n",
    "\t- 예측 성능은 그리 좋지 못하다.\n",
    "\t- 그래서 실제 업무의 적용은 NLTK 패키지가 아닌 다른 감성 사전을 적용하는 것이 일반적이다.\n",
    "\n",
    "#### NLTK를 포함한 대표적인 감성 사전\n",
    "- **SentiwordNet**\n",
    "\t- NLTK 패키지의 WordNet과 유사하게 감성 단어 전용의 WordNet을 구현한 것. WordNet의 Synset개념을 감성 분석에 적용한 것이다.\n",
    "\t- WordNet의 Synset별로 3가지 감성 점수(긍정 감성 지수, 부정 지수, 객관성 지수)를 할당한다.\n",
    "\t- 문장별로 단어들의 긍정 감성 지수와 부정 감성 지수를 합산하여 최종 감성 지수를 계산하고 이에 기반해 감성이 긍정인지 부정인지 결정한다.\n",
    "\n",
    "\n",
    "- **VADER**\n",
    "\t- 주로 소셜 미디어의 텍스트에 대한 감성 분석을 제공하기 위한 패키지이다.\n",
    "\t- 뛰어난 감성 분석 결과를 제공하며, 비교적 빠른 수행 시간을 보장해 대용량 텍스트 데이터에 잘 사용되는 패키지이다. \n",
    "\n",
    "\n",
    "- **Pattern**\n",
    "\t- 예측 성능 측면에서 가장 주목받는 패키지"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SentiWordNet을 이용한 감성 분석\n",
    "#### WordNet Synset과 SentiWordNet SentiSynset 클래스의 이해\n",
    "SentiWordNet은 WordNet 기반의 synset을 이용하므로 먼저 synset에 대한 개념 이해 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading collection 'all'\n",
      "[nltk_data]    | \n",
      "[nltk_data]    | Downloading package abc to /Users/wizdom/nltk_data...\n",
      "[nltk_data]    |   Package abc is already up-to-date!\n",
      "[nltk_data]    | Downloading package alpino to\n",
      "[nltk_data]    |     /Users/wizdom/nltk_data...\n",
      "[nltk_data]    |   Package alpino is already up-to-date!\n",
      "[nltk_data]    | Downloading package biocreative_ppi to\n",
      "[nltk_data]    |     /Users/wizdom/nltk_data...\n",
      "[nltk_data]    |   Package biocreative_ppi is already up-to-date!\n",
      "[nltk_data]    | Downloading package brown to\n",
      "[nltk_data]    |     /Users/wizdom/nltk_data...\n",
      "[nltk_data]    |   Package brown is already up-to-date!\n",
      "[nltk_data]    | Downloading package brown_tei to\n",
      "[nltk_data]    |     /Users/wizdom/nltk_data...\n",
      "[nltk_data]    |   Package brown_tei is already up-to-date!\n",
      "[nltk_data]    | Downloading package cess_cat to\n",
      "[nltk_data]    |     /Users/wizdom/nltk_data...\n",
      "[nltk_data]    |   Package cess_cat is already up-to-date!\n",
      "[nltk_data]    | Downloading package cess_esp to\n",
      "[nltk_data]    |     /Users/wizdom/nltk_data...\n",
      "[nltk_data]    |   Package cess_esp is already up-to-date!\n",
      "[nltk_data]    | Downloading package chat80 to\n",
      "[nltk_data]    |     /Users/wizdom/nltk_data...\n",
      "[nltk_data]    |   Package chat80 is already up-to-date!\n",
      "[nltk_data]    | Downloading package city_database to\n",
      "[nltk_data]    |     /Users/wizdom/nltk_data...\n",
      "[nltk_data]    |   Package city_database is already up-to-date!\n",
      "[nltk_data]    | Downloading package cmudict to\n",
      "[nltk_data]    |     /Users/wizdom/nltk_data...\n",
      "[nltk_data]    |   Package cmudict is already up-to-date!\n",
      "[nltk_data]    | Downloading package comparative_sentences to\n",
      "[nltk_data]    |     /Users/wizdom/nltk_data...\n",
      "[nltk_data]    |   Package comparative_sentences is already up-to-\n",
      "[nltk_data]    |       date!\n",
      "[nltk_data]    | Downloading package comtrans to\n",
      "[nltk_data]    |     /Users/wizdom/nltk_data...\n",
      "[nltk_data]    |   Package comtrans is already up-to-date!\n",
      "[nltk_data]    | Downloading package conll2000 to\n",
      "[nltk_data]    |     /Users/wizdom/nltk_data...\n",
      "[nltk_data]    |   Package conll2000 is already up-to-date!\n",
      "[nltk_data]    | Downloading package conll2002 to\n",
      "[nltk_data]    |     /Users/wizdom/nltk_data...\n",
      "[nltk_data]    |   Package conll2002 is already up-to-date!\n",
      "[nltk_data]    | Downloading package conll2007 to\n",
      "[nltk_data]    |     /Users/wizdom/nltk_data...\n",
      "[nltk_data]    |   Package conll2007 is already up-to-date!\n",
      "[nltk_data]    | Downloading package crubadan to\n",
      "[nltk_data]    |     /Users/wizdom/nltk_data...\n",
      "[nltk_data]    |   Package crubadan is already up-to-date!\n",
      "[nltk_data]    | Downloading package dependency_treebank to\n",
      "[nltk_data]    |     /Users/wizdom/nltk_data...\n",
      "[nltk_data]    |   Package dependency_treebank is already up-to-date!\n",
      "[nltk_data]    | Downloading package dolch to\n",
      "[nltk_data]    |     /Users/wizdom/nltk_data...\n",
      "[nltk_data]    |   Package dolch is already up-to-date!\n",
      "[nltk_data]    | Downloading package europarl_raw to\n",
      "[nltk_data]    |     /Users/wizdom/nltk_data...\n",
      "[nltk_data]    |   Package europarl_raw is already up-to-date!\n",
      "[nltk_data]    | Downloading package floresta to\n",
      "[nltk_data]    |     /Users/wizdom/nltk_data...\n",
      "[nltk_data]    |   Package floresta is already up-to-date!\n",
      "[nltk_data]    | Downloading package framenet_v15 to\n",
      "[nltk_data]    |     /Users/wizdom/nltk_data...\n",
      "[nltk_data]    |   Package framenet_v15 is already up-to-date!\n",
      "[nltk_data]    | Downloading package framenet_v17 to\n",
      "[nltk_data]    |     /Users/wizdom/nltk_data...\n",
      "[nltk_data]    |   Package framenet_v17 is already up-to-date!\n",
      "[nltk_data]    | Downloading package gazetteers to\n",
      "[nltk_data]    |     /Users/wizdom/nltk_data...\n",
      "[nltk_data]    |   Package gazetteers is already up-to-date!\n",
      "[nltk_data]    | Downloading package genesis to\n",
      "[nltk_data]    |     /Users/wizdom/nltk_data...\n",
      "[nltk_data]    |   Package genesis is already up-to-date!\n",
      "[nltk_data]    | Downloading package gutenberg to\n",
      "[nltk_data]    |     /Users/wizdom/nltk_data...\n",
      "[nltk_data]    |   Package gutenberg is already up-to-date!\n",
      "[nltk_data]    | Downloading package ieer to\n",
      "[nltk_data]    |     /Users/wizdom/nltk_data...\n",
      "[nltk_data]    |   Package ieer is already up-to-date!\n",
      "[nltk_data]    | Downloading package inaugural to\n",
      "[nltk_data]    |     /Users/wizdom/nltk_data...\n",
      "[nltk_data]    |   Package inaugural is already up-to-date!\n",
      "[nltk_data]    | Downloading package indian to\n",
      "[nltk_data]    |     /Users/wizdom/nltk_data...\n",
      "[nltk_data]    |   Package indian is already up-to-date!\n",
      "[nltk_data]    | Downloading package jeita to\n",
      "[nltk_data]    |     /Users/wizdom/nltk_data...\n",
      "[nltk_data]    |   Package jeita is already up-to-date!\n",
      "[nltk_data]    | Downloading package kimmo to\n",
      "[nltk_data]    |     /Users/wizdom/nltk_data...\n",
      "[nltk_data]    |   Package kimmo is already up-to-date!\n",
      "[nltk_data]    | Downloading package knbc to\n",
      "[nltk_data]    |     /Users/wizdom/nltk_data...\n",
      "[nltk_data]    |   Package knbc is already up-to-date!\n",
      "[nltk_data]    | Downloading package lin_thesaurus to\n",
      "[nltk_data]    |     /Users/wizdom/nltk_data...\n",
      "[nltk_data]    |   Package lin_thesaurus is already up-to-date!\n",
      "[nltk_data]    | Downloading package mac_morpho to\n",
      "[nltk_data]    |     /Users/wizdom/nltk_data...\n",
      "[nltk_data]    |   Package mac_morpho is already up-to-date!\n",
      "[nltk_data]    | Downloading package machado to\n",
      "[nltk_data]    |     /Users/wizdom/nltk_data...\n",
      "[nltk_data]    |   Package machado is already up-to-date!\n",
      "[nltk_data]    | Downloading package masc_tagged to\n",
      "[nltk_data]    |     /Users/wizdom/nltk_data...\n",
      "[nltk_data]    |   Package masc_tagged is already up-to-date!\n",
      "[nltk_data]    | Downloading package moses_sample to\n",
      "[nltk_data]    |     /Users/wizdom/nltk_data...\n",
      "[nltk_data]    |   Package moses_sample is already up-to-date!\n",
      "[nltk_data]    | Downloading package movie_reviews to\n",
      "[nltk_data]    |     /Users/wizdom/nltk_data...\n",
      "[nltk_data]    |   Package movie_reviews is already up-to-date!\n",
      "[nltk_data]    | Downloading package names to\n",
      "[nltk_data]    |     /Users/wizdom/nltk_data...\n",
      "[nltk_data]    |   Package names is already up-to-date!\n",
      "[nltk_data]    | Downloading package nombank.1.0 to\n",
      "[nltk_data]    |     /Users/wizdom/nltk_data...\n",
      "[nltk_data]    |   Package nombank.1.0 is already up-to-date!\n",
      "[nltk_data]    | Downloading package nps_chat to\n",
      "[nltk_data]    |     /Users/wizdom/nltk_data...\n",
      "[nltk_data]    |   Package nps_chat is already up-to-date!\n",
      "[nltk_data]    | Downloading package omw to /Users/wizdom/nltk_data...\n",
      "[nltk_data]    |   Package omw is already up-to-date!\n",
      "[nltk_data]    | Downloading package opinion_lexicon to\n",
      "[nltk_data]    |     /Users/wizdom/nltk_data...\n",
      "[nltk_data]    |   Package opinion_lexicon is already up-to-date!\n",
      "[nltk_data]    | Downloading package paradigms to\n",
      "[nltk_data]    |     /Users/wizdom/nltk_data...\n",
      "[nltk_data]    |   Package paradigms is already up-to-date!\n",
      "[nltk_data]    | Downloading package pil to /Users/wizdom/nltk_data...\n",
      "[nltk_data]    |   Package pil is already up-to-date!\n",
      "[nltk_data]    | Downloading package pl196x to\n",
      "[nltk_data]    |     /Users/wizdom/nltk_data...\n",
      "[nltk_data]    |   Package pl196x is already up-to-date!\n",
      "[nltk_data]    | Downloading package ppattach to\n",
      "[nltk_data]    |     /Users/wizdom/nltk_data...\n",
      "[nltk_data]    |   Package ppattach is already up-to-date!\n",
      "[nltk_data]    | Downloading package problem_reports to\n",
      "[nltk_data]    |     /Users/wizdom/nltk_data...\n",
      "[nltk_data]    |   Package problem_reports is already up-to-date!\n",
      "[nltk_data]    | Downloading package propbank to\n",
      "[nltk_data]    |     /Users/wizdom/nltk_data...\n",
      "[nltk_data]    |   Package propbank is already up-to-date!\n",
      "[nltk_data]    | Downloading package ptb to /Users/wizdom/nltk_data...\n",
      "[nltk_data]    |   Package ptb is already up-to-date!\n",
      "[nltk_data]    | Downloading package product_reviews_1 to\n",
      "[nltk_data]    |     /Users/wizdom/nltk_data...\n",
      "[nltk_data]    |   Package product_reviews_1 is already up-to-date!\n",
      "[nltk_data]    | Downloading package product_reviews_2 to\n",
      "[nltk_data]    |     /Users/wizdom/nltk_data...\n",
      "[nltk_data]    |   Package product_reviews_2 is already up-to-date!\n",
      "[nltk_data]    | Downloading package pros_cons to\n",
      "[nltk_data]    |     /Users/wizdom/nltk_data...\n",
      "[nltk_data]    |   Package pros_cons is already up-to-date!\n",
      "[nltk_data]    | Downloading package qc to /Users/wizdom/nltk_data...\n",
      "[nltk_data]    |   Package qc is already up-to-date!\n",
      "[nltk_data]    | Downloading package reuters to\n",
      "[nltk_data]    |     /Users/wizdom/nltk_data...\n",
      "[nltk_data]    |   Package reuters is already up-to-date!\n",
      "[nltk_data]    | Downloading package rte to /Users/wizdom/nltk_data...\n",
      "[nltk_data]    |   Package rte is already up-to-date!\n",
      "[nltk_data]    | Downloading package semcor to\n",
      "[nltk_data]    |     /Users/wizdom/nltk_data...\n",
      "[nltk_data]    |   Package semcor is already up-to-date!\n",
      "[nltk_data]    | Downloading package senseval to\n",
      "[nltk_data]    |     /Users/wizdom/nltk_data...\n",
      "[nltk_data]    |   Package senseval is already up-to-date!\n",
      "[nltk_data]    | Downloading package sentiwordnet to\n",
      "[nltk_data]    |     /Users/wizdom/nltk_data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data]    |   Package sentiwordnet is already up-to-date!\n",
      "[nltk_data]    | Downloading package sentence_polarity to\n",
      "[nltk_data]    |     /Users/wizdom/nltk_data...\n",
      "[nltk_data]    |   Package sentence_polarity is already up-to-date!\n",
      "[nltk_data]    | Downloading package shakespeare to\n",
      "[nltk_data]    |     /Users/wizdom/nltk_data...\n",
      "[nltk_data]    |   Package shakespeare is already up-to-date!\n",
      "[nltk_data]    | Downloading package sinica_treebank to\n",
      "[nltk_data]    |     /Users/wizdom/nltk_data...\n",
      "[nltk_data]    |   Package sinica_treebank is already up-to-date!\n",
      "[nltk_data]    | Downloading package smultron to\n",
      "[nltk_data]    |     /Users/wizdom/nltk_data...\n",
      "[nltk_data]    |   Package smultron is already up-to-date!\n",
      "[nltk_data]    | Downloading package state_union to\n",
      "[nltk_data]    |     /Users/wizdom/nltk_data...\n",
      "[nltk_data]    |   Package state_union is already up-to-date!\n",
      "[nltk_data]    | Downloading package stopwords to\n",
      "[nltk_data]    |     /Users/wizdom/nltk_data...\n",
      "[nltk_data]    |   Package stopwords is already up-to-date!\n",
      "[nltk_data]    | Downloading package subjectivity to\n",
      "[nltk_data]    |     /Users/wizdom/nltk_data...\n",
      "[nltk_data]    |   Package subjectivity is already up-to-date!\n",
      "[nltk_data]    | Downloading package swadesh to\n",
      "[nltk_data]    |     /Users/wizdom/nltk_data...\n",
      "[nltk_data]    |   Package swadesh is already up-to-date!\n",
      "[nltk_data]    | Downloading package switchboard to\n",
      "[nltk_data]    |     /Users/wizdom/nltk_data...\n",
      "[nltk_data]    |   Package switchboard is already up-to-date!\n",
      "[nltk_data]    | Downloading package timit to\n",
      "[nltk_data]    |     /Users/wizdom/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/timit.zip.\n",
      "[nltk_data]    | Downloading package toolbox to\n",
      "[nltk_data]    |     /Users/wizdom/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/toolbox.zip.\n",
      "[nltk_data]    | Downloading package treebank to\n",
      "[nltk_data]    |     /Users/wizdom/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/treebank.zip.\n",
      "[nltk_data]    | Downloading package twitter_samples to\n",
      "[nltk_data]    |     /Users/wizdom/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/twitter_samples.zip.\n",
      "[nltk_data]    | Downloading package udhr to\n",
      "[nltk_data]    |     /Users/wizdom/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/udhr.zip.\n",
      "[nltk_data]    | Downloading package udhr2 to\n",
      "[nltk_data]    |     /Users/wizdom/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/udhr2.zip.\n",
      "[nltk_data]    | Downloading package unicode_samples to\n",
      "[nltk_data]    |     /Users/wizdom/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/unicode_samples.zip.\n",
      "[nltk_data]    | Downloading package universal_treebanks_v20 to\n",
      "[nltk_data]    |     /Users/wizdom/nltk_data...\n",
      "[nltk_data]    | Downloading package verbnet to\n",
      "[nltk_data]    |     /Users/wizdom/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/verbnet.zip.\n",
      "[nltk_data]    | Downloading package verbnet3 to\n",
      "[nltk_data]    |     /Users/wizdom/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/verbnet3.zip.\n",
      "[nltk_data]    | Downloading package webtext to\n",
      "[nltk_data]    |     /Users/wizdom/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/webtext.zip.\n",
      "[nltk_data]    | Downloading package wordnet to\n",
      "[nltk_data]    |     /Users/wizdom/nltk_data...\n",
      "[nltk_data]    |   Package wordnet is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet_ic to\n",
      "[nltk_data]    |     /Users/wizdom/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/wordnet_ic.zip.\n",
      "[nltk_data]    | Downloading package words to\n",
      "[nltk_data]    |     /Users/wizdom/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/words.zip.\n",
      "[nltk_data]    | Downloading package ycoe to\n",
      "[nltk_data]    |     /Users/wizdom/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/ycoe.zip.\n",
      "[nltk_data]    | Downloading package rslp to\n",
      "[nltk_data]    |     /Users/wizdom/nltk_data...\n",
      "[nltk_data]    |   Unzipping stemmers/rslp.zip.\n",
      "[nltk_data]    | Downloading package maxent_treebank_pos_tagger to\n",
      "[nltk_data]    |     /Users/wizdom/nltk_data...\n",
      "[nltk_data]    |   Unzipping taggers/maxent_treebank_pos_tagger.zip.\n",
      "[nltk_data]    | Downloading package universal_tagset to\n",
      "[nltk_data]    |     /Users/wizdom/nltk_data...\n",
      "[nltk_data]    |   Unzipping taggers/universal_tagset.zip.\n",
      "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
      "[nltk_data]    |     /Users/wizdom/nltk_data...\n",
      "[nltk_data]    |   Unzipping chunkers/maxent_ne_chunker.zip.\n",
      "[nltk_data]    | Downloading package punkt to\n",
      "[nltk_data]    |     /Users/wizdom/nltk_data...\n",
      "[nltk_data]    |   Package punkt is already up-to-date!\n",
      "[nltk_data]    | Downloading package book_grammars to\n",
      "[nltk_data]    |     /Users/wizdom/nltk_data...\n",
      "[nltk_data]    |   Unzipping grammars/book_grammars.zip.\n",
      "[nltk_data]    | Downloading package sample_grammars to\n",
      "[nltk_data]    |     /Users/wizdom/nltk_data...\n",
      "[nltk_data]    |   Unzipping grammars/sample_grammars.zip.\n",
      "[nltk_data]    | Downloading package spanish_grammars to\n",
      "[nltk_data]    |     /Users/wizdom/nltk_data...\n",
      "[nltk_data]    |   Unzipping grammars/spanish_grammars.zip.\n",
      "[nltk_data]    | Downloading package basque_grammars to\n",
      "[nltk_data]    |     /Users/wizdom/nltk_data...\n",
      "[nltk_data]    |   Unzipping grammars/basque_grammars.zip.\n",
      "[nltk_data]    | Downloading package large_grammars to\n",
      "[nltk_data]    |     /Users/wizdom/nltk_data...\n",
      "[nltk_data]    |   Unzipping grammars/large_grammars.zip.\n",
      "[nltk_data]    | Downloading package tagsets to\n",
      "[nltk_data]    |     /Users/wizdom/nltk_data...\n",
      "[nltk_data]    |   Unzipping help/tagsets.zip.\n",
      "[nltk_data]    | Downloading package snowball_data to\n",
      "[nltk_data]    |     /Users/wizdom/nltk_data...\n",
      "[nltk_data]    | Downloading package bllip_wsj_no_aux to\n",
      "[nltk_data]    |     /Users/wizdom/nltk_data...\n",
      "[nltk_data]    |   Unzipping models/bllip_wsj_no_aux.zip.\n",
      "[nltk_data]    | Downloading package word2vec_sample to\n",
      "[nltk_data]    |     /Users/wizdom/nltk_data...\n",
      "[nltk_data]    |   Unzipping models/word2vec_sample.zip.\n",
      "[nltk_data]    | Downloading package panlex_swadesh to\n",
      "[nltk_data]    |     /Users/wizdom/nltk_data...\n",
      "[nltk_data]    | Downloading package mte_teip5 to\n",
      "[nltk_data]    |     /Users/wizdom/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/mte_teip5.zip.\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]    |     /Users/wizdom/nltk_data...\n",
      "[nltk_data]    |   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger_ru to\n",
      "[nltk_data]    |     /Users/wizdom/nltk_data...\n",
      "[nltk_data]    |   Unzipping\n",
      "[nltk_data]    |       taggers/averaged_perceptron_tagger_ru.zip.\n",
      "[nltk_data]    | Downloading package perluniprops to\n",
      "[nltk_data]    |     /Users/wizdom/nltk_data...\n",
      "[nltk_data]    |   Unzipping misc/perluniprops.zip.\n",
      "[nltk_data]    | Downloading package nonbreaking_prefixes to\n",
      "[nltk_data]    |     /Users/wizdom/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/nonbreaking_prefixes.zip.\n",
      "[nltk_data]    | Downloading package vader_lexicon to\n",
      "[nltk_data]    |     /Users/wizdom/nltk_data...\n",
      "[nltk_data]    | Downloading package porter_test to\n",
      "[nltk_data]    |     /Users/wizdom/nltk_data...\n",
      "[nltk_data]    |   Unzipping stemmers/porter_test.zip.\n",
      "[nltk_data]    | Downloading package wmt15_eval to\n",
      "[nltk_data]    |     /Users/wizdom/nltk_data...\n",
      "[nltk_data]    |   Unzipping models/wmt15_eval.zip.\n",
      "[nltk_data]    | Downloading package mwa_ppdb to\n",
      "[nltk_data]    |     /Users/wizdom/nltk_data...\n",
      "[nltk_data]    |   Unzipping misc/mwa_ppdb.zip.\n",
      "[nltk_data]    | \n",
      "[nltk_data]  Done downloading collection all\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sysnsets() 반환 type: <class 'list'>\n",
      "synsets() 반환 값 개수: 18\n",
      "synsets() 반환 값: [Synset('present.n.01'), Synset('present.n.02'), Synset('present.n.03'), Synset('show.v.01'), Synset('present.v.02'), Synset('stage.v.01'), Synset('present.v.04'), Synset('present.v.05'), Synset('award.v.01'), Synset('give.v.08'), Synset('deliver.v.01'), Synset('introduce.v.01'), Synset('portray.v.04'), Synset('confront.v.03'), Synset('present.v.12'), Synset('salute.v.06'), Synset('present.a.01'), Synset('present.a.02')]\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "\n",
    "term = 'present'\n",
    "\n",
    "# 'present'라는 단어로 wordent의 synsets 생성\n",
    "synsets = wn.synsets(term)\n",
    "print('sysnsets() 반환 type:', type(synsets))\n",
    "print('synsets() 반환 값 개수:', len(synsets))\n",
    "print('synsets() 반환 값:', synsets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "여러 개의 synset 객체를 가지는 리스트가 반환되었다. 총 18개의 서로 다른 semantic을 가지는 synset객체가 반환됐다. \n",
    "\n",
    "Synset(‘present.n.01’)와 같이 Synset객체의 파라미터 ‘present.n.01’은 POS태그를 나타낸다. 여기서 present는 의미, n은 명사 품사, 01은 present가 명사로서 가지는 의미가 여러가지있어서 이를 구분하는 인덱스이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### Synset name:  present.n.01 #####\n",
      "POS : noun.time\n",
      "Definition : the period of time that is happening now; any continuous stretch of time including the moment of speech\n",
      "Lemmas : ['present', 'nowadays']\n",
      "##### Synset name:  present.n.02 #####\n",
      "POS : noun.possession\n",
      "Definition : something presented as a gift\n",
      "Lemmas : ['present']\n",
      "##### Synset name:  present.n.03 #####\n",
      "POS : noun.communication\n",
      "Definition : a verb tense that expresses actions or states at the time of speaking\n",
      "Lemmas : ['present', 'present_tense']\n",
      "##### Synset name:  show.v.01 #####\n",
      "POS : verb.perception\n",
      "Definition : give an exhibition of to an interested audience\n",
      "Lemmas : ['show', 'demo', 'exhibit', 'present', 'demonstrate']\n",
      "##### Synset name:  present.v.02 #####\n",
      "POS : verb.communication\n",
      "Definition : bring forward and present to the mind\n",
      "Lemmas : ['present', 'represent', 'lay_out']\n",
      "##### Synset name:  stage.v.01 #####\n",
      "POS : verb.creation\n",
      "Definition : perform (a play), especially on a stage\n",
      "Lemmas : ['stage', 'present', 'represent']\n",
      "##### Synset name:  present.v.04 #####\n",
      "POS : verb.possession\n",
      "Definition : hand over formally\n",
      "Lemmas : ['present', 'submit']\n",
      "##### Synset name:  present.v.05 #####\n",
      "POS : verb.stative\n",
      "Definition : introduce\n",
      "Lemmas : ['present', 'pose']\n",
      "##### Synset name:  award.v.01 #####\n",
      "POS : verb.possession\n",
      "Definition : give, especially as an honor or reward\n",
      "Lemmas : ['award', 'present']\n",
      "##### Synset name:  give.v.08 #####\n",
      "POS : verb.possession\n",
      "Definition : give as a present; make a gift of\n",
      "Lemmas : ['give', 'gift', 'present']\n",
      "##### Synset name:  deliver.v.01 #####\n",
      "POS : verb.communication\n",
      "Definition : deliver (a speech, oration, or idea)\n",
      "Lemmas : ['deliver', 'present']\n",
      "##### Synset name:  introduce.v.01 #####\n",
      "POS : verb.communication\n",
      "Definition : cause to come to know personally\n",
      "Lemmas : ['introduce', 'present', 'acquaint']\n",
      "##### Synset name:  portray.v.04 #####\n",
      "POS : verb.creation\n",
      "Definition : represent abstractly, for example in a painting, drawing, or sculpture\n",
      "Lemmas : ['portray', 'present']\n",
      "##### Synset name:  confront.v.03 #####\n",
      "POS : verb.communication\n",
      "Definition : present somebody with something, usually to accuse or criticize\n",
      "Lemmas : ['confront', 'face', 'present']\n",
      "##### Synset name:  present.v.12 #####\n",
      "POS : verb.communication\n",
      "Definition : formally present a debutante, a representative of a country, etc.\n",
      "Lemmas : ['present']\n",
      "##### Synset name:  salute.v.06 #####\n",
      "POS : verb.communication\n",
      "Definition : recognize with a gesture prescribed by a military regulation; assume a prescribed position\n",
      "Lemmas : ['salute', 'present']\n",
      "##### Synset name:  present.a.01 #####\n",
      "POS : adj.all\n",
      "Definition : temporal sense; intermediate between past and future; now existing or happening or in consideration\n",
      "Lemmas : ['present']\n",
      "##### Synset name:  present.a.02 #####\n",
      "POS : adj.all\n",
      "Definition : being or existing in a specified place\n",
      "Lemmas : ['present']\n"
     ]
    }
   ],
   "source": [
    "# synset 객체가 가지는 여러가지 속성 살펴보기\n",
    "# POS(품사), 정의(Definition), 부명제(Lemma) 표현\n",
    "\n",
    "for synset in synsets:\n",
    "    print('##### Synset name: ', synset.name(), '#####')\n",
    "    print('POS :', synset.lexname())\n",
    "    print('Definition :', synset.definition())\n",
    "    print('Lemmas :', synset.lemma_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이처럼 synset은 하나의 단어가 가질 수 있는 여러 가지 시맨틱 정보를 개별 클래스로 나타낸 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- WordNet은 어떤 어휘와 다른 어휘 간의 관계를 유사도로 나타낼 수 있다.\n",
    "- synset 객체는 **단어간의 유사도**를 나타내기 위해 **path_similarity()** 메서드를 제공한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tree</th>\n",
       "      <th>lion</th>\n",
       "      <th>tiger</th>\n",
       "      <th>cat</th>\n",
       "      <th>dog</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>tree</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lion</th>\n",
       "      <td>0.07</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tiger</th>\n",
       "      <td>0.07</td>\n",
       "      <td>0.33</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cat</th>\n",
       "      <td>0.08</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dog</th>\n",
       "      <td>0.12</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.20</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       tree  lion  tiger   cat   dog\n",
       "tree   1.00  0.07   0.07  0.08  0.12\n",
       "lion   0.07  1.00   0.33  0.25  0.17\n",
       "tiger  0.07  0.33   1.00  0.25  0.17\n",
       "cat    0.08  0.25   0.25  1.00  0.20\n",
       "dog    0.12  0.17   0.17  0.20  1.00"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 어떤 어휘와 다른 어휘 간의 관계를 유사도로 나타내기\n",
    "\n",
    "# synset 객체를 단어별로 생성\n",
    "tree = wn.synset('tree.n.01')\n",
    "lion = wn.synset('lion.n.01')\n",
    "tiger = wn.synset('tiger.n.02')\n",
    "cat = wn.synset('cat.n.01')\n",
    "dog = wn.synset('dog.n.01')\n",
    "\n",
    "entities = [tree, lion, tiger, cat, dog]\n",
    "similarities = []\n",
    "entity_names = [entity.name().split('.')[0] for entity in entities]\n",
    "\n",
    "# 단어별 synset을 반복하면서 다른 단어의 synset과 유사도를 측정한다.\n",
    "for entity in entities :\n",
    "    similarity = [round(entity.path_similarity(compared_entity), 2)\n",
    "                 for compared_entity in entities]\n",
    "    similarities.append(similarity)\n",
    "    \n",
    "# 개별 단어별 synset과 다른 단어의 synset과의 유사도를 DataFrame 형태로 저장한다.\n",
    "similarity_df = pd.DataFrame(similarities, columns=entity_names, index=entity_names)\n",
    "similarity_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SentiWordNet은 WordNet의 Synset과 유사한 Senti_Synset 클래스를 가지고 있다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "senti_synsets() 반환 type : <class 'list'>\n",
      "senti_synsets() 반환 값 개수 : 11\n",
      "senti_synsets() 반환 값 : [SentiSynset('decelerate.v.01'), SentiSynset('slow.v.02'), SentiSynset('slow.v.03'), SentiSynset('slow.a.01'), SentiSynset('slow.a.02'), SentiSynset('dense.s.04'), SentiSynset('slow.a.04'), SentiSynset('boring.s.01'), SentiSynset('dull.s.08'), SentiSynset('slowly.r.01'), SentiSynset('behind.r.03')]\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import sentiwordnet as swn\n",
    "\n",
    "senti_synsets = list(swn.senti_synsets('slow'))\n",
    "print('senti_synsets() 반환 type :', type(senti_synsets))\n",
    "print('senti_synsets() 반환 값 개수 :', len(senti_synsets))\n",
    "print('senti_synsets() 반환 값 :', senti_synsets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SentiSynset 객체는 단어의 감성을 나타내는 감성 지수(긍정 감성 지수, 부정 감성지수로 나뉜다)와 객관성을(감성과 반대) 나타내는 객관성 지수를 가지고 있다. 어떤 단어가 전혀 감성적이지 않으면 객관성 지수는 1이되고, 감성 지수는 모두 0이 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "father 긍정 감성 지수: 0.0\n",
      "father 부정 감성 지수: 0.0\n",
      "father 객관성 지수: 1.0\n",
      "\n",
      "\n",
      "fabulous 긍정 감성 지수: 0.875\n",
      "fabulous 부정 감성 지수: 0.125\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import sentiwordnet as swn\n",
    "\n",
    "father = swn.senti_synset('father.n.01')\n",
    "print('father 긍정 감성 지수:', father.pos_score())\n",
    "print('father 부정 감성 지수:', father.neg_score())\n",
    "print('father 객관성 지수:', father.obj_score())\n",
    "print('\\n')\n",
    "\n",
    "fabulous = swn.senti_synset('fabulous.a.01')\n",
    "print('fabulous 긍정 감성 지수:', fabulous.pos_score())\n",
    "print('fabulous 부정 감성 지수:', fabulous.neg_score())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "father은 객관적인 단어로 객관성 지수가 1.0이고 긍정 감성/부정 감성 지수가 모두 0이다. 반면에 fabulous는 감성 단어로서 긍정 감성 지수가 0.875, 부정 감성 지수가 0.125이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SentiWordNet을 이용한 영화 감상평 감성 분석\n",
    "< SentiWordNet을 이용해 감성 분석을 수행하는 개략적인 순서 >\n",
    "1. 문서를 문장 단위로 분해\n",
    "2. 다시 문장을 단어 단위로 토큰화하고 품사 태깅\n",
    "3. 품사 태깅된 단어 기반으로 synset 객체와 senti_synset 객체를 생성\n",
    "4. Senti_synset에서 긍정/부정 감성 지수를 구하고 이를 모두 합산해 특정 임계치 값 이상일 때 긍정감성으로, 그렇지 않을때 부정 감성으로 결정|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SentiWordNet을 이용하기 위해서 WordNet을 이용해 문서를 다시 단어로 토큰화한 뒤 어근 추출과 품사 태깅을 적용해야 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 품사 태깅을 수행하는 내부 함수 생성\n",
    "\n",
    "from nltk.corpus import wordnet as wn\n",
    "\n",
    "# 간단한 NTLK PennTreebank Tag를 기반으로 WordNet 기반의 품사 Tag로 변환\n",
    "def penn_to_wn(tag):\n",
    "    if tag.startswith('J'):\n",
    "        return wn.ADJ\n",
    "    elif tag.startswith('N'):\n",
    "        return wn.NOUN\n",
    "    elif tag.startswith('R'):\n",
    "        return wn.ADV\n",
    "    elif tag.startswith('V'):\n",
    "        return wn.VERB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문서를 문장 -> 단어 토큰 -> 품사 태깅 후에 SentiSynset 클래스를 생성하고 Polarity Score를 합산하는 함수 생성\n",
    "# 총 감성 지수가 0 이상일 경우 긍정 감성, 그렇지 않을 경우 부정 감성으로 예측\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import sentiwordnet as swn\n",
    "from nltk import sent_tokenize, word_tokenize, pos_tag\n",
    "\n",
    "def swn_polarity(text):\n",
    "    # 감성 지수 초기화\n",
    "    sentiment = 0.0\n",
    "    tokens_count = 0\n",
    "    \n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    raw_sentences = sent_tokenize(text)\n",
    "    # 분해된 문장별로 단어 토큰 -> 품사 태깅 후에 SentiSynset 생성 -> 감성 지수 합산\n",
    "    for raw_sentence in raw_sentences:\n",
    "        # NLTK 기반의 품사 태깅 문장 추출\n",
    "        tagged_sentence = pos_tag(word_tokenize(raw_sentence))\n",
    "        for word, tag in tagged_sentence:\n",
    "            \n",
    "            # WordNet 기반 품사 태깅과 어근 추출\n",
    "            wn_tag = penn_to_wn(tag)\n",
    "            if wn_tag not in (wn.NOUN, wn.ADJ, wn.ADV):\n",
    "                continue\n",
    "            lemma = lemmatizer.lemmatize(word, pos=wn_tag)\n",
    "            if not lemma:\n",
    "                continue\n",
    "            # 어근을 추출한 단어와 WordNet 기반 품사 태깅을 입력해 Synset 객체를 생성\n",
    "            synsets = wn.synsets(lemma, pos=wn_tag)\n",
    "            if not synsets:\n",
    "                continue\n",
    "            # sentiwordnet의 감성 단어 분석으로 감성 synset 추출\n",
    "            # 모든 단어에 대해 긍정 감성 지수는 +로 부정 감성 지수는 -로 합산해 감성 지수 계산\n",
    "            synset = synsets[0]\n",
    "            swn_synset = swn.senti_synset(synset.name())\n",
    "            sentiment += (swn_synset.pos_score() - swn_synset.neg_score())\n",
    "            tokens_count += 1\n",
    "            \n",
    "    if not tokens_count :\n",
    "            return 0\n",
    "        \n",
    "    # 총 score가 0 이상일 경우 긍정(Positive) 1, 그렇지 않을 경우 부정(Negative) 0 반환\n",
    "    if sentiment >= 0 :\n",
    "        return 1\n",
    "        \n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lambda 구문을 이용해 swn_polarity() 함수를 개별 감상평 텍스트에 적용. \n",
    "# 새로운 칼럼으로 ‘preds’를 추가해 swn_polarity로 반환된 감성 평가를 담고, \n",
    "# 실제 감성 평가인 ‘sentiment’칼럼과 정확도, 정밀도 재현율 값 모두 측정하기\n",
    "\n",
    "review_df['preds'] = review_df['review'].apply(lambda x : swn_polarity(x))\n",
    "y_target = review_df['sentiment'].values\n",
    "preds = review_df['preds'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7668 4832]\n",
      " [3636 8864]]\n",
      "정확도: 0.6613\n",
      "정밀도: 0.6472\n",
      "재현율: 0.7091\n"
     ]
    }
   ],
   "source": [
    "# SentiWordNet의 감성 분석 예측 성능 살펴보기\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score\n",
    "from sklearn.metrics import recall_score, f1_score, roc_auc_score\n",
    "import numpy as np\n",
    "\n",
    "print(confusion_matrix(y_target, preds))\n",
    "print(\"정확도:\", np.round(accuracy_score(y_target, preds), 4))\n",
    "print(\"정밀도:\", np.round(precision_score(y_target, preds), 4))\n",
    "print(\"재현율:\", np.round(recall_score(y_target, preds), 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "정확도 지표를 포함한 전반적인 성능 평가 지표는 만족스러울 만한 수치는 아니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VADER를 이용한 감성 분석\n",
    "- **VADER** : 소셜 미디어의 감성 분석 용도로 만들어진 룰 기반의 Lexicon\n",
    "- **SentimentIntensityAnalyzer 클래스** 이용해 쉽게 감성 분석 제공"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'neg': 0.119, 'neu': 0.755, 'pos': 0.126, 'compound': -0.0678}\n"
     ]
    }
   ],
   "source": [
    "# VADER의 간단한 사용법\n",
    "\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "senti_analyzer = SentimentIntensityAnalyzer()\n",
    "senti_scores = senti_analyzer.polarity_scores(review_df['review'][0])\n",
    "print(senti_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SentimentIntensityAnalyzer 객체를 생성한 뒤에 문서별로 polarity_scores() 메서드를 호출해 감성 점수를 구한 뒤, 해당 문서의 감성 점수가 특정 임계값 이상이면 긍정, 그렇지 않으면 부정으로 판단한다.\n",
    "- SentimentIntensity 분석 객체의 **polarity_scores() 메서드** : 딕셔너리 형태의 감성 점수를 반환한다.\n",
    "\t- **neg** : 부정 감성 지수\n",
    "\t- **neu** : 중립적인 감성 지수\n",
    "\t- **pos** : 긍정 감성 지수\n",
    "\t- **compound** : neg, neu, pos score를 적절히 조합해 -1에서 1 사이의 감성 지수 표현한 값이다.\n",
    "         - compound score를 기반으로 부정 감성 또는 긍정 감성 여부를 결정한다.\n",
    "         - 보통 0.1 이상이면 긍정 감성, 그 이하이면 부정 감성으로 판단하나, 상황에 따라 임계값을 적절히 조정해 예측 성능을 조절한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 6729  5771]\n",
      " [ 1858 10642]]\n",
      "정확도: 0.6948\n",
      "정밀도: 0.6484\n",
      "재현율: 0.8514\n"
     ]
    }
   ],
   "source": [
    "def vader_polarity(review, threshold=0.1):\n",
    "    analyzer = SentimentIntensityAnalyzer()\n",
    "    scores = analyzer.polarity_scores(review)\n",
    "    \n",
    "    # compound 값에 기반해 threshold 입력값보다 크면 1, 그렇지 않으면 0을 반환\n",
    "    agg_score = scores['compound']\n",
    "    final_sentiment = 1 if agg_score >= threshold else 0\n",
    "    return final_sentiment\n",
    "\n",
    "# apply lambda 식을 이용해 레코드별로 vader_polarity()를 수행하고 결과를 'vader_preds'에 저장\n",
    "review_df['vader_preds'] = review_df['review'].apply(lambda x : vader_polarity(x, 0.1))\n",
    "y_target = review_df['sentiment'].values\n",
    "vader_preds = review_df['vader_preds'].values\n",
    "\n",
    "print(confusion_matrix(y_target, vader_preds))\n",
    "print(\"정확도:\", np.round(accuracy_score(y_target, vader_preds), 4))\n",
    "print(\"정밀도:\", np.round(precision_score(y_target, vader_preds), 4))\n",
    "print(\"재현율:\", np.round(recall_score(y_target, vader_preds), 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "정확도 및 재현율이 SentiWordNet보다 크게 향상되었다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 06. 토픽 모델링(Topic Modeling) - 20 뉴스그룹\n",
    ": 문서 집합에 숨어있는 주제를 찾아내는 것. 숨겨진 주체를 효과적으로 표현할 수 있는 중심 단어를 함축적으로 추출한다.\n",
    "- 머신러닝 기반의 토픽모델링에서 자주 사용되는 기법은 **LSA(Latent Semantic Analysis)와 LDA(Latent Dirichlet Allocation)** 이다.\n",
    "\t- **LatentDirichletAllocation 클래스** : LDA 기반 토픽 모델링 클래스\n",
    "\t\t- LDA는 Count 기반의 벡터화만 사용한다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CountVectorizer Shape: (7862, 1000)\n"
     ]
    }
   ],
   "source": [
    "# 20가지의 주제를 가진 뉴스그룹 데이터에서 8개 주제를 추출하고 LDA 기반 토픽 모델링 적용\n",
    "\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "# 모토사이클, 야구, 그래픽스, 윈도우즈, 중동, 기독교, 전자공학, 의학 8개 주제를 추출\n",
    "cats = ['rec.motorcycles', 'rec.sport.baseball', 'comp.graphics', 'comp.windows.x',\n",
    "       'talk.politics.mideast', 'soc.religion.christian', 'sci.electronics', 'sci.med']\n",
    "\n",
    "# 위에서 cats 변수로 기재된 카테고리만 추출. featch_20newsgroups()의 categoires에 cats입력\n",
    "news_df = fetch_20newsgroups(subset='all', remove=('headers', 'footers', 'quotes'),\n",
    "                            categories=cats, random_state=0)\n",
    "\n",
    "# LDA는 Count 기반의 벡터화만 적용한다.\n",
    "count_vect = CountVectorizer(max_df=0.95, max_features=1000, min_df=2, stop_words='english',\n",
    "                            ngram_range=(1, 2))\n",
    "feat_vect = count_vect.fit_transform(news_df.data)\n",
    "print('CountVectorizer Shape:', feat_vect.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LatentDirichletAllocation(n_components=8, random_state=0)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 피처 벡터화된 데이터 세트를 기반으로 LDA 토픽 모델링 수행\n",
    "# n_components 파라미터로 토픽 개수 조정(추출한 주제와 동일하게 8개)\n",
    "\n",
    "lda = LatentDirichletAllocation(n_components=8, random_state=0)\n",
    "lda.fit(feat_vect)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LatentDirichletAllocation.fit을 수행하면 components_ 속성값을 가진다\n",
    "- **components_** : 개별 토픽별로 각 word 피처가 얼마나 많이 그 토픽에 할당됐는지에 대한 수치를 가지고 있다.\n",
    "\t- 높은 값일수록 해당 word 피처는 그 토픽의 중심 word가 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 1000)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[3.60992018e+01, 1.35626798e+02, 2.15751867e+01, ...,\n",
       "        3.02911688e+01, 8.66830093e+01, 6.79285199e+01],\n",
       "       [1.25199920e-01, 1.44401815e+01, 1.25045596e-01, ...,\n",
       "        1.81506995e+02, 1.25097844e-01, 9.39593286e+01],\n",
       "       [3.34762663e+02, 1.25176265e-01, 1.46743299e+02, ...,\n",
       "        1.25105772e-01, 3.63689741e+01, 1.25025218e-01],\n",
       "       ...,\n",
       "       [3.60204965e+01, 2.08640688e+01, 4.29606813e+00, ...,\n",
       "        1.45056650e+01, 8.33854413e+00, 1.55690009e+01],\n",
       "       [1.25128711e-01, 1.25247756e-01, 1.25005143e-01, ...,\n",
       "        9.17278769e+01, 1.25177668e-01, 3.74575887e+01],\n",
       "       [5.49258690e+01, 4.47009532e+00, 9.88524814e+00, ...,\n",
       "        4.87048440e+01, 1.25034678e-01, 1.25074632e-01]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# components_의 형태와 속성값 확인\n",
    "print(lda.components_.shape)\n",
    "lda.components_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8개 토픽별로 1000개의 word 피처가 해당 토픽별로 연관도 값을 가지고 있다. 하지만 이 값들만으로는 각 토픽별 word 연관도를 보기가 어렵다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic # 0\n",
      "year 10 game medical health team 12 20 disease cancer 1993 games years patients good\n",
      "Topic # 1\n",
      "don just like know people said think time ve didn right going say ll way\n",
      "Topic # 2\n",
      "image file jpeg program gif images output format files color entry 00 use bit 03\n",
      "Topic # 3\n",
      "like know don think use does just good time book read information people used post\n",
      "Topic # 4\n",
      "armenian israel armenians jews turkish people israeli jewish government war dos dos turkey arab armenia 000\n",
      "Topic # 5\n",
      "edu com available graphics ftp data pub motif mail widget software mit information version sun\n",
      "Topic # 6\n",
      "god people jesus church believe christ does christian say think christians bible faith sin life\n",
      "Topic # 7\n",
      "use dos thanks windows using window does display help like problem server need know run\n"
     ]
    }
   ],
   "source": [
    "# 각 토픽별로 연관도가 높은 순으로 word를 나열해주는 함수 만들기\n",
    "\n",
    "def display_topics(model, feature_names, no_top_words):\n",
    "    for topic_index, topic in enumerate(model.components_):\n",
    "        print('Topic #', topic_index)\n",
    "        \n",
    "        # components_ array에서 가장 값이 큰 순으로 정렬했을 때, 그 값의 array 인덱스를 반환\n",
    "        topic_word_indexes = topic.argsort()[::-1]\n",
    "        top_indexes = topic_word_indexes[:no_top_words]\n",
    "        \n",
    "        # top_indexes 대상인 인덱스별로 feature_names에 해당하는 word feature 추출 후 join으로로 concat\n",
    "        feature_concat = ' '.join([feature_names[i] for i in top_indexes])\n",
    "        print(feature_concat)\n",
    "        \n",
    "# CountVectorizer 객체 내의 전체 word의 명칭을 get_features_names()를 통해 추출\n",
    "feature_names = count_vect.get_feature_names()\n",
    "\n",
    "# 토픽별 가장 연관도가 높은 word를 15개만 추출\n",
    "display_topics(lda, feature_names, 15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Topic #1, #2, #3, #4, #6은 주제에 맞는 단어들이 추출됐으나, Topic #0, #5, #7은 주로 애매한 주제어가 추출됐다. 특히 모토사이클, 야구 주제의 경우 명확한 주제어가 추출되지 않았다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 07. 문서 군집화 소개와 실습(Opinion Review 데이터 세트)\n",
    "### 문서 군집화 개념\n",
    ": 비슷한 텍스트 구성의 문서를 군집화(Clustering)하는 것이다. 텍스트 분류 기반의 문서 분류와 유사하나, 텍스트 분류 기반의 문서 분류는 사전에 결정 카테고리 값을 가진 학습 데이터 세트가 필요한데 반해, **문서 군집화는 학습 데이터 세트가 필요 없는 비지도학습 기반으로 동작한다.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Opinion Reveiw 데이터 세트를 이용한 문서 군집화 수행하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>opinion_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>battery-life_ipod_nano_8gb</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gas_mileage_toyota_camry_2007</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>room_holiday_inn_london</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>location_holiday_inn_london</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>staff_bestwestern_hotel_sfo</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        filename  \\\n",
       "0     battery-life_ipod_nano_8gb   \n",
       "1  gas_mileage_toyota_camry_2007   \n",
       "2        room_holiday_inn_london   \n",
       "3    location_holiday_inn_london   \n",
       "4    staff_bestwestern_hotel_sfo   \n",
       "\n",
       "                                        opinion_text  \n",
       "0                                                ...  \n",
       "1                                                ...  \n",
       "2                                                ...  \n",
       "3                                                ...  \n",
       "4                                                ...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob, os\n",
    "\n",
    "# 디렉터리 설정\n",
    "path = '/Users/wizdom/Desktop/data_analysis/파이썬 머신러닝 완벽가이드/실습 데이터/OpinosisDataset1.0/topics'\n",
    "# path로 지정한 디렉터리 밑에 있는 모든 .data 파일의 파일명을 리스트로 취합\n",
    "all_files = glob.glob(os.path.join(path, \"*.data\"))\n",
    "filename_list = []\n",
    "opinion_text = []\n",
    "\n",
    "# 개별 파일의 파일명은 filename_list로 취합,\n",
    "# 개별 파일의 파일 내용은 DataFrame 로딩 후 다시 string으로 변환해 opinion_text list로 취합\n",
    "for file_ in all_files :\n",
    "    # 개별 파일을 읽어서 DataFrame으로 생성\n",
    "    df = pd.read_table(file_, index_col=None, header=0, encoding='latin1')\n",
    "    \n",
    "    # 절대 경로로 주어진 파일명을 가공.\n",
    "    filename_ = file_.split('/')[-1]\n",
    "    # 맨 마지막 .data 확장자도 제거\n",
    "    filename = filename_.split('.')[0]\n",
    "    \n",
    "    # 파일명 list와 파일 내용 list에 파일명과 파일 내용을 추가\n",
    "    filename_list.append(filename)\n",
    "    opinion_text.append(df.to_string())\n",
    "    \n",
    "# 파일명 list와 파일 내용 list 객체를 DataFrame으로 생성\n",
    "document_df = pd.DataFrame({'filename':filename_list, 'opinion_text':opinion_text})\n",
    "document_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "각 파일 이름 자체만으로 의견의 텍스트가 어떠한 제품/서비스에 대한 리뷰인지 잘 알 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "import nltk\n",
    "import string\n",
    "\n",
    "remove_punct_dict = dict((ord(punct), None) for punct in string.punctuation)\n",
    "lemmar = WordNetLemmatizer()\n",
    "\n",
    "def LemTokens(tokens):\n",
    "    return [lemmar.lemmatize(token) for token in tokens]\n",
    "\n",
    "def LemNormalize(text):\n",
    "    return LemTokens(nltk.word_tokenize(text.lower().translate(remove_punct_dict)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:383: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ha', 'le', 'u', 'wa'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n"
     ]
    }
   ],
   "source": [
    "# 문서를 TF-IDF 형태로 피처 벡터화하기\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_vect = TfidfVectorizer(tokenizer=LemNormalize, stop_words='english',\n",
    "                           ngram_range=(1, 2), min_df=0.05, max_df=0.85)\n",
    "# opinion_text 칼럼 값으로 피처 벡터화 수행\n",
    "feature_vect = tfidf_vect.fit_transform(document_df['opinion_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문서별 텍스트가 TF-IDF 변환된 피처 벡터화 행렬 데이터에 대해서 군집화를 수행해 어떤 문서끼리 군집되는지 확인\n",
    "# 먼저 5개의 중심(Centroid) 기반으로 어떻게 군집화되는지 확인\n",
    "\n",
    "# 군집화 기법은 K-평균을 적용\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "km_cluster = KMeans(n_clusters=5, max_iter=10000, random_state=0)\n",
    "km_cluster.fit(feature_vect)\n",
    "# 군집의 label값과 중심별로 할당된 데이터 세트의 좌표 값 구하기\n",
    "cluster_label = km_cluster.labels_\n",
    "cluster_centers = km_cluster.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>opinion_text</th>\n",
       "      <th>cluster_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>battery-life_ipod_nano_8gb</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gas_mileage_toyota_camry_2007</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>room_holiday_inn_london</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>location_holiday_inn_london</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>staff_bestwestern_hotel_sfo</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        filename  \\\n",
       "0     battery-life_ipod_nano_8gb   \n",
       "1  gas_mileage_toyota_camry_2007   \n",
       "2        room_holiday_inn_london   \n",
       "3    location_holiday_inn_london   \n",
       "4    staff_bestwestern_hotel_sfo   \n",
       "\n",
       "                                        opinion_text  cluster_label  \n",
       "0                                                ...              1  \n",
       "1                                                ...              3  \n",
       "2                                                ...              2  \n",
       "3                                                ...              2  \n",
       "4                                                ...              2  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 군집이 각  주제별로 유사한 형태로 잘 구성됐는지 알아보기\n",
    "\n",
    "document_df['cluster_label'] = cluster_label\n",
    "document_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>opinion_text</th>\n",
       "      <th>cluster_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>buttons_amazon_kindle</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>eyesight-issues_amazon_kindle</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>fonts_amazon_kindle</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>navigation_amazon_kindle</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>price_amazon_kindle</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         filename  \\\n",
       "26          buttons_amazon_kindle   \n",
       "36  eyesight-issues_amazon_kindle   \n",
       "44            fonts_amazon_kindle   \n",
       "38       navigation_amazon_kindle   \n",
       "41            price_amazon_kindle   \n",
       "\n",
       "                                         opinion_text  cluster_label  \n",
       "26                                                ...              0  \n",
       "36                                                ...              0  \n",
       "44                                                ...              0  \n",
       "38                                                ...              0  \n",
       "41                                                ...              0  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# document_df DataFrame 객체에서 cluster_label로 어떤 파일명으로 매칭됐는지 보면서 군집화 결과 확인\n",
    "\n",
    "document_df[document_df['cluster_label']==0].sort_values(by='filename')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cluster #0은 호텔에 대한 리뷰로 군집화 돼 있음을 알 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>opinion_text</th>\n",
       "      <th>cluster_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>battery-life_amazon_kindle</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>battery-life_ipod_nano_8gb</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>battery-life_netbook_1005ha</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>features_windows7</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>keyboard_netbook_1005ha</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>performance_netbook_1005ha</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>screen_garmin_nuvi_255W_gps</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>screen_ipod_nano_8gb</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>screen_netbook_1005ha</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>size_asus_netbook_1005ha</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>sound_ipod_nano_8gb</td>\n",
       "      <td>headphone jack i got a clear case for it a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>speed_windows7</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>video_ipod_nano_8gb</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       filename  \\\n",
       "9    battery-life_amazon_kindle   \n",
       "0    battery-life_ipod_nano_8gb   \n",
       "11  battery-life_netbook_1005ha   \n",
       "21            features_windows7   \n",
       "12      keyboard_netbook_1005ha   \n",
       "15   performance_netbook_1005ha   \n",
       "8   screen_garmin_nuvi_255W_gps   \n",
       "25         screen_ipod_nano_8gb   \n",
       "37        screen_netbook_1005ha   \n",
       "7      size_asus_netbook_1005ha   \n",
       "24          sound_ipod_nano_8gb   \n",
       "40               speed_windows7   \n",
       "14          video_ipod_nano_8gb   \n",
       "\n",
       "                                         opinion_text  cluster_label  \n",
       "9                                                 ...              1  \n",
       "0                                                 ...              1  \n",
       "11                                                ...              1  \n",
       "21                                                ...              1  \n",
       "12                                                ...              1  \n",
       "15                                                ...              1  \n",
       "8                                                 ...              1  \n",
       "25                                                ...              1  \n",
       "37                                                ...              1  \n",
       "7                                                 ...              1  \n",
       "24      headphone jack i got a clear case for it a...              1  \n",
       "40                                                ...              1  \n",
       "14                                                ...              1  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_df[document_df['cluster_label']==1].sort_values(by='filename')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cluster #1을 살펴보면 킨들, 아이팟, 넷북 등의 포터블 전자기기에 대한 리뷰로 군집화돼 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>opinion_text</th>\n",
       "      <th>cluster_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>bathroom_bestwestern_hotel_sfo</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>food_holiday_inn_london</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>food_swissotel_chicago</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>free_bestwestern_hotel_sfo</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>location_bestwestern_hotel_sfo</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>location_holiday_inn_london</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>parking_bestwestern_hotel_sfo</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>price_holiday_inn_london</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>room_holiday_inn_london</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>rooms_bestwestern_hotel_sfo</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>rooms_swissotel_chicago</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>service_bestwestern_hotel_sfo</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>service_holiday_inn_london</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>service_swissotel_hotel_chicago</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>staff_bestwestern_hotel_sfo</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>staff_swissotel_chicago</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           filename  \\\n",
       "31   bathroom_bestwestern_hotel_sfo   \n",
       "17          food_holiday_inn_london   \n",
       "32           food_swissotel_chicago   \n",
       "49       free_bestwestern_hotel_sfo   \n",
       "39   location_bestwestern_hotel_sfo   \n",
       "3       location_holiday_inn_london   \n",
       "50    parking_bestwestern_hotel_sfo   \n",
       "28         price_holiday_inn_london   \n",
       "2           room_holiday_inn_london   \n",
       "46      rooms_bestwestern_hotel_sfo   \n",
       "30          rooms_swissotel_chicago   \n",
       "16    service_bestwestern_hotel_sfo   \n",
       "27       service_holiday_inn_london   \n",
       "13  service_swissotel_hotel_chicago   \n",
       "4       staff_bestwestern_hotel_sfo   \n",
       "20          staff_swissotel_chicago   \n",
       "\n",
       "                                         opinion_text  cluster_label  \n",
       "31                                                ...              2  \n",
       "17                                                ...              2  \n",
       "32                                                ...              2  \n",
       "49                                                ...              2  \n",
       "39                                                ...              2  \n",
       "3                                                 ...              2  \n",
       "50                                                ...              2  \n",
       "28                                                ...              2  \n",
       "2                                                 ...              2  \n",
       "46                                                ...              2  \n",
       "30                                                ...              2  \n",
       "16                                                ...              2  \n",
       "27                                                ...              2  \n",
       "13                                                ...              2  \n",
       "4                                                 ...              2  \n",
       "20                                                ...              2  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_df[document_df['cluster_label']==2].sort_values(by='filename')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cluster #2는 #0과 같이 대부분 호텔에 대한 리뷰로 군집화 되어 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>opinion_text</th>\n",
       "      <th>cluster_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>comfort_honda_accord_2008</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>comfort_toyota_camry_2007</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gas_mileage_toyota_camry_2007</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>interior_honda_accord_2008</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>interior_toyota_camry_2007</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>mileage_honda_accord_2008</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>performance_honda_accord_2008</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>quality_toyota_camry_2007</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>seats_honda_accord_2008</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>transmission_toyota_camry_2007</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          filename  \\\n",
       "18       comfort_honda_accord_2008   \n",
       "43       comfort_toyota_camry_2007   \n",
       "1    gas_mileage_toyota_camry_2007   \n",
       "45      interior_honda_accord_2008   \n",
       "22      interior_toyota_camry_2007   \n",
       "35       mileage_honda_accord_2008   \n",
       "47   performance_honda_accord_2008   \n",
       "42       quality_toyota_camry_2007   \n",
       "29         seats_honda_accord_2008   \n",
       "23  transmission_toyota_camry_2007   \n",
       "\n",
       "                                         opinion_text  cluster_label  \n",
       "18                                                ...              3  \n",
       "43                                                ...              3  \n",
       "1                                                 ...              3  \n",
       "45                                                ...              3  \n",
       "22                                                ...              3  \n",
       "35                                                ...              3  \n",
       "47                                                ...              3  \n",
       "42                                                ...              3  \n",
       "29                                                ...              3  \n",
       "23                                                ...              3  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_df[document_df['cluster_label']==3].sort_values(by='filename')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cluster #3은 토요타와 혼다 등의 자동차에 대한 리뷰로 잘 군집화 돼 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>opinion_text</th>\n",
       "      <th>cluster_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>accuracy_garmin_nuvi_255W_gps</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>directions_garmin_nuvi_255W_gps</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>display_garmin_nuvi_255W_gps</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>satellite_garmin_nuvi_255W_gps</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>speed_garmin_nuvi_255W_gps</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>updates_garmin_nuvi_255W_gps</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>voice_garmin_nuvi_255W_gps</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           filename  \\\n",
       "33    accuracy_garmin_nuvi_255W_gps   \n",
       "34  directions_garmin_nuvi_255W_gps   \n",
       "48     display_garmin_nuvi_255W_gps   \n",
       "10   satellite_garmin_nuvi_255W_gps   \n",
       "6        speed_garmin_nuvi_255W_gps   \n",
       "19     updates_garmin_nuvi_255W_gps   \n",
       "5        voice_garmin_nuvi_255W_gps   \n",
       "\n",
       "                                         opinion_text  cluster_label  \n",
       "33                                                ...              4  \n",
       "34                                                ...              4  \n",
       "48                                                ...              4  \n",
       "10                                                ...              4  \n",
       "6                                                 ...              4  \n",
       "19                                                ...              4  \n",
       "5                                                 ...              4  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_df[document_df['cluster_label']==4].sort_values(by='filename')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cluster #4는 주로 차량용 네비게이션으로 군집이 구성돼 있음을 알 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "전반적으로 군집화된 결과를 살펴보면 군집 개수가 약간 많게 설정돼 있어 세분화되어 군집화된 경향이 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>opinion_text</th>\n",
       "      <th>cluster_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>interior_honda_accord_2008</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>interior_toyota_camry_2007</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>transmission_toyota_camry_2007</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>quality_toyota_camry_2007</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>comfort_toyota_camry_2007</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>mileage_honda_accord_2008</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>comfort_honda_accord_2008</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>seats_honda_accord_2008</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gas_mileage_toyota_camry_2007</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>performance_honda_accord_2008</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>service_holiday_inn_london</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>staff_swissotel_chicago</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>price_holiday_inn_london</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>rooms_swissotel_chicago</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>free_bestwestern_hotel_sfo</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>bathroom_bestwestern_hotel_sfo</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>parking_bestwestern_hotel_sfo</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>service_bestwestern_hotel_sfo</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>food_swissotel_chicago</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>location_bestwestern_hotel_sfo</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>service_swissotel_hotel_chicago</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>rooms_bestwestern_hotel_sfo</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>staff_bestwestern_hotel_sfo</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>location_holiday_inn_london</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>room_holiday_inn_london</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>food_holiday_inn_london</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>navigation_amazon_kindle</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>screen_netbook_1005ha</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>speed_windows7</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>eyesight-issues_amazon_kindle</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>price_amazon_kindle</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>fonts_amazon_kindle</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>display_garmin_nuvi_255W_gps</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>directions_garmin_nuvi_255W_gps</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>battery-life_ipod_nano_8gb</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>buttons_amazon_kindle</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>sound_ipod_nano_8gb</td>\n",
       "      <td>headphone jack i got a clear case for it a...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>features_windows7</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>updates_garmin_nuvi_255W_gps</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>performance_netbook_1005ha</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>video_ipod_nano_8gb</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>keyboard_netbook_1005ha</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>battery-life_netbook_1005ha</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>satellite_garmin_nuvi_255W_gps</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>battery-life_amazon_kindle</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>screen_garmin_nuvi_255W_gps</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>size_asus_netbook_1005ha</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>speed_garmin_nuvi_255W_gps</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>voice_garmin_nuvi_255W_gps</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>accuracy_garmin_nuvi_255W_gps</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>screen_ipod_nano_8gb</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           filename  \\\n",
       "45       interior_honda_accord_2008   \n",
       "22       interior_toyota_camry_2007   \n",
       "23   transmission_toyota_camry_2007   \n",
       "42        quality_toyota_camry_2007   \n",
       "43        comfort_toyota_camry_2007   \n",
       "35        mileage_honda_accord_2008   \n",
       "18        comfort_honda_accord_2008   \n",
       "29          seats_honda_accord_2008   \n",
       "1     gas_mileage_toyota_camry_2007   \n",
       "47    performance_honda_accord_2008   \n",
       "27       service_holiday_inn_london   \n",
       "20          staff_swissotel_chicago   \n",
       "28         price_holiday_inn_london   \n",
       "30          rooms_swissotel_chicago   \n",
       "49       free_bestwestern_hotel_sfo   \n",
       "31   bathroom_bestwestern_hotel_sfo   \n",
       "50    parking_bestwestern_hotel_sfo   \n",
       "16    service_bestwestern_hotel_sfo   \n",
       "32           food_swissotel_chicago   \n",
       "39   location_bestwestern_hotel_sfo   \n",
       "13  service_swissotel_hotel_chicago   \n",
       "46      rooms_bestwestern_hotel_sfo   \n",
       "4       staff_bestwestern_hotel_sfo   \n",
       "3       location_holiday_inn_london   \n",
       "2           room_holiday_inn_london   \n",
       "17          food_holiday_inn_london   \n",
       "38         navigation_amazon_kindle   \n",
       "37            screen_netbook_1005ha   \n",
       "40                   speed_windows7   \n",
       "36    eyesight-issues_amazon_kindle   \n",
       "41              price_amazon_kindle   \n",
       "44              fonts_amazon_kindle   \n",
       "48     display_garmin_nuvi_255W_gps   \n",
       "34  directions_garmin_nuvi_255W_gps   \n",
       "0        battery-life_ipod_nano_8gb   \n",
       "26            buttons_amazon_kindle   \n",
       "24              sound_ipod_nano_8gb   \n",
       "21                features_windows7   \n",
       "19     updates_garmin_nuvi_255W_gps   \n",
       "15       performance_netbook_1005ha   \n",
       "14              video_ipod_nano_8gb   \n",
       "12          keyboard_netbook_1005ha   \n",
       "11      battery-life_netbook_1005ha   \n",
       "10   satellite_garmin_nuvi_255W_gps   \n",
       "9        battery-life_amazon_kindle   \n",
       "8       screen_garmin_nuvi_255W_gps   \n",
       "7          size_asus_netbook_1005ha   \n",
       "6        speed_garmin_nuvi_255W_gps   \n",
       "5        voice_garmin_nuvi_255W_gps   \n",
       "33    accuracy_garmin_nuvi_255W_gps   \n",
       "25             screen_ipod_nano_8gb   \n",
       "\n",
       "                                         opinion_text  cluster_label  \n",
       "45                                                ...              0  \n",
       "22                                                ...              0  \n",
       "23                                                ...              0  \n",
       "42                                                ...              0  \n",
       "43                                                ...              0  \n",
       "35                                                ...              0  \n",
       "18                                                ...              0  \n",
       "29                                                ...              0  \n",
       "1                                                 ...              0  \n",
       "47                                                ...              0  \n",
       "27                                                ...              1  \n",
       "20                                                ...              1  \n",
       "28                                                ...              1  \n",
       "30                                                ...              1  \n",
       "49                                                ...              1  \n",
       "31                                                ...              1  \n",
       "50                                                ...              1  \n",
       "16                                                ...              1  \n",
       "32                                                ...              1  \n",
       "39                                                ...              1  \n",
       "13                                                ...              1  \n",
       "46                                                ...              1  \n",
       "4                                                 ...              1  \n",
       "3                                                 ...              1  \n",
       "2                                                 ...              1  \n",
       "17                                                ...              1  \n",
       "38                                                ...              2  \n",
       "37                                                ...              2  \n",
       "40                                                ...              2  \n",
       "36                                                ...              2  \n",
       "41                                                ...              2  \n",
       "44                                                ...              2  \n",
       "48                                                ...              2  \n",
       "34                                                ...              2  \n",
       "0                                                 ...              2  \n",
       "26                                                ...              2  \n",
       "24      headphone jack i got a clear case for it a...              2  \n",
       "21                                                ...              2  \n",
       "19                                                ...              2  \n",
       "15                                                ...              2  \n",
       "14                                                ...              2  \n",
       "12                                                ...              2  \n",
       "11                                                ...              2  \n",
       "10                                                ...              2  \n",
       "9                                                 ...              2  \n",
       "8                                                 ...              2  \n",
       "7                                                 ...              2  \n",
       "6                                                 ...              2  \n",
       "5                                                 ...              2  \n",
       "33                                                ...              2  \n",
       "25                                                ...              2  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 중심 개수를 5개에서 3개로 낮춰서 3개 그룹으로 군집화한 뒤 결과 확인\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# 3개의 집합으로 군집화\n",
    "km_cluster = KMeans(n_clusters=3, max_iter=10000, random_state=0)\n",
    "km_cluster.fit(feature_vect)\n",
    "cluster_label = km_cluster.labels_\n",
    "cluster_centers = km_cluster.cluster_centers_\n",
    "\n",
    "# 소속 군집을 cluster_label 칼럼으로 할당하고 cluster_label 값으로 정렬\n",
    "document_df['cluster_label'] = cluster_label\n",
    "document_df.sort_values(by='cluster_label')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#0은 자동차 리뷰로만, #1은 호텔 리뷰로만, #2는 포터블 전자기기 리뷰로만 군집이 잘 구성됐다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 군집별 핵심 단어 추출하기\n",
    "- Kmeans 객체의 **clusters_centers_ 속성** : 각 군집을 구성하는 단어 피처가 중심(centroid)을 기준으로 얼마나 가깝게 위치해 있는지 제공\n",
    "\t- 배열 값으로 제공되며, 행은 개별 군집, 열은 개별 피처를 의미한다.\n",
    "\t- 각 배열내의 값은 개별 군집 내의 상대 위치를 숫자 값으로 표현한 일종의 좌표 값이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cluster_centers shape: (3, 4611)\n",
      "[[0.         0.00092551 0.         ... 0.         0.         0.        ]\n",
      " [0.         0.00099499 0.00174637 ... 0.         0.00183397 0.00144581]\n",
      " [0.01005322 0.         0.         ... 0.00706287 0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "# 군집 3개로 생성한 KMeans 객체인 km_clsuter에서 cluster_centers_ 속성값 가져오기\n",
    "\n",
    "cluster_centers = km_cluster.cluster_centers_\n",
    "print('cluster_centers shape:', cluster_centers.shape)\n",
    "print(cluster_centers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "군집이 3개 word 피처가 2409개로 구성되어 있다. 각 행의 배열 값은 각 군집 내의 2409개 피처의 위치가 개별 중심과 얼마나 가까운가를 상대 값으로 나타낸 것이다. 0에서 1까지의 값을 가질 수 있으며 1에 가까울수록 중심과 가까운 값을 의미한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 군집별 top n 핵심 단어, 그 단어의 중심 위치 상댓값, 대상 파일명을 반환함\n",
    "def get_cluster_details(cluster_model, cluster_data, feature_names, \n",
    "                        clusters_num, top_n_features=10):\n",
    "    cluster_details = {}\n",
    "    \n",
    "    # cluster_centers array의 값이 큰 순으로 정렬된 인덱스 값을 반환\n",
    "    # 군집 중심점(centroid)별 할당된 word 피처들의 거리값이 큰 순으로 값을 구하기 위함\n",
    "    centroid_feature_ordered_ind = cluster_model.cluster_centers_.argsort()[:, ::-1]\n",
    "    \n",
    "    # 개별 군집별로 반복하면서 핵심 단어, 그 단어의 중심 위치 상댓값, 대상 파일명 입력\n",
    "    for cluster_num in range(clusters_num):\n",
    "        # 개별 군집별 정보를 담을 데이터 초기화\n",
    "        cluster_details[cluster_num] = {}\n",
    "        cluster_details[cluster_num]['cluster'] = cluster_num\n",
    "        \n",
    "        # cluster_centers_.argsort()[:, ::-1]로 구한 인덱스를 이용해 top n 피처 단어를 구함\n",
    "        top_feature_indexes = centroid_feature_ordered_ind[cluster_num, :top_n_features]\n",
    "        top_features = [feature_names[ind] for ind in top_feature_indexes]\n",
    "        \n",
    "        # top_feature_indexes를 이용해 해당 피처 단어의 중심 위치 상댓값 구함\n",
    "        top_feature_values = cluster_model.cluster_centers_[cluster_num, \n",
    "                                                           top_feature_indexes].tolist()\n",
    "        \n",
    "        # cluster_details 딕셔너리 객체에 개별 군집별 핵심단어와 중심위치 상댓값, 해당 파일명 입력\n",
    "        cluster_details[cluster_num]['top_features'] = top_features\n",
    "        cluster_details[cluster_num]['top_features_value'] = top_feature_values\n",
    "        filenames = cluster_data[cluster_data['cluster_label'] == cluster_num]['filename']\n",
    "        filenames = filenames.values.tolist()\n",
    "        \n",
    "        cluster_details[cluster_num]['filenames'] = filenames\n",
    "        \n",
    "    return cluster_details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_cluster_details가 반환하는 cluster_details를 보기 좋게 만들어주는 함수\n",
    "def print_cluster_details(cluster_details):\n",
    "    for cluster_num, cluster_detail in cluster_details.items():\n",
    "        print('####### Cluster {0}'.format(cluster_num))\n",
    "        print('Top features:', cluster_detail['top_features'])\n",
    "        print('Reviews 파일명:', cluster_detail['filenames'][:7])\n",
    "        print('==============================================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-437714b9b25e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mfeatures_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtfidf_vect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_feature_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m cluster_details = get_cluster_details(cluster_model=km_cluster, cluster_data=document_df,\n\u001b[0m\u001b[1;32m      6\u001b[0m                                      feature_names=feature_names, clusters_num=3, top_n_features=10)\n\u001b[1;32m      7\u001b[0m \u001b[0mprint_cluster_details\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcluster_details\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-41-3a68fc93eccf>\u001b[0m in \u001b[0;36mget_cluster_details\u001b[0;34m(cluster_model, cluster_data, feature_names, clusters_num, top_n_features)\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;31m# cluster_centers_.argsort()[:, ::-1]로 구한 인덱스를 이용해 top n 피처 단어를 구함\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mtop_feature_indexes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcentroid_feature_ordered_ind\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcluster_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mtop_n_features\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mtop_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfeature_names\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mind\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mind\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtop_feature_indexes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;31m# top_feature_indexes를 이용해 해당 피처 단어의 중심 위치 상댓값 구함\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-41-3a68fc93eccf>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;31m# cluster_centers_.argsort()[:, ::-1]로 구한 인덱스를 이용해 top n 피처 단어를 구함\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mtop_feature_indexes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcentroid_feature_ordered_ind\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcluster_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mtop_n_features\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mtop_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfeature_names\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mind\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mind\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtop_feature_indexes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;31m# top_feature_indexes를 이용해 해당 피처 단어의 중심 위치 상댓값 구함\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# 위의 두 함수 호출\n",
    "\n",
    "features_names = tfidf_vect.get_feature_names()\n",
    "\n",
    "cluster_details = get_cluster_details(cluster_model=km_cluster, cluster_data=document_df,\n",
    "                                     feature_names=feature_names, clusters_num=3, top_n_features=10)\n",
    "print_cluster_details(cluster_details)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 08. 문서 유사도\n",
    "### 문서 유사도 측정 방법 - 코사인 유사도\n",
    ": 문서와 문서간의 유사도 비교는 일반적으로 **코사인 유사도(Cosine Similarity)**를 사용한다. \n",
    "- 코사인 유사도는 벡터와 벡터 간의 유사도를 비교할 떄 벡터의 크기보다는 **벡터의 상호 방향성이 얼마나 유사한지**에 기반한다. 즉, 코사인 유사도는 **두 벡터 사이의 사잇각을 구해서 얼마나 유사한지 수치로 적용한 것**이다. \n",
    "\n",
    "###  두 벡터 사잇각\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![python image2](https://wikimedia.org/api/rest_v1/media/math/render/svg/2a8c50526e2cc7aa837477be87eff1ea703f9dec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "유사도는 다음과 같이 두 벡터의 내적을 총 벡터 크기의 합으로 나눈 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "코사인 유사도가 문서의 유사도 비교에 가장 많이 사용되는 이유는 \n",
    "- 먼저 문서를 피처 벡터화 변환하면 차원이 매우 많은 희소 행렬이 되기 쉽다.\n",
    "\t- 이러한 희소 행렬 기반에서 문서와 문서 벡터간의 크기에 기반한 유사도 지표는 정확도가 떨어지기 쉽다.\n",
    "- 문서가 매우 긴 경우 단어의 빈도수도 더 많을 것이기 때문에 이러한 빈도수에만 기반해서는 공장한 비교를 할 수 없다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 간단한 문서에 대해 서로간의 문서 유사도를 코사인 유사도 기반으로 구하기\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# 두개의 넘파이 배열에 대한 코사인 유사도를 구하는 함수\n",
    "def cos_similarity(v1, v2):\n",
    "    dot_product = np.dot(v1, v2)\n",
    "    l2_norm = (np.sqrt(sum(np.square(v1)))) * np.sqrt(sum(np.square(v2)))\n",
    "    similarity = dot_product / l2_norm\n",
    "    \n",
    "    return similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 18)\n"
     ]
    }
   ],
   "source": [
    "# doc_list로 정의된 3개의 간단한 문서의 유사도를 비교하기 위해 TF-IDF로 벡터화된 행렬로 변환\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "doc_list = ['if you take the blue pill, the story ends' ,\n",
    "            'if you take the red pill, you stay in Wonderland',\n",
    "            'if you take the red pill, I show you how deep the rabbit hole goes']\n",
    "\n",
    "tfidf_vect_simple = TfidfVectorizer()\n",
    "feature_vect_simple = tfidf_vect_simple.fit_transform(doc_list)\n",
    "print(feature_vect_simple.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문장 1, 문장 2 Cosine 유사도: 0.402\n"
     ]
    }
   ],
   "source": [
    "# TFidfVectorizer로 transform()한 결과는 희소 행렬이므로 밀집 행렬로 변환\n",
    "feature_vect_dense = feature_vect_simple.todense()\n",
    "\n",
    "# 첫 번째 문장과 두 번째 문장의 피처 벡터 추출\n",
    "vect1 = np.array(feature_vect_dense[0]).reshape(-1, )\n",
    "vect2 = np.array(feature_vect_dense[1]).reshape(-1, )\n",
    "\n",
    "# 첫 번째 문장과 두 번째 문장의 피처 벡터로 두 개 문장의 코사인 유사도 추출\n",
    "similarity_simple = cos_similarity(vect1, vect2)\n",
    "print('문장 1, 문장 2 Cosine 유사도: {0:.3f}'.format(similarity_simple))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문장 1, 문장 3 Cosine 유사도: 0.404\n",
      "문장 2, 문장 3 Cosine 유사도: 0.456\n"
     ]
    }
   ],
   "source": [
    "# 첫 번째 문장과 세 번째 문장 유사도 측정\n",
    "vect1 = np.array(feature_vect_dense[0]).reshape(-1, )\n",
    "vect3 = np.array(feature_vect_dense[2]).reshape(-1, )\n",
    "similarity_simple = cos_similarity(vect1, vect3)\n",
    "print('문장 1, 문장 3 Cosine 유사도: {0:.3f}'.format(similarity_simple))\n",
    "\n",
    "# 두 번째 문장과 세 번째 문장의 유사도 측정\n",
    "vect2 = np.array(feature_vect_dense[1]).reshape(-1, )\n",
    "vect3 = np.array(feature_vect_dense[2]).reshape(-1, )\n",
    "similarity_simple = cos_similarity(vect2, vect3)\n",
    "print('문장 2, 문장 3 Cosine 유사도: {0:.3f}'.format(similarity_simple))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **sklearn.metrics.pairwise.cosine_similarity API** : 사이킷런의 코사인 유사도 측정을 위한 API\n",
    "\t- 첫 번째 파라미터는 비교 기준이 되는 문서의 피처 행렬, 두번째 파라미터는 비교되는 문서의 피처 행렬을 입력해준다\n",
    "    - 희소 행렬, 밀집행렬 모두가 가능하며, 행렬 또는 배열 모두 가능하다.\n",
    "    - 쌍으로(pair) 코사인 유사도 값을 제공할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         0.40207758 0.40425045]]\n"
     ]
    }
   ],
   "source": [
    "# 첫번째 문서와 비교해 바로 자신 문서인 첫번째, 그리고 두번째 세번째 문서 유사도 측정하기\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "similarity_simple_pair = cosine_similarity(feature_vect_simple[0], feature_vect_simple)\n",
    "print(similarity_simple_pair)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1은 비교 기준인 첫 번째 문서 자신에 대한 유사도 측정이다. 0.40207758은 첫 번째와 두 번째 문서의 유사도, 0.40425045는 첫 번째 문서와 세 번째 문서의 유사도 값이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.40207758 0.40425045]]\n"
     ]
    }
   ],
   "source": [
    "# 1제거\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "similarity_simple_pair = cosine_similarity(feature_vect_simple[0], feature_vect_simple[1:])\n",
    "print(similarity_simple_pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         0.40207758 0.40425045]\n",
      " [0.40207758 1.         0.45647296]\n",
      " [0.40425045 0.45647296 1.        ]]\n",
      "shape: (3, 3)\n"
     ]
    }
   ],
   "source": [
    "# 모든 개별 문서에 쌍으로 코사인 유사도 값 계산하유\n",
    "\n",
    "similarity_simple_pair = cosine_similarity(feature_vect_simple, feature_vect_simple)\n",
    "print(similarity_simple_pair)\n",
    "print('shape:', similarity_simple_pair.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Opinion Review 데이터 세트를 이용한 문서 유사도 측정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:383: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ha', 'le', 'u', 'wa'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob, os\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "path = '/Users/wizdom/Desktop/data_analysis/파이썬 머신러닝 완벽가이드/실습 데이터/OpinosisDataset1.0/topics'\n",
    "all_files = glob.glob(os.path.join(path, \"*.data\"))\n",
    "filename_list = []\n",
    "opinion_text = []\n",
    "\n",
    "for file_ in all_files:\n",
    "    df = pd.read_table(file_,index_col=None, header=0,encoding='latin1')\n",
    "    filename_ = file_.split('/')[-1]\n",
    "    filename = filename_.split('.')[0]\n",
    "    filename_list.append(filename)\n",
    "    opinion_text.append(df.to_string())\n",
    "\n",
    "document_df = pd.DataFrame({'filename':filename_list, 'opinion_text':opinion_text})\n",
    "\n",
    "tfidf_vect = TfidfVectorizer(tokenizer=LemNormalize, stop_words='english' , \\\n",
    "                             ngram_range=(1,2), min_df=0.05, max_df=0.85 )\n",
    "feature_vect = tfidf_vect.fit_transform(document_df['opinion_text'])\n",
    "\n",
    "km_cluster = KMeans(n_clusters=3, max_iter=10000, random_state=0)\n",
    "km_cluster.fit(feature_vect)\n",
    "cluster_label = km_cluster.labels_\n",
    "cluster_centers = km_cluster.cluster_centers_\n",
    "document_df['cluster_label'] = cluster_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "호텔로 클러스터링 된 문서들의 DataFrame Index: Int64Index([2, 3, 4, 13, 16, 17, 20, 27, 28, 30, 31, 32, 39, 46, 49, 50], dtype='int64')\n",
      "##### 비교 기준 문서명  room_holiday_inn_london  와 타 문서 유사도######\n",
      "[[1.         0.19917258 0.22235374 0.37631406 0.26026786 0.15836737\n",
      "  0.19544761 0.40020673 0.31124876 0.77312013 0.51442299 0.15026112\n",
      "  0.16717527 0.81484367 0.11154184 0.10831277]]\n"
     ]
    }
   ],
   "source": [
    "# 호텔을 주제로 군집화된 데이터 먼저 추출하고 이 데이터에 해당하는 TfidfVectorizer의 데이터 추출\n",
    "\n",
    "# cluster_label=1인 데이터는 호텔로 클러스터링된 데이터임. DataFrame에서 해당 Index를 추출\n",
    "hotel_indexes = document_df[document_df['cluster_label']==1].index\n",
    "print('호텔로 클러스터링 된 문서들의 DataFrame Index:', hotel_indexes)\n",
    "\n",
    "# 호텔로 클러스터링된 데이터 중 첫번째 문서를 추출하여 파일명 표시.  \n",
    "comparison_docname = document_df.iloc[hotel_indexes[0]]['filename']\n",
    "print('##### 비교 기준 문서명 ',comparison_docname,' 와 타 문서 유사도######')\n",
    "\n",
    "''' document_df에서 추출한 Index 객체를 feature_vect로 입력하여 호텔 클러스터링된 feature_vect 추출 \n",
    "이를 이용하여 호텔로 클러스터링된 문서 중 첫번째 문서와 다른 문서간의 코사인 유사도 측정.'''\n",
    "similarity_pair = cosine_similarity(feature_vect[hotel_indexes[0]] , feature_vect[hotel_indexes])\n",
    "print(similarity_pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'room_holiday_inn_london')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhYAAAEWCAYAAAA6r95OAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAABVHklEQVR4nO2debyd09m/r69Qs8RURRFCq4YkCIqEqLSUIqYqSkXxUqW8NfStoalWS/lVayjFS6gYaoiaaqihiSliyEQNLfpSWvMQY/D9/bHWznmys8eTvc85Se7r8zmf7L2e9aznXs/W7vtZa+11yTZBEARBEAStYL7uDiAIgiAIgrmHSCyCIAiCIGgZkVgEQRAEQdAyIrEIgiAIgqBlRGIRBEEQBEHLiMQiCIIgCIKWEYlFEATzNJKekzSsk+da0ur59bmSjm+kbjuQNE3Sam1sf19J97Sp7U5/BkHPY/7uDiAIgmBuwPZB3Xz9xbrz+kFQIkYsgiDoNiTFw00QzGVEYhEEQZeSh72PkTQZeFfSDpIek/SmpLslfalQ90u57M1cZ4fCsVGSfifpz3ka4F5Jn5P0G0lvSHpC0noNhjVQ0mRJb0m6UtJChescIOnvkl6XdL2kFar0a5SknxfeHyXpJUkvStqvrO52kh6V9Lak5yWNLBy7SdKhZfUnSxpeqwNl0zKjJJ2d23pH0nhJ/crqHiTp6Xyvzpakxm7VjDY2lTQh37MJkjYtHLtb0s/yZ/KOpNskLVM4vrekf0p6TdKxZe0umD/DF/PfbyQtmI8NlfSCpB9Kejnf3xHNxB20n0gsgiDoDvYAtgM2Ai4HDgeWBW4GbpD0GUkLADcAtwGfBQ4FRkv6YqGdbwLHAcsAHwL3A4/k91cDv24wnm8C2wCrAv2BfQEkfQX4ZT6+PPBP4Ip6jUnaBjgS+CqwBlC+fuBdYB+gD+k+HFxIHC4Gvl1oawCwIuneNMMewE+BJYG/AyeVHf8GsCEwgNS/rRttWNJSwE3AGcDSpPt8k6SlC9X2BEaQPrvPkO4HktYCzgH2BlbI53++cN6xwJeBgTm2jUifcYnPAb1J9+S7wNmSlmw09qD9RGIRBEF3cIbt54EdgJts3257OnAasDCwKenLZTHgZNsf2b4TuJH0hVlijO2HbX8AjAE+sH2J7U+AK4FGRyzOsP2i7ddJyczAXL4XcKHtR2x/CPwPsImkvnXa+yZwke2ptt8FRhYP2r7b9hTbn9qeTEqutsiH/wSsIWmN/H5v4ErbHzXYlxLX2n7Q9sfA6EKfSpxs+03b/wfcVeF4LbYDnrb9B9sf274ceALYvlDnIttP2X4f+GOh/V2BG22Pzff0eODTwnl7ASfaftn2K6TkaO/C8en5+HTbNwPTgGKyGXQzkVgEQdAdPJ//XYE0CgCA7U/zsRXzsedzWYl/5mMl/lN4/X6F940uaPx34fV7hfPK45sGvFYWQyVWoKOPFNsAkLSxpLskvSLpLeAg0igL+cv2j8C3Jc1HSqT+0GA/ilTrU6PHazHTfcmUfza17umMe5MTr9dqtP3PXFbitZwsdTb2oM1EYhEEQXdQ0iq/CKxSKszz/CsB/8rHVspfriVWzse6ivL4FiUN3deL4SVSP0qsXHb8MuB6YCXbvYFzgeIah4tJT+5bAe/Zvr9T0bePme5LptHPZqZ7I2kR0j2t1vbKuSyYQ4jEIgiC7uSPwHaStsprKn5IWitxHzCetBbhaEkLSBpKGmqvu8ahhVwGjJA0MC8g/AUw3vZzdc77I7CvpLXyF+dPyo4vDrxu+wNJG5HWI8wgJxKfAv+Pzo1WtJubgS9I2lPS/JJ2B9YiTVXV42rgG5IGS/oMcCIzfxddDhwnadm84PME4NIWxx+0kUgsgiDoNmw/SVqoeCbwKilx2D6vqfiItAbj6/nY74B9bD/RhfHdQVoDcA3pSbsf8K0Gzvsz8BvgTtLCyTvLqnwPOFHSO6Qvzj9WaOYSYF164Jeq7ddIiz9/SJrGOBr4hu1XGzj3MeAQUtL2EvAG8EKhys+Bh4DJwBTSYtyfE8wxyHb9WkEQBEGXImkf4EDbg7s7liBohhixCIIg6GHk6ZPvAed1dyxB0CyRWARBMFcjaeW8gValv/JFld2OpK2BV0i/cLmsUD6kWj9aeO1zq1zj3FZdI5j7iamQIAiCIAhaRoxYBEEQBEHQMkIAFMzzLLPMMu7bt293hxEEQTBH8fDDD79qe9ny8kgsgnmevn378tBDD3V3GEEQBHMUksp3XwUisQgCPn7ldV45p8dtFRAEQdBWlj342/UrdYJYYxEEQRAEQcuIxCIIgiAIgpYRiUWDSNpX0lktameF+jU71fZASdu2o+2y6zT1u3lJwyWt1UC9kZKObLLtBSX9RdLE7CsIgiAIupE5JrFQYo6Jtwb7MrMCuJUMBJpKLCR1xTqb4SRBUTtYD1jA9kDbV7bpGkEQBEGD9Ogvakl9Jf1N0u9IIpr/lTRV0pTS02lOOE6tUD5U0l8l/VHSU5JOlrSXpAdzvX653m753EmSxtYJaSVJt0h6UtIMW6Gkb+d2J0r6vaRe+W9UIa4jJO0KDAJG57pbSLo2t7GjpPclfUbSQpKeyeX98jUfljRO0pqV4i5YAncvPb1LWlTShZImSHpU0o753H0lXSXpBuC2/P7afJ2nJf2qgc/mpHztByQtl8tWkXSHpMn535UlbUoSSZ2a4+pXrU8NXPMwSY/n9q+Q9FmSoGlgoe2tcl+n5L4v2EjbQRAEQWuYE34V8kVgBHAHcBAwAFgGmJATgU1JT+rl5eSyLwGvA88AF9jeSNIPgEOBw0lmwa1t/0tSnzqxbASsA7yXr3MTSeu8O7CZ7ek5CdoLeAxY0fY6AJL62H5T0veBI20/lEcLRuW2hwBTgQ1Jn8v4XH4ecJDtpyVtTDI8fqU8btsfSToBGGT7+/mavwDutL1f7tuDkv6S290E6G/7dUn75nu4HklZ/aSkM20/X+U+LAo8YPvYnIQcQLIPngVcYvtiSfsBZ9geLul64EbbV+e47qjSp3r8CFjV9oeF+7l/vp/fkLQQcDewle2nJF0CHEyyTM6EpAOBAwE+v9TSDVw6CIIgaIQePWKR+aftB4DBwOW2P7H9H+CvpC/hauUAE2y/ZPtD4B/Abbl8CtA3v74XGCXpAKBXnVhut/2a7feBa/O1twI2ICUaE/P71UiJzGqSzpS0DfB2eWO2Pwb+LulLpKTl18DmpCRjnKTFSInTVbnt3wPLNxH314Af5XPvBhYCSm6E222/Xqh7h+23bH8APA6sUuM+fATcmF8/TMe93IQOt8EfSPdnJur0qR6TSaM93wY+rnD8i8Cztp/K7y8m3c9ZsH2e7UG2By292BINXj4IgiCox5wwYvFu/ldVjlcrh/T0XeLTwvtPyX23fVB+at4OmChpoO3XqrRXLlZxvv7Ftv9nlsCkAcDWwCHAN4H9KrQ5Dvg6MB34C2kEoxdwJCnxe9P2wFkCqRB3hbYF7GL7ybK4NqbjvpYo3qtPqP3fxnR3SGZq1a0koqnapwbYjpQo7AAcL2ntsuO1/lsIgiAIuoA5YcSixFjS+oFekpYlfcE8WKO8IST1sz3e9gnAq8BKNap/VdJSkhYmLUi8lzRFs2ue7ycfX0XSMsB8tq8BjgfWz228Ayxe1q/DgfttvwIsDawJPGb7beBZSbvltpWTlWpxl7d9K3CoJOVz1mv0vnSS+4Bv5dd7Affk1zPiqtWnWigt3F3J9l3A0UAfYLGyak8AfSWtnt/vTRrBCoIgCLqIOWHEosQY0lD7JNKT8NG2/y2pWnlDCwJJiwrXID3t3pHbqcY9pCH+1YHLbD8EIOk40iLI+UgjD4cA7wMXqeOXLKURjVHAuZLez3GPB5YjJRiQhvtfLowI7AWck6+xAHBFjrFS3P9Hx9THL4GfkdYXTM7JxXPANxq8L53hMOBCSUeRtM8jcvkVwPmSDgN2rdGnWvQCLpXUm9Tn0/MaixkVbH8gaQRpmmV+YAIQuucgCIIuJLTpwTzPoEGDHK6QIAiC5pD0sO1B5eVz0lRIEARBEAQ9nDlpKqRLkLQ1cEpZ8bO2d+qOeLoTSeOB8n0g9rY9pc3XPRvYrKz4t7Yvaud1gyAIgtknpkKCeZ4BKy/nPx+zV3eHEQRB0DArHPLr7g4hpkKCIAiCIGg/kVgEQRAEQdAyIrEIgiAIgqBlRGIxByPp5gb8Jo221U61+VBJN1Y5dkEj1w2CIAjmDCKxYM5Vstve1vabLWpuOO1Tm1fF9v62H+/q6wZBEATtYY77Mm0V6kFKdklrq0O7PlnSGpKOzjtVIul0SXfm11tJujS/fk7SMkp69JvydaYW4jxZHZrx03JZu9Xmq0v6S47lkdK9ABaTdLWkJySNLmwzfrekQfn1NvmcSUoGVCRtJOk+JRX6fZK+mMsXyfd/sqQrJY0vtLNH/hymSir/6XApzgMlPSTpodemvd9I14IgCIIGmNf3segpSvaDSPs0jJb0GdL21WOBHwJnAIOABSUtQDKGjis7fxvgRdvbAUjqLWkpYCdgTdsuXL/davPRwMm2xyhpzOcjeUzWA9YGXiQ5VjajwyWCkuflfGBz28/m+CH5Pza3/bGkYcAvgF2A7wFv2O4vaR1gYm5nBdI+JBsAb5C2Wh9u+7pikLbPIynpGbDycvGb6yAIghYxz45YZHqKkv1+4MeSjgFWyVr2h4ENJC1OMo/eT0owhjBrYjEFGCbpFElDbL9F0rR/AFwgaWfgvVy3bWrzHOuKtsdAcnfYLl33Qdsv2P6UlAT0LTv9y8BY28/mc0tK9945jqnA6aTkhBz3FbnuVJJjBdLnc7ftV7KWfjRV1OlBEARB65nXE4u2K9mB40hP7BMlLV2pIduXkaYi3gdulfQV29NJ0rARJGvoOGBLoB/wt7LznyI9oU8BfinphPyluhFwDWn9xC1V+lFTbV74+1KV84s0er8qqdZVJZafAXfZXgfYHliozrVCnR4EQdCNzOuJRYluVbJLWg14xvYZwPVA/0JcR+Z/x5GmTCYWzKel81cA3rN9KXAasH4edeht+2bStMzAXL1tavN83guShufzFpS0SL3zMvcDW0haNZ9bmgrpDfwrv963UP8e4Ju57lrAurl8fG5nGUm9gD0IdXoQBEGXEYlFYgxpKH0ScCdZvV6jvFFOLS0iJCUH1dTguwNT87TDmsAluXwcaQri/jwV8wGzToNA+lJ9MJ9/LPBzUpJwo6TJpC/WI3Ldw4ARuXxv4Ae5/ArgqLxIsh8p6fiupEnAY8CODfZ5b+Cw3P59wOcaOcn2K8CBwLX5mlfmQ78ijcLcy8zTSb8Dls3XOYb0Ob1l+yWSov4u0v1+xPafGow9CIIgmE3CFRLMkeTRiAVsf5AToTuAL9j+qNm2QpseBEHQPKriCpnXfxUSzLksAtyVfykj4ODOJBVBEARBa4nEogvRXKRkVzerzW2/Q/qVTBAEQdCDiKmQYJ7nS6v08YXHzvKr2yAIMpscWHFH/mAep9pUSCzeDIIgCIKgZURiEQRBEARBy2hbYqHk4pjaRP19834MpffPSVqmPdF1DknTWtDGQEnbtiKeKu3/uF1tF64xStKuTdTvK2nPBus1/N9M4bzDlLwvo5s9NwiCIGgtPWnEYl9ghXqVikiaExefDgTallgATScW+aeb7aQvUDexmA2+B2xre682XiMIgiBogHYnFvNLujgbKK/ORsoTJE3I5snz8q6Ou5JW+I9WsmsunM8/VMl2OUXZrilpZD7vNuASVbB15nrVykdJOkfSXZKekbSFpAvzE++oeh2S9P9yTHfk3ThRFROoyuymSoKxE0m7eU6UtHvuW598H16TtE8+9w+Shint+nlqvmeTJf1XPr58bnNivsYQSScDC+ey0bnet9VhTv19KYmQNE3SiZLGA5vk9yflWB+QtFydW7G5km30mdLoRe7DLDZY4GRgSI7hiGp9auDeV7LAngusBlyf215K0nX5+AOS+tdrNwiCIGgd7U4svgicZ7s/SYr1PeAs2xtm98PCwDeyUfMhYK/spSh5rF+1vT5wDmlr6xIbADva3pMOW2d/knDqjFynWjnAkiRT5xHADXTIrdaVNLBGfxYl7eS4Pmk3y5/k8vOAQ21vkOP8XS4v2U0HADvkfRZOAK7M/bySDtPn2iRL6pB87peBB4DvknaU3JAk2DpAadvrPYFbbQ8kmVYn2v4R8H5uey9JXyLt6rlZrvcJaUfNUl+m2t7Y9j35/QM51rHAATXuA6QdQQcD3yAlDgA702GDHUbaeXR54EfAuBzX6TX6VI+SBXYgKRF9IftYXgS2zG3/FHg0f+4/pmMX05lQQZv+xrTY/iIIgqBVtDuxeN72vfn1paQvoi0ljZc0hfTlvnbVs+Ha/O/DzGzDvL6QfFSzddayeN6QfRtTgP/YnpKtm48xq3WzyKd0bDV9KTBYtU2gjdhNx5EcJJuTEqh1Ja0IvG57GvA1YJ/c9nhgaWANYAJpa+6RwLp5X4dytiIlYRPy+VuRnu4hJRnXFOp+BJR+U1Z+vytxne1PbT8OlEY3atlgi1TrUz0qWWDLGUz6vLF9J7C0pN7llWyfZ3uQ7UFLLvaZBi4dBEEQNEK71yiUb5Jh0tP8INvP5y/FhWY5q4OSEbPchvluhbrVrlmpvGgiLbeUNnNPTMEEOstB+yBJGwPbkeyms9QhjQ4cAqxM8nzsBOxKhxNEpNGQW8tPlLR5bvsPkk61Xf50LuBi2/9T4bof2P6k8H56QW5WyT5aTvG+qezfelTsk6S+tU6yfVmeutmOZIHdPycP5W3PcmqDcQVBEASzSbtHLFaWtEl+vQcdJs1X85N+8ZcFM+yaTVLN1lmtfHaYj46Y9wTuqWUCVWW76Uz9tP08sAywhu1ncpxH0pFY3AocrLR1NZK+IGlRSasAL9s+H/hfYP1cf3qpLsmfsaukz+Zzl8rntYtqNtjyz7Zin+o1ruoW2PIY9sr1h5Km097udI+CIAiCpmj3iMXfgO9I+j3wNGmof0nSFMRzpOH8EqOAcyW9T5rGaJTDgAslHQW8AoyoUz47vAusLelh4C3S+gVIX2TnSDoOWIBkCp1EWmOwBukp+o5c9n/Aj/I0wC/zOovxdEyVjAN+SUcidAFpWuIRScp9GQ4MJdlIpwPTgH1y/fOAyZIeyessjgNukzQfMJ00OvLPFtyLSowhfXaTSKMER9v+t6TXgI+VrKWjgN9W6VM9dge+nfv8b9JC2HJGAhcpWU/fA74zG/0JgiAImiS29A7mecJuGgRB0DyKLb2DIAiCIGg3c+IGU20nLxBcsKx4b9tTuiOe7kLSscBuZcVX2T6pzdedayywQRAE8xoxFRLM8/Tr29un/KSZZT1B0Hl2HXFLd4cQBC0hpkKCIAiCIGg7kVgEQRAEQdAyIrEIgiAIgqBlRGJRhSzoGtaitoZKurF+zZnOuVvSoPz6Zkl9KtQZKenIWU7uJK3sc6HN2VbN53aavodBEARB1zNP/ypE0vy2P650LO+W2SOw3U7NevE6PabPQRAEwZzJXDFikbe4vklJ+T1VSUe+gaS/KqnMb82WzdJIwC8k/RU4VtJzeVdKlLTuz0taQEmvXtKBb6ikCJ+kpO1eXM2rvxdTUsc/IWl03nESSVtJelRJM36hpPKfuZJjXCa/PlbSk5L+QrLHluockGOZJOma3JfFJT1b2Dp7idzWAuXXyMeLfX5O0k9VWVt/Yb6Pz0g6rMHPSKqgVM8jEXdXuTfb5LJ7SObUUlsV1ejNxKaC3fTtsJsGQRC0jLkisQC2AV60PSDr2G8BzgR2zSrzC4Hi3gt9bG9h+6ek7ae3yOXbk1Tk00sVJX2GZDT9QVaKDwPep3n193rA4cBaJMPoZpIWIm1xvbvtdUkjSAdXa0DSBiT/yXqkL9qiOfTarKMfQNpK/bvZeHo3SdpFPveaYv/qUE1bvyawNbAR8JNqiUoZ1ZTqUP3enE/6TIYAnyu0VUuN3lBsRbvpEmE3DYIgaBlzS2IxBRgm6RRJQ0iyr3WA25WcHMcBny/Uv7Lsdcn58a2yY5BGBV6yPQHA9tt5+qRZ9feDtl/IevaJJFfGF0kbPz2V61xMEndVYwgwxvZ7Wax1feHYOpLGKeno96JDR38BHZ6UEcBFNdovp5q2/ibbH9p+FXiZDm16LWop1SvdmzVJ9+bpbF29tKytamr0zsQWBEEQtIi5Yo2F7afy0/y2JIHX7cBjtqvtelTUrl8P/FLSUsAGQCUNd6VdxKrqzKtQ1IyXtOSNasaLVNvRbBQw3PYkSfuSJGXYvldSX0lbAL1sT23iWtW09ZX6Uo9afa3WXrW+1lKjdya2IAiCoEXMFSMWklYA3rN9KXAasDGwrLKyPa+ZWLvSubankdTevwVutP1JWZUngBUkbZjbWlzS/HRS/V2h7b6SVs/v9yY9yVdjLLCTpIUlLU6aJiixOPBSjmevsvMuAS6nudGKVlNNqV6NJ4BVJfXL7/coayvU6EEQBD2QueVpbl3SnP2nJDX4wcDHwBl5iHx+4DfAY1XOvxK4ivyUX8T2R3mh4ZmSFiatrxhGdZ15w9j+QNII4KqcrEwAzq1R/xFJV5KmC/5JUqyXOJ40JfNP0tTQ4oVjo4Gfk5KL7qKaUn3NSpXzvTkQuEnSqySN/Dr58EhCjR4EQdAjCVfIPED+pceOtvfu7lh6IqFND4IgaB5VcYXMLSMWQRUknQl8nbT+JAiCIAjaSiQWLUTSuuRfKxT40PbG3REPgO1Dy8sknQ1sVlb8W9udWoMhaWngjgqHtrL9WmfaDIIgCOZMYiokmOdZebXePvJnX+7uMIK5gMP2avRHYkEw51NtKmSu+FVIEARBEAQ9g0gsgiAIgiBoGXN0YqE22Dg7EcMFktZqUVtDJW3aQL19JZ1V4/gM50eD1+0rac8G6zWzwVbpvBmuk7LyHST9qNn2giAIgp5Lj1+8qR5uILW9fwubGwpMA+5rYZuN0BfYE7isKy9q+3pm3pY8CIIgmMPpshEL9XADqaTlJY2VNDHHN0TSNyX9Oh//gaRn8ut+SsbNUqyD8rVGqcPeeUQ+fpikx/P1r8hls9g5JfUFDgKOyDEMkbSskql0Qv4r/yVHLTbP9+OZwj2SKhhGgZOBIfm6RzRz38ruYS9Jp+W2J0sq/iLlUM1qSp0x8iJpOUlj8uc3qTRyk+/Tw5IeU9owq3St70p6Kt//8wvtrCLpjnz9OySt3MQ9C4IgCGaTrhyxKBlItwNQ2hHzz6SNm17JX3InAfvl+n1sb5Hrrk8ykN5FwUCqZNcuGkh3tz1B0hKUGUiVdOT3SrrN9rMV4tszt3uSpF7AIsDTwFH5+BDgNUkrkiRY48rOHwismO2qSOqTy38ErGr7w0JZyc45XNJXgEtsD5R0LjDN9mm5jcuA023fk78gbwW+1MjNBpbPca5JGhW4mpkNo8sAEySNzTEeafsb+boHVrpvVHd3lDgQWBVYz/bHSv6VEq/aXl/S90im1PKRnjOAv9reKd//xXL5frZfV9r1dIKka4AFSTuNrg+8Q/K7TMr1zyLdz4sl7ZfbHV4eaO7jgQBLLr1QnW4FQRAEjdKVicUU4DRJpwA3Am/QYSAF6AW8VKhfyUB6F8lA+ruytmcxkAJI+hrQXx3rDXqTDKSVEosJwIVKro3rbE8E3pG0mJKXYyXSVMHmpCTj2rLznwFWU9qQ6ibgtlw+GRgt6Trgulw2GNglx3qnpKKds8gwYK1SAgUskWNphOuyLfRxSSXD5wzDKPAfpRGhDYFyz0a1+/YUtRkGnFuaurL9euFY0ZS6c4VzvwLsk8/7BHgrlx8maaf8eqUcx+dIScjrAJKuAr6Q62xSaP8PwK8qBWr7POA8SD83rdOvIAiCoEG6LLHo6QZS22MlbQ5sB/xB0qm2LwHuJ+nGnySNUuxH+vL6Ydn5b0gaAGwNHAJ8M9fdjpSM7AAcryRDq2XnLDIfsInt92fqlBqSohYtnyr7tx4V71uerql3XrUv6Wqm1OqNJcHYMNI9eE/S3cBCNGeFjaQhCIKgC+nKNRY92kAqaRXgZdvnA/9LGmaHZNI8Mv/7KLAlaTfNt8rOXwaYz/Y15GF6pXUhK9m+Czga6EMa4q9m53yHmeVhtwHfL1xjYKXYm6CaYbT8up01t94GHJTvPWVTIfW4gySPK63VWII0UvJGTirWBEq7WD0IbCFpyXytXQrt3Eca1YJ0j+9pIoYgCIJgNunKqZCebiAdChwlaTrplxn75PJxpCH4sbY/kfQ8KZEpZ0WScbOUrP0PaXrn0tw/kdZLvClpJJXtnDcAV0vaETgUOAw4O9ebn5QYHFQl/kaoZhh9DfhY0iRgFCmB60vz5tYLSFMSk/N9PJ+05qERfgCcJ+m7pFGNg4FbSInKZNKI0QMAtv8l6Rckm+uLwOMUpk5IU1pH5bhHNHj9IAiCoAXElt7BHImkxWxPyyMWY4ALbY/pTFthNw2CIGgexZbewVzGSEkTgamkxbjXdWs0QRAEATAHbJDVatQDDaSdRdKxwG5lxVfZPqnN190aOKWs+FnbO1Wq3w5sH9lV1wqCIAgaJ6ZCgnmeZVbv7e1PrfbjpGBu4aKdbunuEIJgriKmQoIgCIIgaDuRWARBEARB0DIisQiCIAiCoGVEYlEDtVDLrqREv7HJc+6WNCi/vrngGinWGSmpZQsZW9nnQpvTWtRO0/cwCIIg6FrmuV+FNIqkXj1By17C9rZddJ0e0+cgCIJgzmOeHLGQ1FfSE5IuVtJrX62kY39O0glKSvTd1EIte2axfK0nJI3Ou1oiaStJjyopxS9UMoqWx/xc3jYcScdKelLSX0gCtlKdA3Isk5R064vkOJ8tbM+9RG5rgSr3ptjn5yT9VLPqzkfmOO9W0rIf1uB9lypo2/NIxN1V7s02ueweCvIyVVDPNxObpAMlPSTpoQ/e/qiR8IMgCIIGmCcTi8wXgfNs9yfZPb+Xyz+wPdj2FaWK6tCy/8D2ANJ24TNp2UmW0AMkrVrjmusBhwNrAasBm0laiLSN9u621yWNIh1crQElkdu3cls75+uWuNb2hjnGvwHftf0OcDdJhkY+9xrb02vEWeRV2+sD55CcKSXWJAnXNgJ+Ui1RKaOobR9G2uJ9+Xys2r05H9ieZJT9XKGtknq+P/Bj4JJmYrN9nu1BtgcttMRnGgg9CIIgaIR5ObF43va9+fWlJKU4zKxrLzGLlj2rwb8G7JN3gBwPLE3SelfjQdsvZJ35RJKP44ukzaVKSvKLSXKwagwBxth+L4vLri8cW0fSOElTSAKuktTtAjqcGSOAi2q0X05Rd963UH6T7Q9tvwq8DCxXfmIFZmjbbf8HKGnbofK9WZN0b5522nDl0rK2/gBJPQ8U1fOdiS0IgiBoAfPyGovyncFK798tr0gLtOyZosq8pA9vRgFeotquZqOA4bYnSdqXLGyzfW+e/tkC6GV7ahPXqqY7r9SXetTqa7X2qvW1lnq+M7EFQRAELWBeHrFYWVnZDuxBbb32bGvZ67TdV9Lq+f3epCf5aowFdpK0sKTFSdMEJRYHXsrx7FV23iXA5TQ3WtFqqmnbq/EEsKqkfvn9HmVtVVLPB0EQBN3IvJxY/A34jpKSeynSGoKK2P4IKGnZJwG3AwuRphgeJ+nFpwK/p8mnY9sfkKYnrspTGJ8C59ao/whpumYicA1J617ieNKUzO3MqnYfDSxJSi66izHAZJK2/U6ytr1a5XxvDgRuyos3/1k4PBIYlD+/k+lQzwdBEATdyDzpCpHUF7jR9jrdHUtXkX/psaPtvbs7lp5GaNODIAiaR1VcITH3PA8g6Uzg60CX7IURBEEQzLvMk4mF7eeAtoxWqAdq2W0fWl4m6Wxgs7Li39ru1BoMSUsDd1Q4tJXt1zrTZhAEQTDnMU9OhQRBkd6rr+jNTq26dUjQTdy803HdHUIQBDWoNhXS0OLN/AuEL9avGQRBEATBvEzdxELS9qRfINyS3w+UdH3Nk4IgCIIgmCdpZMRiJGlr5DcBbE9k5h0YeyzqZjtplXaGS1qrFTFVaLuvpD3b0XbZdWZ4SxqsP1TSpg3U21fSWZ2I5/LsDDmi2XODIAiC1tLI4s2Pbb+VnVA9Dknz5+21Z6GHmjqHAzeS9r9oNX2BPYHLGj1ByeL6SRtiKTIUmAbc1+qGJX0O2NT2Kq1uOwiCIGieRkYspuan4F6S1sg/XWzHF8Sikm5SMnNOlbS7pA0k/VXSw5JuLQmrsrnyF5L+Chybn6Dny8cWkfS8pAXUejvpEpLGSHpc0rmFa35N0v1KFtCrJC2Wy0/OdSdLOi0/te9Akm9NlLSxpIdz3QGSLGnl/P4fuS/LKplKJ+S/zfLxLXIbE5XMqIuTNooaksuOqNa/PIJwl6TLgCmqYRetwaGa1Xo6i3FUac+Qg4AjclxDqvWpgf9Gdsv/bUySNDYX3wZ8ttD2wHztyfmzWrKRtoMgCILW0MiIxaHAsST/wuWkbax/1oZYtgFetL0dgJJQ6s+kTZ1eUVJsnwTsl+v3sb1Frrs+sAVwF2mL61ttTy99N6rDTrq77QmSlqDMTqqkKr9X0m22n60S40Yk++Y/SWtOdpZ0N3AcMMz2u5KOAf5baUh/J2BN25bUx/abSutTbrR9dY5toRzPEOAhUmJwD/Cy7fckXQCcbvuenHTcCnyJZBo9JHtAFgM+AH4EHGn7G7ntAyv1r9CXdWw/q7Ql9nokadmLwL2kn6LW2ub8VdvrS/pejmV/OoyjwyV9BbjE9kBJ5wLTbJ+W47qsSp/qcQKwte1/SeqTy3bI93Ngbnsyyd/yV0knAj8hWVNnIt+bAwEWWrZ3+eEgCIKgk9RNLGy/R0osjm1zLFOA0ySdQpoqeIO018TtOUHoBbxUqH9l2evdSYnFt4DflbU9i50U0kgD0L80qgH0JtlJqyUWD9p+Jp97Ocmw+QEp2bg3x/kZ4H6Siv0D4AJJN+U+VeI+0pf45sAvSAmW6NiqexiwVmEAYYk8OnEv8GtJo0m69BcqDDJU699HuS/Ffj5o+4Xct4mkaZVaiUXRerpzfj0Y2AWScVRS0ThapFqf6nEvMErSHwvXn0G+Vh/bJdfKxcBVlRqyfR5wHqSfmzZw7SAIgqAB6iYWkgYBPyZ90cyob7t/KwOx/ZSkDUi7Q/6S5Lt4zPYmVU4pWkivB34paSlgA5KHokir7KSVjKgCbre9R3llSRsBW5GSne8DX6nQ5jjSaMUqwJ+AY3K7pURkPmAT2++XnXdyTli2BR5Q5UWqFfuXRyjKLa7NGkErWU9rGUeLVOxTvdkX2wdJ2hjYDpgoaWCdGIMgCIIuppE1FqNJOu5dSNMMpb+WImkF4D3blwKnARsDyyobSJXWTKxd6Vzb00iWzN+ShsXLFyO2yk66kaRVldZW7E56on8A2EzZTqq0LuILeXqit+2bSUPxA3Mb75AspCXGAt8Gnrb9KfA6KVm4Nx+/jZSUlO7TwPxvP9tTbJ9CmkJZs0LbrbCvNkM142h5XBX7VI/c5/F5Ue6rwErF47bfAt6QNCQX1TPFBkEQBC2mkTUWr9juin0r1iUtavwUmA4cDHwMnJGHuOcHfgM8VuX8K0nD3kPLD9j+KK/ROFPSwqT1FcNIdtK+JDupgFdIv9qoxv2kBZLrkr5Ex9j+VNK+wOV5HQOkNRfvAH+StBDpSb70U8grgPMlHQbsavsf+Um9tBjxHuDztt/I7w8Dzs5rB+bP9Q4CDpe0JWnE4HHSepRPgY+VDKyjSIlWM/2bXUYCF+VY36PDOHoDcLWkHUlrdqr1qR6nSlqDdD/vIFlSy38N8h3gXEmLAM+QzLFBEARBF1F3S29JWwF7kP6PfMZwue1Z5riDYE4k7KZBEATNo9mwm44gDbMvQHoihjRvHolFEARBEAQz0UhiMcD2um2PpIegHmgn7S4kjQFWLSs+ponFrp297rHAbmXFV9k+qZ3XDYIgCGafRqZCziftOdCOnSKDoNvp3a+vB/8qTJrt4KZd9u/uEIIgaBOzMxUyGPiOpGdJaywEuNU/Nw2CIAiCYM6nkcRim7ZHEQRBEATBXEEjO2/+E0DSZ4GF2h5REARBEARzLHU3yJK0g6SnSdtc/xV4jrRnQo9E0uF5D4N69YZIekxJXrWwkqzrMUmnVqk/Q2g2m/H9eHbbqNF225TshWs0rY9v4jO5O+/02kzba6pDxNavmXODIAiC1tPIzps/A74MPGV7VdIW1ffWPqVbORyo+yVG2iHyNNsD89bS/wWsb/uodgZH2h69XQwneUsaJu9A2m4Op7HPpDMMB/5kez3b/2jTNYIgCIIGaSSxmG77NWA+SfPZvouO7am7Fc2qWv8JsAJwl6S7cp1zJD2URyN+msv2B74JnKCkCL8eWBQYn3forMYwSeMkPSWpZBCtpiZfXtLY/DQ9NY+QnAwsnMtGSzo678CJpNMl3ZlfbyXp0vy6s0r2fvnvFiXt/Dh16M1HSfp1vken5PdnKGnln2lgZGYxVVCs57gfVVKpXyhpwdy/8s+kYp/qfNa9cpxTc/tHSNqWlLTsX2j7v3OdqZIOr9Hegfm/i4c+evudepcPgiAIGqSRp9U38//xjwVGS3qZtNV2T6CSan0EsKXtV3OdY22/LqkXcIek/rYvkDSYmfXl00rq7Rr0JenZ+5G+KFcH9qGymnxnkr79pHztRWyPk/T9guL7y8APgTOAQcCCSl6PwcA4Scswe0r2O4CDbD+tJO/6HR0itC/kdj+RNApYPl93TZLU7eoa92EWxbqkh0jbiG+VhXKXAAfb/o2k/y59JtX6BJxY594PBFa0vU7uW6nPM5TsShK7ESTPjEiJ4l9tP1re2Ex20359w24aBEHQIhoZsdiR5NY4ArgF+AdtkJB1kimkUYRTJA3JEqpyvinpEeBR0pfh7KxB+KPtT20/TfJQrElSk++jpBofDyxNUpNPAEZIGgmsa7vSY/HDwAZKyvAPSS6SQSTb6TjSFFRJyT6R5MFYhZmV7DuTvBwzkZPBTYGr8rm/JyUPJa4qk7Vdl/v2OLBcnfvwoO0XsjRtIinh+iLwrO2ncp2LSSr4cqr1qR7PAKtJOlPSNqR7UM5gkr/l3Symu5Z0L4MgCIIuopFfhRT12he3MZamKVet55GCGUhaFTgS2ND2G/nJfHZ+2VJNm15RvS5pc5Li+w+STrV9SVn80yU9R3rKvg+YDGxJGhH5W/63s0r2+YA3a4zC1NKm1/aXV1as1zun2HbFPtUif34DgK2BQ0hTWftVaDsIgiDoRhr5VcjOkp6W9JaktyW9I6nS02KXo1lV6+szs6J7CdIX6FuSlgO+PpuX3E3SfEq/PlgNeJIqanJJqwAv2z4f+N8cG8D0Ut3MWFLyM5Y0SnEQMNFpS9ROK9mzrvxZSbvlc5W/mNvFE0DfUqzMrCwvfiYV+1Sv8TyFMp/ta4Dj6bifRcYCw3Obi5Kmi8Z1tkNBEARB8zSyxuJXwPa2/9buYDpBJdX6JsCfJb1ke0tJj5JU688w+79meZL0Zbkcae3CB5KqqdeHAkdJmg5MI63FgDSvP1nSI7b3In3xHQvcn9ccfJDLsP2KZkPJTvrlyzmSjiNJ5K4gqcZbTr4XI0hTL/OTpoLOLfS5+JlU6tNTszQ6MyuSlOylZPh/KsTwSB6VejAXXVBpfUUQBEHQPhpxhdxre7MuiicIupzQpgdBEDSPZsMV8pCkK4HrKMyt2w5tehAEQRAEM9FIYrEE6VcHXyuUmbTifq5DoewGulcfL2k8sGBZ8d62p7T72kEQBMHsUXcqJAjmdvr0W91DTvlVd4cxx3HDrjt3dwhBEHQj1aZCGvlVyBck3SFpan7fPy8GDIIgCIIgmIlGNsg6n7QCfzqA7cmkvROCIAiCIAhmopHEYhHbD5aVdfuW3pKmtbi9mcygkk6UNKyF7Y+UdGST50zL/64gqeIW2+qEEbTONW+W1KeF7TVtQ63RVtP3MAiCIOhaGlm8+WreEMoASoKql9oaVfcwHLgReBzA9gndGk0B2y+S9qXoimtt2xXXCYIgCOZOGhmxOITkmVhT0r9IOz0e3M6gmiHvKHmqOqyXuxeOHZ3LJimZRZF0gJKJdJKka/IujZXMoKNyElXR2pnLn5P0UyVL5xRle2gN1sojDM/kTaxKcdY0ckrqW1jjsrCkK5SsplcCCxfqVTK5biVpTKHOVyVV/UVP7tMy+Zp/k3R+bu82SQvnOncr+VkeVDK9NuTjkLSUpOty7A9I6p/LR+b7WuneHCvpSUl/IflISuUDcxuTJY2RtOTsxBYEQRC0hrqJhe1nbA8DliXZNAfbfq7tkTXOzqQtrQcAw0jJwfKSvk4ahdjY9gDSDqIA19reMJf9Dfiu7ftIRs+jbA+0/Y9S40q7W44Cdre9LmmUp5hYvWp7feAc0tbctViT5LrYCPiJpAU0s5Hzy8ABktar0cbBpG3M+wMnARsUjh2bV+j2B7bIX9x3Al+StGyuMwK4qE6cJdYAzra9NvAmsEvh2Py2NyIlmj9psL2fAo/m2H8MFN0p1e7Nt0g21Z2BDQv1LwGOyW1NKYuhbmyaSZteyV0XBEEQdIaqUyFKqutK5QDY/nWbYmqWwcDl2dT5H0l/JX0BbQFcZPs9ANuv5/rrSPo50AdYjOT6qEUla+chwG/y+9LT/8OkL79a3GT7Q+BDJf38chSMnAB5NGEIycZaic1JmnVsT5Y0uXDsm5IOJH2uywNr5Tp/AL4t6SLSluf7lDdahWdtTyz0r2/h2LVVymsxmJyc2L5T0tJKqnuofG+GkO7NewBKWnjyOX1sl1wkFwNXNRNbUZvep9/q8ZvrIAiCFlFrjcXiNY71JKoZLcWsNlJIow/DbU9SclYM7WT7JUq7kZYsn43ULdbvjJFzln6ptsn1IuAGkmr9KtuNLr4tj3fhCsca6feMMCuUlfpS6d4UjzdDZ2ILgiAIWkDVqRDbP63115VB1mEssLukXnm4f3OShOo2YD9Ji0Ca38/1FwdeUjKM7lVop2jgLFLL2tmq+Jsxco4lxy1pHdK0B9QwuebFny+SZF+jWhh7sxRjH0qaRqplyh0L7JTXlSwObA9g+y3gjcL6iVZ/JkEQBEEnqTUVcrTtX0k6kwpPjbYPq3BadzCGNLw/iRTn0bb/DdwiaSDJdfIRcDNpXv94YDzwT9LcfCmZKDeDAnWtnbNNJ4yc55Asn5OBiaXz8ghMLZPraGBZ24+3KvZOMJKO2N8DvlOrcr43V5L6+U9mTri+A5ybE8dnSGtHgiAIgm6m6pbekl6zvXT+lcIb5cdtX9zm2IIWIuks0sLJ/+3uWHoaYTcNgiBoHnXCbvofSauQngS3bFtkQduR9DBpmuSH3R1LEARBMHdTK7E4B7gFWA0oPs6VFkWu1sa45ljytMkPyorvtX1Id8QDYHuD8jK12CAqaWvglLLiZ23v1Jn2giAIgjmTunZTSefY7jEbYgVBq1my35oe+qsLujuMOYYxuwzu7hCCIOgBVJsKaWSDrEgqgiAIgiBoiEa29A6CIAiCIGiISCyCIAiCIGgZkVg0gaTDSxtu1ak3JIu7JubNnU7N709tYSxVVeqdbK/RvjWtaVcN3bmk+5ppKwiCIOjZRGLRHIcDdb98SbtLnpaFZu8D/wWsb/uoVgVi+0XbrVSpH05jfWsptjft6msGQRAE7SMSiypIWlTSTUp69amSfgKsANwl6a5cp5KmfH/gm8AJkkZncdaiwHgVlO5l19otX2OSpLG57GZ1aMUflXRCfv0zSftrZpX62lkTPlFJI75Ghfh3z3VnUcDn3UbL+/Y1SfcrKeGvkrRYg/dtm3zOJEl3FA5VU8ZPK7xuSHOfy/spadMnSDqx1I4Sp+Y+T6lxz2fYTT98+81GuhYEQRA0QAiaqrMN8KLt7WCGUXMEsKXtV3OdY22/LqkXcIek/rYvkDQYuNH21fncabYH1rjWCcDWtv8lqU8uGwsMkfQc8DGwWS4fDFxadv5BwG9tj5b0GaAXsG15/OpQwG9l+ylJlwAH2/6Nks12S9uvSlqG5BUZZvtdSccA/w2cWOuGKblazgc2t/2sOvwskLToW5K2UH8y/4x5euHcoub+vcK519o+P9f5OfBd4Ezgt7nPl0s6qHCdnYGBwABgGWCCpLG2XyrGWrSbLtlvzbCbBkEQtIgYsajOFGCYpFMkDcniq3K+KekRkuJ8bWCtTl7rXmCUpANISQEkL8bmpETiJmCx/LTe1/aTZeffD/w4JwCr5OmXSvFXUsBvXiGeL+e+3CtpIsnLsUoD/fgyMNb2szCTqh6yFj0nZSUtepFhVNfcj5M0hTTFtHYu34QOVfplhXYGA5fb/sT2f0hysg0biD0IgiBoATFiUYX8RL8B6cn/l5JuKx5XbU15s9c6SNLGwHbARCV52gRgEEmwdTvp6fsA4OEK51+mtJPmdsCtkva3fWeF+K9vMCQBt9veo8muVFPVQ3Uter1zR9FazX0QBEHQRmLEogqSVgDes30pcBqwPjOr1atqyjtxrX62x9s+AXgVWMn2R8DzpPUaD5BGMI6kglJd0mrAM7bPICUP/avEX0sBX+zbA8BmpXpKSvcvNNCV+4EtctJVVNU3QrOa+weAXfLrbxXKxwK7S+qVp2Y2p8McGwRBELSZGLGozrrAqZI+BaYDB5OG3/8s6SXbW6q2prwZTpW0Bulp+w6SAh5SErFVXnMwDvg8FRILYHfg25KmA/8mrYXYsDz+Ogr488r6ti9wuaSST+Q44ClqYPsVSQcC10qajzTl8dVGboDtZjX3hwOXSvohaaqoNFU1hvQ5TSKNgBxt+9+NxBAEQRDMPnVdIUHQE8kjG+/btqRvAXvY3rEzbYU2PQiCoHnUCW16EPRkNgDOkiTgTWC/7g0nCIIggEgsuhRJxwK7lRVfZfuk7ohndlCLtevNYnsc6SelQRAEQQ8ipkKCeZ7lVu/v3U+9qbvD6FbO2Gml7g4hCII5jGpTIfGrkCAIgiAIWkYkFkEQBEEQtIxuTSyKnogWtTdc0lqF9ydKGtbC9qtaOptspyGTaCfbHiqprWIvFTwlTZyzb95bo169UZKakqtJWlbSeCUHypBmzg2CIAhay9w2YjGcwrbatk+w/ZfuC6cqh9M+k+hQoKnEIu9p0W72JYnO2sFWwBO218uLOoMgCIJuokckFrWMlGrQeJmf0ncgbQo1Ucl+OePpVxWsnrn8OUk/VTJyTpG0Zp1wB0i6U9LT2e1RivOoHNNkdZhOZzGMqswkKumbkn6d6/9A0jP5dT9J9+TXG0j6q6SHJd0qaflcfpikx/M1r5DUlyQkOyLfgyH5af6aHNsESZvlc0dKOk9pq+9L8vsLVcFAWoVeks5XMrveJmnh3O5AJevoZEljJC2ZP4NBwOgc18LV+lQPSScX+nya0qZavwK2LbS9R/4sp0o6pZF2gyAIgtbQIxILZjZSDiMlB8trZuPlANIXCCTj5Ya57G/Ad23fR9rO+ijbA23/o9S4Oqyeu9tel/Qz24ML13/V9vrAOaRts2vRn+Tk2ISkRl9B0teANYCNcj82kLQ5HYbUAbbXAW7J226/SDKJbkm2mOa2hwCvSVqRJNMap7SV9ZnArrY3AC4ESj9P/RGwnu3+wEG2nyPtpHl6vgfjSBbQ021vSNoC+4JCXzYAdrS9Z36/JrB17sdP8rWrsQZwtu21SftIlLbXvgQ4Jsc0BfhJtrw+BOyVLa8f1+hTVZS2+d4JWDu3/3PbE0l22Ctz20sCpwBfIX0WG0oaXqGtGdr0999+vfxwEARB0El6yj4WM4yUwH8klYyUW1DdePlzoA+wGHBrnfYrWT0PAX6T31+b/32YlOTU4k/ZHvq+pLtIX8KDga+RLKfkmNYgbb99Wn5qvrHSML3tf0taTNLiwEokU+fmpCTj2hz7OsDtkiDZT0sK8MmkUYDrgOuqxDsMWCufC7BEvhbA9bkvJW6y/SHwoaSSgfSFKu0+m7/UId23vkpq+T62S/6Ri+kwkBap1adavA18AFwg6Sbgxgp1NgTutv0KgKTRpPt5XbFSUZu+3Or94zfXQRAELaKnJBbVjJRdZbwsmTcrWTfLKY/Huf1f2v79LBcuM4zaPrFCm/cDI4AnScnIfqQRkR8CKwOP2d6kwnnbkb40dwCOl7R2hTrzAZuUJRDkL/R3y+rWM5DWqrtwjbrliOp9qortjyVtRFpT8S3g+6SRifK2gyAIgm6ip0yFVDNSNmu8LBo6i9SyejbLjpIWkrQ0KaGZQBox2U/SYjnOFSV9VpUNo5XiHEuaghlLGvXYEvjQ9lukZGNZSZvktheQtLaS5Gsl23cBR9MxelPe9m2kL2Dy+QM72e+65HjfUMcvM6rZUyv2qV77+f72tn0zaQHswArVxpMMq8tI6gXsQec/6yAIgqBJesqIRTUjZbPGyyuA8/PCwxk/Waxj9WyWB0k2zZWBn9l+EXhR0peA+/NIwDTg28DqzGpIhTKTKGmUYiVgrO1PJD1PSoaw/VFe/HhGnmqYnzSF8xTJ7tmb9JR+uu03Jd0AXC1pR+BQ4DDgbEmT87ljSQs828V3gHNzMvgMaSQG0ijTuZLeJ33Wlfr0WJ22Fwf+lNfMCDiivILtlyT9D3BXrnOz7T/NbqeCIAiCxogtvYN5nrCbBkEQNI9iS+8gCIIgCNpNT5kK6VHkaZMflBXfa/uQ7oinu8jrSO6ocGgr26+1+dpjgFXLio+xXe8XQEEQBEE3ElMhwTzP6v0G+len9MQNWtvLzrsu090hBEEwBxNTIUEQBEEQtJ1ILIIgCIIgaBmRWARBEARB0DLm+cRCSeT1t7z18+y085ykipPW6pxmvChQu0AFHXyhzr6SzupcxBWveZCkfVrVXm6z6n1psp2m72EQBEHQ9cSvQuB7wNdtP9vdgVTD9v5ddJ3ObhoWBEEQBMA8PmIh6VxgNeB6ST+UdF3WcT8gqX+us1SV8qWVdOGPSvo99R0VDWvGK8R5t6RB+fUISU9lUdtmhTrbSxqf4/mLpOUkzaekd18215lP0t9rjKyMlHRk4ZqnSHowX29ILt9X0rWSbslt/6pSW1Xa/28llflUSYfnsr55xKjSvdlASTl/P0kaV2pnIUkXKanRH5W0ZbOxqWA3fevttv5yNgiCYJ5ink4sbB9EVpgDfYFHs477xyT9N8BPq5T/BLjH9nokXfvKdS7XsGa8WgOSls/xbAZ8FShOj9wDfDnHcwVpW/RPgUvp8KkMAybZfrVOrCXmt70RyctRjGsgsDuwLsnxslK9hpRkbCOAjYEvAwdIWi8frnZvLgIOqyArOwTA9rokF8jFeZvvhmOzfZ7tQbYH9V5i6XrhB0EQBA0yTycWZQwG/gBg+05g6eyxqFa+OelLG9s3AW/Uab9RzfjmNdrYmKwEt/0RcGXh2OeBWyVNAY4CSlKvC4HSuon9SF/WjVLUyfctlN9h+y3bHwCPA6s00NZgYIztd21Py22XZGWN3Js/lLVV+kyeIDljvjAbsQVBEAQtIhKLDipNZbhGefHfRmhGSV6Latc8EzgrP8X/F7AQgO3ngf9I+gopMflzE9eqppPvTF9qTRVVak9U72uzbQVBEARdRCQWHYwlTxlIGgq8avvtBsu/DsyyNqIedTTjlRgPDM3rOxYAdisc6w38K7/+Ttl5F5BGV/5o+5Nm42wRY4HhkhaRtCiwE8nqWhHbbwJvSRqci/YqHC7e+y+QpqGebEfQQRAEQXPE01wHI4GLlPTi79Hx5Vyt/KfA5ZIeISUD/9fJ61bTjM9CVoKPBO4HXgIeAXoV4rxK0r+AB5jZs3E9aQqkmWmQlmL7EUmjSNp5gAtsPyqpb43TRgAXSnoPKDpCfke6Z1OAj4F9bX8o1Vs/GwRBELSbcIXMA+RflJxue0jdyvMgoU0PgiBoHlVxhcSIxVyOpB8BBzPzVEIQBEEQtIVILFqIulEzXg3bJwMnF8skHcvM6zMArrJ9UmevI2k8sGBZ8d62p3S2zSAIgmDOI6ZCgnmetfoO9OjjbuvuMLqE9fb/bHeHEATBXEK1qZD4VUgQBEEQBC0jEosgCIIgCFpGJBY1UBeYT2ejzRMlDWtRWwMlbdtAvaGSbuxE+9OqlLfcphoEQRB0L7F4szY91nxq+4QWNjcQGATc3MI26xI21SAIgrmPGLGogrrIfCppUUk3ZYvnVEm7S9pI0rX5+I6S3pf0mWz1fCaXj5K0a359sqTHcxyn5bLdcnuTJI3NZbNYQSV9BjiRJOyamK+/qKQLJU3I9XZs8J4tVmh/sqRdCsdOyrE8IGm5XFa0qa6uZGWdJOkRSf1ye3fk91OKcUg6XtITkm6XdHmhnbq22CAIgqB9RGJRhS40n24DvGh7gO11gFtIO2qWzJ9DgKnAhiTXx/jiyZKWIm2PvXaO4+f50AnA1rYHADvkslmsoKT/Bk4ArrQ90PaVwLHAnbY3zP0/NW/DXY/jgbdsr5tjuTOXLwo8kGMZCxxQ4dzRJMPpAGBT0s6iHwA72V4/x/H/lBhEMqCuB+xMGm0p0ZAtVgVt+hvvhDY9CIKgVURi0RjtNJ9OAYZJOkXSkGzm/Bj4u6QvARsBv85tDmFWv8bbpC/gCyTtTNp2HOBeYJSkA+jY9ruWFbTI14AfSZoI3E0SmtXTwkPSsp9demO71O+PgNLajHJTKpIWB1a0PSaf94Ht90gjPb9Q2k79L8CKwHK5H3+y/b7td4AbcjsN22KL2vQlFw9tehAEQauIxKIx2mY+tf0UsAEpwfilpNLaiXHA14HppC/VwflvbNn5H5OSj2uA4aQRj9KIy3HASsDEvHlXozINAbvkEYyBtle2/bcGz6vU7+nu2DClknG0Wlx7AcsCG9geCPyHlOSEFCQIgqCHEolFY7TNfCppBeA925cCpwHrF655OHC/7VeApYE1gcfKzl8M6G375lx/YC7vZ3t8XuT5KinBqGYFfQdYvNDsrcChUrJ6SVqPxrgN+H4htobWN+R79oKk4fm8BZWkbL2Bl21Pl7QlsEo+5R5g+7xmZDFgu9xOs7bYIAiCoMXEr0IaYyTtM5+uS1rD8ClpdOLgXD6eNOxfGqGYTPqSLR8RWBz4k6TSk/wRufxUSWvksjuAScATVLaC3kXH1McvgZ8BvwEm5+TiOeAbtW8RkNZ3nC1pKmlk4qfAtQ2cBykJ+L2kE/N92I207uIGSQ8BE3P82J4g6frcp38CDwFv5XYatsUGQRAErSe29A7mSCQtZntaTiDGAgfafqQzbYXdNAiCoHkUdtNgLuM8SWuR1lxc3NmkIgiCIGgtkVh0EeqB5tPOImkE8IOy4nttH9JVMdjes6uuFQRBEDROJBZdRE4eBnZ3HK3A9kXARd0dR6uY/p8P+fdpf+/uMBric0eu3t0hBEEQ1CR+FRIEQRAEQcuIxCIIgiAIgpYRiUUQBEEQBC1jrkos1CLNeZW295V0VovaWaEVMVVouyH9eQuuU1GDXqP+8PwLjnr1ZkjJmmh7wSwvmyhp92bODYIgCFrPXJVYkDTn29req1QgqactUN0XaEtiQVoc2lRi0UX3ZzhQN7HoJOsBCxQEakEQBEE3MtckFppZc/6WpPMk3QZcImlZSddkDfgESZvlc5rVg68k6RZJT0qaYc2U9G1JD+an5t9L6pX/Rimpy6dIOkJJcz4IGJ3rbqH6evR++ZoPSxonac1cPpMWXU3oz/OoyVWSbgBuy++vzdd5WtKvGrjflTToqyhpzifnf1eWtCnJrnpqjqtftT41cM3D1KGHv0LSZ0myt4GFtrfKfZ2S+75glbZm2E1fm/Z6I5cPgiAIGqCnPc13GtsHSdqGpNf+PrA9MNj2+5IuA063fY+klUkujC/RoQffT1If4EFJf7H9bpXLbASsQ9q+e4Kkm4B3gd2BzbLT4nckH8djJGPnOgCS+th+U9L3gSNtP5RHC0bltot69Pnp0KOfBxxk+2lJGwO/A75Chxb9X7ntj5QEZoNsfz9f8xeV+pfb3QTob/t1SfuSRjvWAz4EnpR0pu3nq9yHkgb92JyEHEDazvss4BLbF0vaDzjD9nCl7bdvtH11juuOKn2qx4+AVfM25KX7uX++n99Q2tb8btLeIE9JuoS0RfpvyhuyfV6+twxYad3YfjYIgqBFzDWJRQWut/1+fj0MWEuaIcVcQknV/TVgB3XM65f04NVMnreXNrPKIw2DSc6NDUiJBsDCwMsklfdqks4EbiIJumbC9seSKunRewHjlARbmwJXFWIvPYGXtOh/pLqPo1r/Sn0pPqrfkSVeSHqcJPyqlliUa9C/ml9vAuycX/8BmGXko06f6jGZNNpzHXBdheNfBJ7NxlhI2vRDqJBYBEEQBO1hbk4siqMO8wGbFBINAJS+2Xax/WSDbZY/2ZbU6Rfb/p/yypIGAFuTvty+CexXoc1yPfooUmJxZI77zawMn/nCaYRmY5LZc6KkWerQoT+fqX/5vPJRmQ8LryupzYvU06DPCLNCWdU+NcB2pMRrB+B4SWuXHQ+dehAEQTcz16yxqEO5zntgftmsHvyrkpaStDBpQeK9pG26d83z/eTjq0haBpjP9jXA8XTo0MsV5VX16Fkn/qyk3XLbyslKNS16q/TnneU+4Fv59V4kvTnFuGr1qRaS5gNWsn0XcDTQB1isrNoTQF9Jpe0pQ5seBEHQxcwricVhwKC86O9x4KBc/jNgAZIefGp+X4t7SEP8E4FrbD9k+3HgONIiyMnA7cDywIrA3Uoq8lFAaURjFEnrPTEnKJX06JMLIwJ7Ad+VNIm0bqO0wPTUvEBxaj53EnAXacqn9NPLZvs3uxwGjMj3YW86fCJXAEflRZX9avSpFr2AS5WU74+S1sy8Waxg+wOSJv2qXO9T4NzZ71YQBEHQKKFND+Z5QpseBEHQPKqiTZ9XRiyCIAiCIOgC5ubFm51C0tbAKWXFz9reqTvi6U4kjWfWX2zsbXtKm697NrBZWfFvs1U1CIIg6MHEVEgwzzNg5S/6tiN/391h1GW5w4Z2dwhBEAQziKmQIAiCIAjaTiQWQRAEQRC0jDk+sVDycexaofwCNWDUbOI6QyXdWL9m3XYaMn12su2+kvZsR9tl13ku79PRaP2hSs6QevU6ZZCVdHn+KfERzZ4bBEEQtJY5OrFQDTOn7f3zHhM9jeG0z/TZF2gqsZDUqz2hzMRQ0jbeLUfS54BNbfe3fXo7rhEEQRA0TrcnFvkp+wlJF+enzqslLSLpBCUr51QlU2lp98i7Jf1C0l/p2ICp1NbP8gjGfLneoFw+TZVtnP3y+wmSTpQ0rU64S0gao2TYPDfvBomkr0m6X9IjStbQxXL5yeqwcZ6mWU2fG0t6ONcdIMlKkjQk/SPfh2pm1i1yGxPzxlOLAycDQ3LZEUqG1VPzeZMl/Vc+d6iku5TkbFPy+7vzvX9C0ujS/a7Bobm/U9RhXF1K0nX5Wg9I6i+pL2lDsiNyXEOq9akeKjO65uLbgM8W2h6Yrz05f1ZLNtJ2EARB0Bq6PbHIfBE4z3Z/4G3ge8BZtjfMdtCFgW8U6vexvYXt/1cqULJsfhYYYfvTsvZLNs4BpF0qD8jlvyX9jHFD4MUG4twI+CGwLtAP2DlPCRwHDLO9PvAQ8N+SlgJ2AtbO/fq57fuA64GjbA+0PR5YSNISJLvpQ6TEYBXgZdvv5RhPzzHuAlyQYzkSOCQ7N4YA75Psn+Ny26cD3wXeyuduCBwgadVCX461XRo9WY+0tfhaJP18vS/7V3N/z8mxAPwUeDT398ck0+lzpN0vT89xjavRp3qUjK4DSAka+d9/FNq+BDgmxzAF+EmlhlTQpr8+7a0GLx8EQRDUo6fsY/G87Xvz60tJW0M/K+loYBFgKdLWzzfkOleWnX88MN72gVXar2XjHJ5fXwacVifOB20/A2len2Q3/YD0ZXxvfsj/DHA/KUH6ALhASa9ebX3GfaQv8c2BXwDbkGRa4/LxambWe4FfSxoNXGv7hQqDDF8D+qtjDUpvYI18Px60/WxZ317IfZtImla5h+qUjKoP02E0HUxKFLB9p6SlJfWucG61PtWjptE1X6uP7ZIf5GLgqkoNzaRNX/mL8ZvrIAiCFtFTEotK1tDfAYNsPy9pJEn5XaLczDkB2EDSUmUq8BKN2jg7E6dICvI9yitL2gjYiiTm+j7wlQptjiONOKwC/Ak4JrdbSkQqmlmBk3PCsi3wgKRhFdoWcKjtW8viGsrs2U2L9Yt1K02fVDOcVrLN1rxgg0bXIAiCoBvpKVMhK0vaJL/eg44n5VfzeoVZfvVRxi2k9QU3NfjkW+IB8hM2HVbOWmwkadW8tmL3HOcDwGbKRs28LuILOe7etm8mTTEMzG1Uspt+G3g6T+G8TkoWSiM4Fc2sSnbTKbZPIU2hrFmh7VuBgyUtkM/5gqRFG+hnZxlLEoyVkpdXs820PK5qttmaqLLRdQa23wLekDQkF4XdNAiCoIvpKSMWfwO+I+n3wNOkefslSXPkz5FGJGpi+6qcVFwvadsGr3s4yZj5Q+AmoN5k+/2kBGZd0pfoGNufStoXuFxSafvr40hfpn+StBDpSb70U8grgPMlHQbsavsf+Um9tBjxHuDztt/I7w8DzlYyhs6f6x0EHC5pS9KIwePAn0k2z4+VrKGjSGsZ+gKP5MWYr9Ax9dMORgIX5VjfA76Ty28Arpa0I3BojT7V41RJa5Du5x0ko+sqZXW+Q7LHLgI8Q7KdBkEQBF1Et2/pnX81cGNepNnV114EeN+2JX0L2MN2IwrvYC4i7KZBEATNoypbeveUEYvuYgPgrPw0/yawX/eGEwRBEARzNt0+YtHTkLQu8Iey4g9tb9wd8XQnksYAq5YVH1O+GLQN1z0W2K2s+CrbJ7Xpeu8AT7aj7RawDGk9SU8kYuscEVvn6cnxzYuxrWJ72fLCSCyCeR5JD1UazusJRGydI2LrHD05NujZ8UVsHfSUX4UEQRAEQTAXEIlFEARBEAQtIxKLIMg7cPZQIrbOEbF1jp4cG/Ts+CK2TKyxCIIgCIKgZcSIRRAEQRAELSMSiyAIgiAIWkYkFsE8gaRtJD0p6e+SflThuCSdkY9PlrR+D4tvTUn3S/pQ0pGV2ujG2PbK92yypPskDehBse2Y45oo6SFJg3tKbIV6G0r6pGAh7vbYJA2V9Fa+bxMlndBTYivEN1HSY5K6zAfUwH07qnDPpubPdakeEltvSTdImpTvW/t0B7bjL/7m6j+gF/APYDWS1n4SsFZZnW1JvhUBXwbG97D4PgtsCJwEHNnDYtsUWDK//npX3bsGY1uMjrVk/YEnekpshXp3AjeT3EE9IjZgKEm10CX/nTUZWx+SH2nl/P6zPSW2svrbA3f2lNiAHwOn5NfLkoSXn2lHPDFiEcwLbAT83fYztj8iieDKnTA7Apc48QDQR9LyPSU+2y/bngBM76KYmontPndI8x4APt+DYpvm/P+kwKJAV61Wb+S/OUhSvmuAl7sormZi6w4aiW1P4Frb/wfpfxs9KLYiewCXd0lkjcVmYPGssFiMlFh83I5gIrEI5gVWBJ4vvH8hlzVbp11057Xr0Wxs3yWN/HQFDcUmaSdJT5AMxl3lA6obm6QVgZ2Ac7sophKNfqab5GHzP0tau2tCayi2LwBLSrpb0sOS9ulBsQEzBJfbkJLGrqCR2M4CvgS8SDKH/8D2p+0IZl6XkAXzBqpQVv7k2kiddtGd165Hw7FJ2pKUWHTVOoaGYrM9BhgjaXPgZ8CwdgdGY7H9huTe+SQ9RHYZjcT2CMkDMU3StsB1wBrtDozGYpufJJDcClgYuF/SA7af6gGxldgeuNf2622Mp0gjsW0NTAS+AvQDbpc0zvbbrQ4mRiyCeYEXgJUK7z9PytqbrdMuuvPa9WgoNkn9gQuAHW2/1pNiK2F7LNBP0jLtDozGYhsEXCHpOWBX4HeShveE2Gy/bXtafn0zsEAPum8vALfYftf2q8BYoCsWDDfz39u36LppEGgsthGkKSTb/jvwLLBmW6LpioUl8Rd/3flHesJ5hmRqLS1sWrusznbMvHjzwZ4UX6HuSLp28WYj925l4O/Apj3wc12djsWb6wP/Kr3v7tjK6o+i6xZvNnLfPle4bxsB/9dT7htpOP+OXHcRYCqwTk+ILdfrTVq/sGhXfJ5N3LdzgJH59XL5fwvLtCOemAoJ5npsfyzp+8CtpNXTF9p+TNJB+fi5pFX525K+IN8jZfc9Jj5JnwMeApYAPpV0OGnVd8uHMZuNDTgBWJr0xA3wsbvApNhgbLsA+0iaDrwP7O78/6w9ILZuocHYdgUOlvQx6b59q6fcN9t/k3QLMBn4FLjA9tSeEFuuuhNwm+132x1Tk7H9DBglaQrpAeoYpxGflhNbegdBEARB0DJijUUQBEEQBC0jEosgCIIgCFpGJBZBEARBELSMSCyCIAiCIGgZkVgEQRAEQdAyIrEIgiBoA5IukLRWE/UHSTojv95X0llNXq94/lBJmzYXcRC0htjHIgiCoA3Y3r/J+g+R9ippGknzl50/FJgG3NeZ9oJgdogRiyAIgtlE0qKSbsrSrqmSds+SrEH5+DRJp2Rp1l8kbZSPPyNph1xnqKQbK7S9vaTxkh7N5y6Xy0dKOk/SbcAlpfMl9QUOAo6QNFHSEEnPSlogn7eEpOdK74Og1URiEQRBMPtsA7xoe4DtdYBbyo4vCtxtewPgHeDnwFdJuzSeWKfte4Av216PpMM+unBsA5KfZc9Sge3nSMbU020PtD0OuJu0bT0kj8U1tqc33csgaIBILIIgCGafKcCwPCoxxPZbZcc/oiPZmAL8NX+xTwH61mn788CteSvmo4Ciwvx62+83EN8FdGxTPwK4qIFzgqBTRGIRBEEwmzgpuzcgJQq/lHRCWZXpBdfGp8CH+bxPqb/W7UzgLNvrAv8FLFQ41pCPwva9QF9JWwC9usKtEcy7xOLNIAiC2UTSCsDrti+VNA3Yt4XN9yaZKAG+0+A575CEdUUuIam8f9aiuIKgIjFiEQRBMPusCzwoaSJwLGkNRasYCVwlaRzQqI3yBmCn0uLNXDYaWJKUXARB2wi7aRAEwTyApF1JCz337u5YgrmbmAoJgiCYy5F0JvB1YNvujiWY+4kRiyAIgiAIWkassQiCIAiCoGVEYhEEQRAEQcuIxCIIgiAIgpYRiUUQBEEQBC0jEosgCIIgCFrG/wfNiu8Y0xzsjAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 첫 번째 문서와 다른 문서 간에 유사도가 높은 순으로 이를 정렬하고 시각화하기\n",
    "\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# argsort()를 이용하여 앞예제의 첫번째 문서와 타 문서간 유사도가 큰 순으로 정렬한 인덱스 반환하되 자기 자신은 제외. \n",
    "sorted_index = similarity_pair.argsort()[:,::-1]\n",
    "sorted_index = sorted_index[:, 1:]\n",
    "\n",
    "# 유사도가 큰 순으로 hotel_indexes를 추출하여 재 정렬. \n",
    "hotel_sorted_indexes = hotel_indexes[sorted_index.reshape(-1)]\n",
    "\n",
    "# 유사도가 큰 순으로 유사도 값을 재정렬하되 자기 자신은 제외\n",
    "hotel_1_sim_value = np.sort(similarity_pair.reshape(-1))[::-1]\n",
    "hotel_1_sim_value = hotel_1_sim_value[1:]\n",
    "\n",
    "# 유사도가 큰 순으로 정렬된 Index와 유사도값을 이용하여 파일명과 유사도값을 Seaborn 막대 그래프로 시각화\n",
    "hotel_1_sim_df = pd.DataFrame()\n",
    "hotel_1_sim_df['filename'] = document_df.iloc[hotel_sorted_indexes]['filename']\n",
    "hotel_1_sim_df['similarity'] = hotel_1_sim_value\n",
    "\n",
    "sns.barplot(x='similarity', y='filename',data=hotel_1_sim_df)\n",
    "plt.title(comparison_docname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
