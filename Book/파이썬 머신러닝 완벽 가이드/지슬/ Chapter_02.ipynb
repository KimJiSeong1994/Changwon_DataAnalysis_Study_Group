{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 02. 사이킷런으로 시작하는 머신러닝\n",
    "## 01. 사이킷런 소개와 특징"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.23.2\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "\n",
    "print(sklearn.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 02. 첫 번째 머신러닝 만들어 보기 - 붓꽃 품종 예측하기\n",
    "지도학습 : 학습을 위한 다양한 피처와 분류 결정값인 레이블 데이터로 모델을 학습한 뒤, 별도의 테스트 데이터 세트에서 미지의 레이블을 예측한다.\n",
    "    \n",
    "    - 즉, 지도학습은 명확한 정답이 주어진 데이터를 먼저 한습 한 뒤 미지의 정답을 예측하는 방식이다.\n",
    "    - 분류는 대표적인 지도학습 방법의 하나\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 사이킷런 패키지 내의 모듈명은 sklearn으로 시작하는 명명규칙이 있다.\n",
    "- sklearn.datsets내의 모듈 : 사이킷런에서 자체적으로 제공하는 데이터 세트를 생성하는 모듈의 모임\n",
    "- sklearn.tree 내의 모듈 : 트리 기반 ML 알고리즘을 구현한 클래스의 모임\n",
    "- sklearn.model_selection : 학습 데이터와 검증 데이터, 예측 데이터로 데이터를 분리하거나 최적의 하이퍼 파라미터로 평가하기 위한 다양한 모듈의 모임\n",
    "    - 하이퍼 파라미터 : 머신러닝 알고리즘 별로 최적의 학습을 위해 직접 입력하는 파라미터들을 통칭한다. 이를 통해 머신러닝 알고리즘의 성능을 튜닝할 수 있다.\n",
    "    - train_test_split( ) 함수 : 데이터 세트를 학습 데이터와 테스트 데이터로 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iris target값: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n",
      "iris target명: ['setosa' 'versicolor' 'virginica']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "0                5.1               3.5                1.4               0.2   \n",
       "1                4.9               3.0                1.4               0.2   \n",
       "2                4.7               3.2                1.3               0.2   \n",
       "\n",
       "   label  \n",
       "0      0  \n",
       "1      0  \n",
       "2      0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 붓꽃 데이터 세트 로딩\n",
    "iris = load_iris()\n",
    "\n",
    "#iris.data는 iris 데이터 세트에서 피처(feature)만으로 된 데이터를 numpy로 가지고 있다.\n",
    "iris_data = iris.data\n",
    "\n",
    "# iris.target은 붓꽃 데이터 세트에서 레이블(결정 값) 데이터를 numpyfh rkwlrh dlTek.\n",
    "iris_label = iris.target\n",
    "print('iris target값:', iris_label)\n",
    "print('iris target명:', iris.target_names)\n",
    "\n",
    "# 붓꽃 데이터 세트를 자세히 보기 위해 데이터프레임으로 변환\n",
    "iris_df = pd.DataFrame(data = iris_data, columns = iris.feature_names)\n",
    "iris_df['label'] = iris.target\n",
    "iris_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 학습 데이터로 학습된 모델이 얼마나 뛰어난 성능을 가지는지 평가하려면 데스트 데이터 세트가 필요하다.\n",
    "- train_test_split() : 학습 데이터와 테스트 데이터를 test_size 파라미터 입력 값의 비율로 쉽게 분할한다.\n",
    "    - 첫 번째 파라미터 : 피처 데이터 세트\n",
    "    - 두 번째 파라미터 : 레이블(lable)의 데이터 세트\n",
    "    - test_size : 전체 데이터 세트 중 테스트 데이터 세트의 비율\n",
    "    - random_state : 호출할 때마다 같은 학습/테스트 용 데이터 세트를 생성하기 위해 주어지는 난수 발생 값\n",
    "        - (tran_test_split()는 호출 시 무작위로 데이터를 분리하므로 random_state를 지정하지 않으면 수행할 때마다 다른 학습/테스트 용 데이터를 만들 수 있다.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트 데이터 20% 학습 데이터 80%로 데이터 분할\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris_data, iris_label, test_size=0.2, random_state=11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 분류 알고리즘의 하나인 의사결정 트리 클래스 : DecisionTreeClassifier\n",
    "-  DecisionTreeClassifier 객체의 fit( ) 메서드 : 학습용 피처 데이터 속성과 결정값 데이터 세트를 입력해 호출하면 학습을 수행한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(random_state=11)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DecisionTreeClassifier 객체 생성\n",
    "dt_clf =  DecisionTreeClassifier(random_state=11)\n",
    "\n",
    "# 학습 수행\n",
    "dt_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 예측은 반드시 ! 학습데이터가 아닌 다른 데이터를 이용해야한다. 일반적으로 테스트 데이터 세트를 이용한다.\n",
    "-  DecisionTreeClassifier 객체의 predict()메서드 : 테스트용 피처 데이터 세트를 입력해 호출하면 학습된 모델 기반에서 테스트 데이터 세트에 대한 예측값을 반환하게 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습이 완료된  DecisionTreeClassifier 객체에서 테스트 데이터 세트로 예측 수행\n",
    "pred = dt_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- accuracy_score( ) 함수 : 사이킷런의 정확도 측정을 위함\n",
    "    - 첫번째 파라미터 : 실제 레이블 데이터 세트\n",
    "    - 두 번째 파라미터 : 예측 레이블 데이터 세트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측 정확도: 0.9333\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print('예측 정확도: {0:.4f}'.format(accuracy_score(y_test, pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "분류를 예측한 프로세스 정리\n",
    "1. 데이터 세트 분리 : 데이터를 학습 데이터와 테스트 데이터로 분리\n",
    "2. 모델 학습 : 학습 데이터를 기반으로 ML 알고리즘을 적용해 모델을 학습시킨다.\n",
    "3. 예측 수행 : 학습된 ML 모델을 이용해 테스트 데이터의 분류(즉, 붓꽃 종류)를 예측한다.\n",
    "3. 평가 : 이렇게 예측된 결괏값과 테스트 데이터의 실제 결괏값을비교해 ML 모델 성능을 평가한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 03. 사이킷런의 기반 프레임워크 익히기\n",
    "### Estimator 이해 및 fit( ), predict( ) 메서드\n",
    "- 지도학습의 주요 두 축인 분류와 회귀의 다양한 알고리즘을 구현한 모든 사이킷런 클래스는 fit()과 predict()만을 이용해 간단하게 학습과 예측 결과를 반환한다.\n",
    "- 사이킷런에서는 분류 알고리즘을 구현한 클래스를 Classifier로, 회귀 알고리즘을 구현한 클래스를 Regressor로 지칭힌다.\n",
    "- 분류 알고리즘과 회귀 알고리즘을 합쳐서 Estimator클래스라고 부른다. 즉 지도학습의 모든 알고리즘을 구현한 클래스를 통칭해서 Esimator라고 부른다.(당현이 이 클래스도 fit()과 predict()를 내부에서 구현함)\n",
    "- cross_val_score()와 같은 evaluation 함수, GridSearchCV와 같은 하이퍼 파라미터 튜닝을 지원하는 클래스의 경우 이 Estimator를 인자로 받는다. 인자로 받은 Estimator에 대해서 하이퍼 파라미터 튜닝을 지원하는 클래스 함수 내에서 이 Estimator의 fit과 predict를 호출해 평가를 하거나 하이퍼 파라미터 튜닝을 수행한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 비지도 학습인 차원축소, 클러스터링, 피처 추출 등을 구현한 클래스 역시 대부분 fit( )과 transform( )을 적용한다.\n",
    "- 비지도학습과 피처 추출에서 fit()은 지도학습과 같이 학습을 의미하는 것이 아니라, 입력 데이터의 형태에 맞춰 데이터를 변환하기 위한 사전구조를 맞추는 작업니다.\n",
    "- fit으로 변환을 위한 사전 구조를 맞추면 이후 입력 데이터의 차원 변환, 클러스터링, 피처 추출 등의 실제 작업은 transform()으로 수행한다.\n",
    "- fit_transform() : fit()과 transform()을 하나로 결합한것. 사용에 약간의 주의가 필요하다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 사이킷런의 주요 모듈\n",
    "- 예제 데이터\n",
    "    - sklearn.datasets : 사이킷런에 내장되어 예제로 제공하는 데이터 세트\n",
    "    \n",
    "    \n",
    "- 피처 처리\n",
    "    - sklearn.preprocessing : 데이터 전처리에 필요한 다양한 가공 기능 제공(문자열을 숫자형 코드 값으로 인코딩, 정규화, 스케일링 등)\n",
    "    - sklearn.feture_selection : 알고리즘에 큰 영향을 미치는 피처를 우선순위대로 셀렉션 작업을 수행하는 다양한 기능 제공\n",
    "    - sklearn.feature_extraction : 텍스트 데이터나 이미지 데이터의 벡터화된 피처를 추출(텍스트 데이터 피처 추출은 sklearn.feature_extraction.text 모듈에, 이미지 데이터의 피처 추출은 sklearn.feature_etraction.image 모듈에 지원 API가 있음)\n",
    "    \n",
    "\n",
    "- 피처 처리 & 차원 축소 \n",
    "    - sklearn.decomposition : 차원 축소와 관련한 알고리즘 지원. PCA, NMF, Truncated SVD 등을 통해 차원 축소 기능 수행\n",
    "\n",
    "\n",
    "- 데이터 분리, 검증 & 파라미터 튜닝\n",
    "    - sklearn.model_selection : 교차 검증을 위한 학습용/테스트용 분리, 그리드 서치로 최적 파라미터 추출 등의 API 제공\n",
    "\n",
    "\n",
    "- 평가 \n",
    "    - sklearn.metrics : 분류, 회귀, 클러스터링, 페어와이즈에 대한 다양한 성능 측정 방법 제공.(Accuracy, Precision, Recat, ROC-AUC, RMSE 등 제공)\n",
    "    \n",
    "    \n",
    "- ML 알고리즘\n",
    "    - sklearn.ensemble : 앙상블 알고리즘 제공(랜덤 포레스트, 에이다 부스트, 그래디언트 부스팅 등)\n",
    "    - sklearn.linear_model : 주로 선형회귀, 릿지, 라쏘 및 로지스틱 회귀 등 회귀 관련 알고리즘을 지원. 또한 SGD 관련 알고리즘도 제공\n",
    "    - sklearn.naive_bayes : 나이브 베이즈 알고리즘 제공. 가우시안 NB, 다항 분포 NB 등\n",
    "    - sklearn.neighbors : 최근접 이웃 알고리즘 제공. K-NN\n",
    "    - sklearn.svm : 서포트 벡터 머신 알고리즘 제공\n",
    "    - sklearn.tree : 의사 결정 알고리즘 제공\n",
    "    - sklearn.cluster : 비지도 클러스터링 알고리즘 제공(K-평균, 계층형, DBSCAN등)\n",
    "\n",
    "\n",
    "- 유틸리티\n",
    "   - sklearn.pipeline : 피처 처리 등의 변환과 ML 알고리즘 학습, 예측 등을 함께 묶어서 실행할 수 있는 유틸리티 제공"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 내장된 예제 데이터 세트\n",
    "- 사이킷런에 내장된 데이터 세트는 일반적으로 딕셔너리 형태로 되어있다.\n",
    "- 개별 키가 가리키는 데이터 세트의 의미\n",
    "    - data : 피처의 데이터 세트 (넘파이 배열 타입)\n",
    "    - target : 분류시 레이블 값, 회귀일때는 숫자 결괏값 (넘파이 배열 타입)\n",
    "    - target_names : 개별 레이블의 이름 (넘파이 배열 타입 또는 리스트타입)\n",
    "    - feature_naems : 피처의 이름 (넘파이 배열 타입 또는 리스트타입)\n",
    "    - DESCR : 데이터 세트에 대한 설명과 각 피처의 설명 (스트링타입)\n",
    "- 피처의 데이터 값을 반환받기 위해서는 내장 데이터 세트 API를 호출한 뒤에 그 키값을 지정하면 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.utils.Bunch'>\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris_data = load_iris()\n",
    "print(type(iris_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- bunch 클래스는 파이썬의 딕셔너리 자료형과 유사함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names', 'filename'])\n"
     ]
    }
   ],
   "source": [
    "# 키 값 확인\n",
    "keys = iris_data.keys()\n",
    "print(keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fearue_names의 type: <class 'list'>\n",
      "fearue_names의 shape: 4\n",
      "['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n",
      "\n",
      " target_names의 type: <class 'numpy.ndarray'>\n",
      "target_names의 shape: 3\n",
      "['setosa' 'versicolor' 'virginica']\n",
      "\n",
      " data의 type: <class 'numpy.ndarray'>\n",
      "data의 shape: (150, 4)\n",
      "[[5.1 3.5 1.4 0.2]\n",
      " [4.9 3.  1.4 0.2]\n",
      " [4.7 3.2 1.3 0.2]\n",
      " [4.6 3.1 1.5 0.2]\n",
      " [5.  3.6 1.4 0.2]\n",
      " [5.4 3.9 1.7 0.4]\n",
      " [4.6 3.4 1.4 0.3]\n",
      " [5.  3.4 1.5 0.2]\n",
      " [4.4 2.9 1.4 0.2]\n",
      " [4.9 3.1 1.5 0.1]\n",
      " [5.4 3.7 1.5 0.2]\n",
      " [4.8 3.4 1.6 0.2]\n",
      " [4.8 3.  1.4 0.1]\n",
      " [4.3 3.  1.1 0.1]\n",
      " [5.8 4.  1.2 0.2]\n",
      " [5.7 4.4 1.5 0.4]\n",
      " [5.4 3.9 1.3 0.4]\n",
      " [5.1 3.5 1.4 0.3]\n",
      " [5.7 3.8 1.7 0.3]\n",
      " [5.1 3.8 1.5 0.3]\n",
      " [5.4 3.4 1.7 0.2]\n",
      " [5.1 3.7 1.5 0.4]\n",
      " [4.6 3.6 1.  0.2]\n",
      " [5.1 3.3 1.7 0.5]\n",
      " [4.8 3.4 1.9 0.2]\n",
      " [5.  3.  1.6 0.2]\n",
      " [5.  3.4 1.6 0.4]\n",
      " [5.2 3.5 1.5 0.2]\n",
      " [5.2 3.4 1.4 0.2]\n",
      " [4.7 3.2 1.6 0.2]\n",
      " [4.8 3.1 1.6 0.2]\n",
      " [5.4 3.4 1.5 0.4]\n",
      " [5.2 4.1 1.5 0.1]\n",
      " [5.5 4.2 1.4 0.2]\n",
      " [4.9 3.1 1.5 0.2]\n",
      " [5.  3.2 1.2 0.2]\n",
      " [5.5 3.5 1.3 0.2]\n",
      " [4.9 3.6 1.4 0.1]\n",
      " [4.4 3.  1.3 0.2]\n",
      " [5.1 3.4 1.5 0.2]\n",
      " [5.  3.5 1.3 0.3]\n",
      " [4.5 2.3 1.3 0.3]\n",
      " [4.4 3.2 1.3 0.2]\n",
      " [5.  3.5 1.6 0.6]\n",
      " [5.1 3.8 1.9 0.4]\n",
      " [4.8 3.  1.4 0.3]\n",
      " [5.1 3.8 1.6 0.2]\n",
      " [4.6 3.2 1.4 0.2]\n",
      " [5.3 3.7 1.5 0.2]\n",
      " [5.  3.3 1.4 0.2]\n",
      " [7.  3.2 4.7 1.4]\n",
      " [6.4 3.2 4.5 1.5]\n",
      " [6.9 3.1 4.9 1.5]\n",
      " [5.5 2.3 4.  1.3]\n",
      " [6.5 2.8 4.6 1.5]\n",
      " [5.7 2.8 4.5 1.3]\n",
      " [6.3 3.3 4.7 1.6]\n",
      " [4.9 2.4 3.3 1. ]\n",
      " [6.6 2.9 4.6 1.3]\n",
      " [5.2 2.7 3.9 1.4]\n",
      " [5.  2.  3.5 1. ]\n",
      " [5.9 3.  4.2 1.5]\n",
      " [6.  2.2 4.  1. ]\n",
      " [6.1 2.9 4.7 1.4]\n",
      " [5.6 2.9 3.6 1.3]\n",
      " [6.7 3.1 4.4 1.4]\n",
      " [5.6 3.  4.5 1.5]\n",
      " [5.8 2.7 4.1 1. ]\n",
      " [6.2 2.2 4.5 1.5]\n",
      " [5.6 2.5 3.9 1.1]\n",
      " [5.9 3.2 4.8 1.8]\n",
      " [6.1 2.8 4.  1.3]\n",
      " [6.3 2.5 4.9 1.5]\n",
      " [6.1 2.8 4.7 1.2]\n",
      " [6.4 2.9 4.3 1.3]\n",
      " [6.6 3.  4.4 1.4]\n",
      " [6.8 2.8 4.8 1.4]\n",
      " [6.7 3.  5.  1.7]\n",
      " [6.  2.9 4.5 1.5]\n",
      " [5.7 2.6 3.5 1. ]\n",
      " [5.5 2.4 3.8 1.1]\n",
      " [5.5 2.4 3.7 1. ]\n",
      " [5.8 2.7 3.9 1.2]\n",
      " [6.  2.7 5.1 1.6]\n",
      " [5.4 3.  4.5 1.5]\n",
      " [6.  3.4 4.5 1.6]\n",
      " [6.7 3.1 4.7 1.5]\n",
      " [6.3 2.3 4.4 1.3]\n",
      " [5.6 3.  4.1 1.3]\n",
      " [5.5 2.5 4.  1.3]\n",
      " [5.5 2.6 4.4 1.2]\n",
      " [6.1 3.  4.6 1.4]\n",
      " [5.8 2.6 4.  1.2]\n",
      " [5.  2.3 3.3 1. ]\n",
      " [5.6 2.7 4.2 1.3]\n",
      " [5.7 3.  4.2 1.2]\n",
      " [5.7 2.9 4.2 1.3]\n",
      " [6.2 2.9 4.3 1.3]\n",
      " [5.1 2.5 3.  1.1]\n",
      " [5.7 2.8 4.1 1.3]\n",
      " [6.3 3.3 6.  2.5]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [7.1 3.  5.9 2.1]\n",
      " [6.3 2.9 5.6 1.8]\n",
      " [6.5 3.  5.8 2.2]\n",
      " [7.6 3.  6.6 2.1]\n",
      " [4.9 2.5 4.5 1.7]\n",
      " [7.3 2.9 6.3 1.8]\n",
      " [6.7 2.5 5.8 1.8]\n",
      " [7.2 3.6 6.1 2.5]\n",
      " [6.5 3.2 5.1 2. ]\n",
      " [6.4 2.7 5.3 1.9]\n",
      " [6.8 3.  5.5 2.1]\n",
      " [5.7 2.5 5.  2. ]\n",
      " [5.8 2.8 5.1 2.4]\n",
      " [6.4 3.2 5.3 2.3]\n",
      " [6.5 3.  5.5 1.8]\n",
      " [7.7 3.8 6.7 2.2]\n",
      " [7.7 2.6 6.9 2.3]\n",
      " [6.  2.2 5.  1.5]\n",
      " [6.9 3.2 5.7 2.3]\n",
      " [5.6 2.8 4.9 2. ]\n",
      " [7.7 2.8 6.7 2. ]\n",
      " [6.3 2.7 4.9 1.8]\n",
      " [6.7 3.3 5.7 2.1]\n",
      " [7.2 3.2 6.  1.8]\n",
      " [6.2 2.8 4.8 1.8]\n",
      " [6.1 3.  4.9 1.8]\n",
      " [6.4 2.8 5.6 2.1]\n",
      " [7.2 3.  5.8 1.6]\n",
      " [7.4 2.8 6.1 1.9]\n",
      " [7.9 3.8 6.4 2. ]\n",
      " [6.4 2.8 5.6 2.2]\n",
      " [6.3 2.8 5.1 1.5]\n",
      " [6.1 2.6 5.6 1.4]\n",
      " [7.7 3.  6.1 2.3]\n",
      " [6.3 3.4 5.6 2.4]\n",
      " [6.4 3.1 5.5 1.8]\n",
      " [6.  3.  4.8 1.8]\n",
      " [6.9 3.1 5.4 2.1]\n",
      " [6.7 3.1 5.6 2.4]\n",
      " [6.9 3.1 5.1 2.3]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [6.8 3.2 5.9 2.3]\n",
      " [6.7 3.3 5.7 2.5]\n",
      " [6.7 3.  5.2 2.3]\n",
      " [6.3 2.5 5.  1.9]\n",
      " [6.5 3.  5.2 2. ]\n",
      " [6.2 3.4 5.4 2.3]\n",
      " [5.9 3.  5.1 1.8]]\n",
      "\n",
      " target의 type: <class 'numpy.ndarray'>\n",
      "\n",
      " target의 shape: (150,)\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n"
     ]
    }
   ],
   "source": [
    "# load_iris()가 반환하는 객체의 키가 가리키는 값들\n",
    "print('fearue_names의 type:', type(iris_data.feature_names))\n",
    "print('fearue_names의 shape:', len(iris_data.feature_names))\n",
    "print(iris_data.feature_names)\n",
    "\n",
    "print('\\n target_names의 type:', type(iris_data.target_names))\n",
    "print('target_names의 shape:', len(iris_data.target_names))\n",
    "print(iris_data.target_names)\n",
    "\n",
    "print('\\n data의 type:', type(iris_data.data))\n",
    "print('data의 shape:', iris_data.data.shape)\n",
    "print(iris_data['data'])\n",
    "\n",
    "print('\\n target의 type:', type(iris_data.target))\n",
    "print('\\n target의 shape:', iris_data.target.shape)\n",
    "print(iris_data.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 04. Model Selection 모듈 소개\n",
    "### 학습/테스트 데이터 세트 분리 - train_test_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측 정확도: 1.0\n"
     ]
    }
   ],
   "source": [
    "# 학습과 예측을 동일한 데이터 세트로 수행\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "iris = load_iris()\n",
    "dt_clf = DecisionTreeClassifier()\n",
    "train_data = iris.data\n",
    "train_label = iris.target\n",
    "dt_clf.fit(train_data, train_label)\n",
    "\n",
    "# 학습 데이터 세트로 예측 수행\n",
    "pred = dt_clf.predict(train_data)\n",
    "print('예측 정확도:', accuracy_score(train_label, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이미 학습한 학습 데이터 세트를 기반으로 예측했기 때문에 이런 결과가 나왔다. 따라서 예측을 수행하는 데이터 세트는 학습을 수행한 학습용 데이터 세트가 아닌 전용의 테스트 데이터 세트여야한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- sklearn.model_selection 모듈의 train_test_split\n",
    "     - test_size : 전체 데이터에서 테스트 데이터 세트 크기를 얼마로 샘플링 할 것인가를 결정(디폴트는 0.25(25%)이다.)\n",
    "     - train_size : 전체 데이터에서 학습용 데이터 세트 크기를 얼마로 샘플링 할 것인가(잘 사용X)\n",
    "     - shuffle : 데이터를 분리하기 전에 데이터를 미리 섞을지 결정(디폴트 True) 데이터를 분산시켜서 좀 더 효율적인 학습 및 테스트 데이터 세트를 만드는데 사용\n",
    "     - random_state : 호출할 때마다 동일한 학습/테스트용 데이터 세트 생성하기 위해 주어지는 난수값\n",
    "     - train_test_split() 의 반환 값은 튜플 형태이다. 순차적으로 학습용 데이터의 피처 데이터 세트, 테스트용 데이터의 피처데이터 세트, 학습용 데이터의 레이블 데이터세트, 테스트용 데이터의 레이블 데이터 세트가 반환된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "dt_clf = DecisionTreeClassifier()\n",
    "iris_data = load_iris()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris_data.data, iris_data.target, test_size = 0.3, random_state=121)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측 정확도: 0.9556\n"
     ]
    }
   ],
   "source": [
    "dt_clf.fit(X_train, y_train)\n",
    "pred = dt_clf.predict(X_test)\n",
    "print('예측 정확도: {0:.4f}'.format(accuracy_score(y_test, pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 교차 검증\n",
    "- 과적합 : 모델이 학습 데이터에만 과도하게 최적화되어 실제 예측을 다른 데이터로 수행할 경우에는 예측 성능이 과도하게 떨어지는 것.\n",
    "- ML은 데이터에 기반한다. 그리고 데이터는 이상치, 분포도, 다양한 속성값, 피처 중요도 등 여러가지 ml에 영향을 미치는 요소를 가지고 있다. \n",
    "    - 특정 ml알고리즘에서 최적으로 동작할 수 있도록 데이터를 선별해 학습하면 실제 데이터 양식과는 많은 차이가 있을 것이고 결국 성능 저하로 이어진다.\n",
    "- 교차검증 : 이러한 데이터 편중을 막기 위해 별도의 여러 세트로 구성된 학습 데이터 세트와 검증 데이터 세트에서 학습과 평가를 수행하는 것. 그리고 각 세트에서 수행한 평가 결과에 따라 하잍퍼 파라미터 튜닝 등의 모델 최적화를 더욱 손쉬게 할 수 있다.\n",
    "    - 대부분의 ml 모델의 성능 평가는 교차검증 기반으로, 1차 평가를 한 뒤에 최종적으로 테스트 데이터 세트에 적용해 평가하는 프로세스이다.\n",
    "    - ml에 사용되는 데이터 세트를 세분화해서 학습, 검증, 테스트 데이터 세트로 나눌 수 있다.\n",
    "    - 테스트 데이터 세트 외에 별도의 검증 데이터 세트를 둬서 최종 평가 이전에 학습된 모델을 다양하게 평가하는 데 사용한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### K 폴드 교차 검증\n",
    ": 가장 보편적으로 사용되는 교차 검증 기법이다. 먼저 K개의 데이터 폴드 세트를 만들어서 K번만큼 각 폴트 세트에 학습과 검증 평가를 반복적으로 수행하는 방법\n",
    "- 데이터 세트와 검증 데이터 세트를 점진적으로 변경하면서 마지막 K번째까지 학습과 검증을 수행하는 것\n",
    "- K개의 예측 평가를 구했으면 이를 평균해서 K폴드 평가 결과로 바녕ㅇ한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "붓꽃 데이터 세트 크기: 150\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "\n",
    "iris = load_iris()\n",
    "features = iris.data\n",
    "label = iris.target\n",
    "dt_clf = DecisionTreeClassifier(random_state=156)\n",
    "\n",
    "# 5개의 폴드 세트로 분리하는 KFold 객체와 폴드 세트별 정확도를 담을 리스트 객체 생성\n",
    "kfold = KFold(n_splits=5)\n",
    "cv_accuracy = []\n",
    "print('붓꽃 데이터 세트 크기:', features.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- KFold 객체는 split()을 호출하면 학습용/검증용 데이터로 분할할 수 있는 인덱스를 반환한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "#1 교차 검증 정확도 :1.0, 학습 데이터 크기: 120, 검증 데이터 크기: 30\n",
      "#1 검증 세트 인덱스:[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29]\n",
      "\n",
      "#2 교차 검증 정확도 :0.9667, 학습 데이터 크기: 120, 검증 데이터 크기: 30\n",
      "#2 검증 세트 인덱스:[30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53\n",
      " 54 55 56 57 58 59]\n",
      "\n",
      "#3 교차 검증 정확도 :0.8667, 학습 데이터 크기: 120, 검증 데이터 크기: 30\n",
      "#3 검증 세트 인덱스:[60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83\n",
      " 84 85 86 87 88 89]\n",
      "\n",
      "#4 교차 검증 정확도 :0.9333, 학습 데이터 크기: 120, 검증 데이터 크기: 30\n",
      "#4 검증 세트 인덱스:[ 90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119]\n",
      "\n",
      "#5 교차 검증 정확도 :0.7333, 학습 데이터 크기: 120, 검증 데이터 크기: 30\n",
      "#5 검증 세트 인덱스:[120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137\n",
      " 138 139 140 141 142 143 144 145 146 147 148 149]\n",
      "\n",
      "## 평균 검증 정확도: 0.9\n"
     ]
    }
   ],
   "source": [
    "n_iter = 0\n",
    "\n",
    "# KFold 객체의 split()를 호출하면 폴드 별 학습용, 검증용 테스트의 로우 인덱스를 array로 반환\n",
    "for train_index, test_index in kfold.split(features):\n",
    "    # kfold.split()으로 반환된 인덱스를 이용해 학습용, 검증용 테스트 데이터 추출\n",
    "    X_train, X_test = features[train_index], features[test_index]\n",
    "    y_train, y_test = label[train_index], label[test_index]\n",
    "    # 학습 미 예측\n",
    "    dt_clf.fit(X_train, y_train)\n",
    "    pred = dt_clf.predict(X_test)\n",
    "    n_iter += 1\n",
    "    # 반복시마다 정확도 측정 \n",
    "    accuracy = np.round(accuracy_score(y_test, pred), 4)\n",
    "    train_size = X_train.shape[0]\n",
    "    test_size = X_test.shape[0]\n",
    "    print('\\n#{0} 교차 검증 정확도 :{1}, 학습 데이터 크기: {2}, 검증 데이터 크기: {3}'\n",
    "          .format(n_iter, accuracy, train_size, test_size))\n",
    "    print('#{0} 검증 세트 인덱스:{1}'.format(n_iter,test_index))\n",
    "    cv_accuracy.append(accuracy)\n",
    "    \n",
    "# 개별 iteration별 정확도를 합하여 평균 정확도 계산 \n",
    "print('\\n## 평균 검증 정확도:', np.mean(cv_accuracy)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stratified K 폴드\n",
    ": 불균형한 분포도를 가진 레이블 데이터 집합을 위한 K 폴드 방식이다. \n",
    "- 불균형한 분포도를 가진 레이블 데이터 집합은 특정 레이블 값이 특이하게 많거나 매우 적어서 값의 분포가 한쪽으로 치우치는 것을 말한다.\n",
    "- stratified K 폴드는 K폴드가 레이블 데이터 집합이 원본 데이터 집합의 레이블 분포를 학습 및 테스트 세트에 제대로 분배하지 못하는 경우의 문제를 해결해준다.\n",
    "- 이를 위해 stratified K 폴드는 원본 데이터의 레이블 분포를 먼저 고려한 뒤, 이 분포와 동일하게 학습과 검증 데이터 세트를 분배한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    50\n",
       "1    50\n",
       "0    50\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "iris = load_iris()\n",
    "\n",
    "iris_df = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n",
    "iris_df['label']=iris.target\n",
    "iris_df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## 교차 검증: 1\n",
      "학습 레이블 데이터 분포:\n",
      " 2    50\n",
      "1    50\n",
      "Name: label, dtype: int64\n",
      "검증 레이블 데이터 분포:\n",
      " 0    50\n",
      "Name: label, dtype: int64\n",
      "## 교차 검증: 2\n",
      "학습 레이블 데이터 분포:\n",
      " 2    50\n",
      "0    50\n",
      "Name: label, dtype: int64\n",
      "검증 레이블 데이터 분포:\n",
      " 1    50\n",
      "Name: label, dtype: int64\n",
      "## 교차 검증: 3\n",
      "학습 레이블 데이터 분포:\n",
      " 1    50\n",
      "0    50\n",
      "Name: label, dtype: int64\n",
      "검증 레이블 데이터 분포:\n",
      " 2    50\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "kfold = KFold(n_splits=3)\n",
    "\n",
    "# kfold.split(X)는 폴드 세트를 3번 반복할 때마다 달라지는 학습/테스트 용 데이터 로우 인덱스 번호 반환. \n",
    "n_iter =0\n",
    "for train_index, test_index  in kfold.split(iris_df):\n",
    "    n_iter += 1\n",
    "    label_train= iris_df['label'].iloc[train_index]\n",
    "    label_test= iris_df['label'].iloc[test_index]\n",
    "    print('## 교차 검증: {0}'.format(n_iter))\n",
    "    print('학습 레이블 데이터 분포:\\n', label_train.value_counts())\n",
    "    print('검증 레이블 데이터 분포:\\n', label_test.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- StratifiedKFold는 이처럼 KFold로 분할된 레이블 데이터 세트가 전체 레이블 값의 분포도를 반영하지 못하는 문제를 해결해준다.\n",
    "- KFold와의 사용시의 큰 차이는 stratifiedkfold는 레이블 데이터 분포도에 따라 학습/검증 데이터를 나누기 때문에 split()메서드에 인자로 피처 데이터 세트뿐만 아니라 레이블 데이터 세트도 반드시 필요하다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## 교차 검증: 1\n",
      "학습 레이블 데이터 분포:\n",
      " 2    34\n",
      "1    33\n",
      "0    33\n",
      "Name: label, dtype: int64\n",
      "검증 레이블 데이터 분포:\n",
      " 1    17\n",
      "0    17\n",
      "2    16\n",
      "Name: label, dtype: int64\n",
      "## 교차 검증: 2\n",
      "학습 레이블 데이터 분포:\n",
      " 1    34\n",
      "2    33\n",
      "0    33\n",
      "Name: label, dtype: int64\n",
      "검증 레이블 데이터 분포:\n",
      " 2    17\n",
      "0    17\n",
      "1    16\n",
      "Name: label, dtype: int64\n",
      "## 교차 검증: 3\n",
      "학습 레이블 데이터 분포:\n",
      " 0    34\n",
      "2    33\n",
      "1    33\n",
      "Name: label, dtype: int64\n",
      "검증 레이블 데이터 분포:\n",
      " 2    17\n",
      "1    17\n",
      "0    16\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "skf = StratifiedKFold(n_splits=3)\n",
    "n_iter=0\n",
    "\n",
    "for train_index, test_index in skf.split(iris_df, iris_df['label']):\n",
    "    n_iter += 1\n",
    "    label_train= iris_df['label'].iloc[train_index]\n",
    "    label_test= iris_df['label'].iloc[test_index]\n",
    "    print('## 교차 검증: {0}'.format(n_iter))\n",
    "    print('학습 레이블 데이터 분포:\\n', label_train.value_counts())\n",
    "    print('검증 레이블 데이터 분포:\\n', label_test.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "학습 레이블과 검증 레이블 데이터 값의 분포도가 동일하게 할당 됐음을 알 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "#1 교차 검증 정확도 :0.98, 학습 데이터 크기: 100, 검증 데이터 크기: 50\n",
      "#1 검증 세트 인덱스:[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  50\n",
      "  51  52  53  54  55  56  57  58  59  60  61  62  63  64  65  66 100 101\n",
      " 102 103 104 105 106 107 108 109 110 111 112 113 114 115]\n",
      "\n",
      "#2 교차 검증 정확도 :0.94, 학습 데이터 크기: 100, 검증 데이터 크기: 50\n",
      "#2 검증 세트 인덱스:[ 17  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  67\n",
      "  68  69  70  71  72  73  74  75  76  77  78  79  80  81  82 116 117 118\n",
      " 119 120 121 122 123 124 125 126 127 128 129 130 131 132]\n",
      "\n",
      "#3 교차 검증 정확도 :0.98, 학습 데이터 크기: 100, 검증 데이터 크기: 50\n",
      "#3 검증 세트 인덱스:[ 34  35  36  37  38  39  40  41  42  43  44  45  46  47  48  49  83  84\n",
      "  85  86  87  88  89  90  91  92  93  94  95  96  97  98  99 133 134 135\n",
      " 136 137 138 139 140 141 142 143 144 145 146 147 148 149]\n",
      "\n",
      "## 교차 검증별 정확도: [0.98 0.94 0.98]\n",
      "## 평균 검증 정확도: 0.9666666666666667\n"
     ]
    }
   ],
   "source": [
    "dt_clf = DecisionTreeClassifier(random_state=156)\n",
    "\n",
    "skfold = StratifiedKFold(n_splits=3)\n",
    "n_iter=0\n",
    "cv_accuracy=[]\n",
    "\n",
    "# StratifiedKFold의 split( ) 호출시 반드시 레이블 데이터 셋도 추가 입력 필요  \n",
    "for train_index, test_index  in skfold.split(features, label):\n",
    "    # split( )으로 반환된 인덱스를 이용하여 학습용, 검증용 테스트 데이터 추출\n",
    "    X_train, X_test = features[train_index], features[test_index]\n",
    "    y_train, y_test = label[train_index], label[test_index]\n",
    "    #학습 및 예측 \n",
    "    dt_clf.fit(X_train , y_train)    \n",
    "    pred = dt_clf.predict(X_test)\n",
    "\n",
    "    # 반복 시 마다 정확도 측정 \n",
    "    n_iter += 1\n",
    "    accuracy = np.round(accuracy_score(y_test,pred), 4)\n",
    "    train_size = X_train.shape[0]\n",
    "    test_size = X_test.shape[0]\n",
    "    print('\\n#{0} 교차 검증 정확도 :{1}, 학습 데이터 크기: {2}, 검증 데이터 크기: {3}'\n",
    "          .format(n_iter, accuracy, train_size, test_size))\n",
    "    print('#{0} 검증 세트 인덱스:{1}'.format(n_iter,test_index))\n",
    "    cv_accuracy.append(accuracy)\n",
    "    \n",
    "# 교차 검증별 정확도 및 평균 정확도 계산 \n",
    "print('\\n## 교차 검증별 정확도:', np.round(cv_accuracy, 4))\n",
    "print('## 평균 검증 정확도:', np.mean(cv_accuracy)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 이렇게 stratified K 폴드의 경우 원본 데이터의 레이블 분포도 특성을 반영한 학습 및 검증 데이터 세트를 만들 수 있으므로 왜곡된 레이블 데이터 세트에서는 반드시 이를 이용해 교차 검증 해햐한다.\n",
    "- 사실 일반적으로 분류에서의 교차검증은 K 폴드가 아니라 stratified K폴드로 분할돼야 한다. \n",
    "- 하지만 회귀에서는 지원되지 않는다(회귀의 결정값은 이산값 형태의 레이블이 아니라 연속된 숫자값이기 때문)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 교차 검증을 보다 간편하게 - cross_val_score()\n",
    ": API 내부에서 Estimator를 학습(fit), 예측(predict), 평가(evaluation)시켜주므로 간단하게 교차 검증을 수행할 수 있다.\n",
    "- 폴드세트를 설정하고 for 루프에서 반복으로 학습 및 테스트 데이터의 인덱스를 추출한 뒤 반복적으로 학습과 예측을 수행하고 예측성능을 반환하는 것을 한꺼번에 수행해준다 !\n",
    "- 주요 파라미터\n",
    "    - estimator : 사이킷런의 분류 알고리즘 클래스인 Classifier 또는 회귀 알고리즘 클래스인 Regressor을 의미한다.\n",
    "    - X : 피처 데이터 세트\n",
    "    - y : 레이블 데이터 세트\n",
    "    - scoring : 예측 성능 평가 지표를 기술\n",
    "    - cv : 교차 검증 폴드 수 \n",
    "- 수행 후 반환 값은 cv로 지정된 횟수만큼 scoring파라미터로 지정된 평가 지표로 평가 결괏값을 배열로 반환한다. 일반적으로 이를 평균해 평가 수치로 사용한다.\n",
    "- classifier가 입력되면 stratified K 폴드 방식으로 레이블 값의 분포에 따라 학습/테스트 세트를 분할한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "교차 검증별 정확도: [0.98 0.94 0.98]\n",
      "평균 검증 정확도: 0.9667\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score, cross_validate\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris_data = load_iris()\n",
    "dt_clf = DecisionTreeClassifier(random_state=156)\n",
    "\n",
    "data = iris_data.data\n",
    "label = iris_data.target\n",
    "\n",
    "# 성능 지표는 정확도, 교차 검증 세트는 3개\n",
    "scores = cross_val_score(dt_clf, data, label, scoring='accuracy', cv = 3)\n",
    "print('교차 검증별 정확도:', np.round(scores, 4))\n",
    "print('평균 검증 정확도:', np.round(np.mean(scores), 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 비슷한 API로 cross_validat( )가 있다. \n",
    "    - 여러개의 평가 지표를 반환할 수 있다. \n",
    "    - 학습 데이터에 대한 성능, 평가 지표와 수행 시간도 같이 제공한다.\n",
    "    - 그러나 보통 cross_val_score() 하나로도 대부분의 경우 쉽게 사용한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridSearchCV - 교차 검증과 최적 하이퍼 파라미터 튜닝을 한번에\n",
    ": Classifier나 Regressor와 같은 알고리즘에 사용되는 하이퍼 파라미터를순차적으로 입력하면서 편리하게 최적의 파라미터를 도출할 수 있는 방안을 제공한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_parameters = { 'max_depth':[1, 2, 3],\n",
    "                  'min_samples_split':[2, 3]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- GridSearchCV는 교차검증을 기반으로 이 하이퍼 파라미터의 최적값을 찾게 해준다. 즉, 데이터 세트는 교차 검증을 위한 학습/테스트 세트로 자동으로 분할한 뒤에 하이퍼 파라미터 그리드에 기술된 모든 파라미터를 순차적으로 적용해 최적의 파라미터를 찾을 수 있게 해준다.\n",
    "    - !순차적으로 파라미터를 테스트하므로 수행시간이 상대적으로 오래 걸림\n",
    "    - (grid_parameters는 6회에 걸쳐 하이퍼 파라미터를 변경하면서 교차 검증 데이터 세트에 수행 성능을 측정하는데 cv가 3회이면 3*6 = 18회의 학습/평가가 이루어진다.\n",
    "- 주요 파라미터\n",
    "    - estimator : classifier, regressor, pipeline이 사용될 수 있다.\n",
    "    - prarm_grid : key + 리스트 값을 가지는 딕셔너리가 주어진다. estimator의 튜닝을 위해 파라미터명과 사용될 여러 파라미터 값을 지정\n",
    "    - scoring : 예측 성능을 측정할 평가 방법 지정. 보통은 사이킷런의 성능 평가 지표를 지정하는 문자열로 지정하나 별도의 성능 평가 지표 함수도 지정할 수 있다.\n",
    "    - cv : 교차검증을 위해 분할되는 학습/테스트 세트의 개수\n",
    "    - refit : 디폴트 True로 설정시 가장 최적의 하이퍼 파라미터를 찾은 뒤 입력된 estimator 객체를 해당 하이퍼파라미터로 재학습시킨다.\n",
    "        - 또, true로 설정하면 GridSearchCV가 최적 성능을 나타내는 하이퍼 파라미터로 Estimator를 학습해 best_estimator_로 저장한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# 데이터를 로딩하고 학습데이터와 테스트 데이터 분리\n",
    "iris_data = load_iris()\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris_data.data, iris_data.target, test_size = 0.2, random_state=121)\n",
    "dtree = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- GridSearchCV 객체의 fit(학습데이터세트) 메서드를 수행하면, 학습 데이터를 cv에 기술된 폴딩 세트로 분할해 param_grid에 기술된 하이퍼 파라미터를 순차적으로 변경하면서 학습/평가를 수행하고 그 결과를 cv_results_속성에 기록한다.\n",
    "    - cv_result는 gridsearchcv의 결과 세트로서 딕셔너리 형태로 key 값과 리스트 형태의 value 값을 가진다.\n",
    "    - fit()를 수행하면 최고 성능을 나타낸 하이퍼 파라미터의 값과 그때의 평가 결과 값이 각각 best_params_, best_score_속성에 기록된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'max_depth': 1, 'min_samples_split': 2}</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'max_depth': 1, 'min_samples_split': 3}</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'max_depth': 2, 'min_samples_split': 2}</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>3</td>\n",
       "      <td>0.925</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'max_depth': 2, 'min_samples_split': 3}</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>3</td>\n",
       "      <td>0.925</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'max_depth': 3, 'min_samples_split': 2}</td>\n",
       "      <td>0.975000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.975</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{'max_depth': 3, 'min_samples_split': 3}</td>\n",
       "      <td>0.975000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.975</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     params  mean_test_score  rank_test_score  \\\n",
       "0  {'max_depth': 1, 'min_samples_split': 2}         0.700000                5   \n",
       "1  {'max_depth': 1, 'min_samples_split': 3}         0.700000                5   \n",
       "2  {'max_depth': 2, 'min_samples_split': 2}         0.958333                3   \n",
       "3  {'max_depth': 2, 'min_samples_split': 3}         0.958333                3   \n",
       "4  {'max_depth': 3, 'min_samples_split': 2}         0.975000                1   \n",
       "5  {'max_depth': 3, 'min_samples_split': 3}         0.975000                1   \n",
       "\n",
       "   split0_test_score  split1_test_score  split2_test_score  \n",
       "0              0.700                0.7               0.70  \n",
       "1              0.700                0.7               0.70  \n",
       "2              0.925                1.0               0.95  \n",
       "3              0.925                1.0               0.95  \n",
       "4              0.975                1.0               0.95  \n",
       "5              0.975                1.0               0.95  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# param_grid의 하이퍼 파라미터를 3개의 train, test et fold로 나누어 테스트 수행 설정\n",
    "### refit = Truerk default임. True이면 가장 좋은 파라미터 설정으로 재학습시킨다.\n",
    "grid_dtree = GridSearchCV(dtree, param_grid = grid_parameters, cv=3, refit=True)\n",
    "\n",
    "# 붓꽃 학습 데이터로 param_grid의 하이퍼 파라미터를 순차적으로 학습/평가\n",
    "grid_dtree.fit(X_train, y_train)\n",
    "\n",
    "# GridSearchCV 결과를 추출해 데이터 프레임으로 변환\n",
    "scores_df = pd.DataFrame(grid_dtree.cv_results_)\n",
    "scores_df[['params', 'mean_test_score', 'rank_test_score', \\\n",
    "           'split0_test_score', 'split1_test_score', 'split2_test_score']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "주요 칼럼별 의미\n",
    "- params : 수행할 때마다 적용된 개별 하이퍼 파라미터 값을 나타낸다.\n",
    "- mean_test_score : 개별 하이퍼 파라미터별로 CV의 폴딩 테스트 세트에 대해 총 수행한 평가 평균값이다.\n",
    "- rank_test_score : 하이퍼 파라미터별로 성능이 좋은 score순위를 나타낸다. 1이 가장 뛰어난 순위이며 이떄의 파라미터가 최적의 하이퍼 파라미터이다.\n",
    "- split0_test_score, split1_test_score, split2_test_score : cv가 3인 경우, 즉 3개의 폴딩 세트에서 각각 테스트한 성능 수치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV 최적 파라미터: {'max_depth': 3, 'min_samples_split': 2}\n",
      "GridSearchCV 최고 정확도:0.9750\n"
     ]
    }
   ],
   "source": [
    "print('GridSearchCV 최적 파라미터:', grid_dtree.best_params_)\n",
    "print('GridSearchCV 최고 정확도:{0:.4f}' .format(grid_dtree.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테스트 데이터 세트 정확도:0.9667\n"
     ]
    }
   ],
   "source": [
    "# GridSearchCV의 refit으로 이미 학습된 최적 estimator 반환\n",
    "estimator = grid_dtree.best_estimator_\n",
    "\n",
    "# GridSearchCV의 best_estimator_는 이미 최적 학습이 됐으므로 별도 학습이 필요 없음\n",
    "pred = estimator.predict(X_test)\n",
    "print('테스트 데이터 세트 정확도:{0:.4f}'.format(accuracy_score(y_test,pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 05. 데이터 전처리\n",
    "사이킷런의 ML 알고리즘을 적용하기 전에 데이터에 대해 미리 처리해야 할 기본사항\n",
    "1. 결손값, 즉 NaN, Null값은 허용되지 않는다. 따라서 이러한 Null값은 고정된 다른 값으로 변환되어야 한다.\n",
    "    - 피처값 중 널값이 얼마 되지 않는다면 피처의 평균값 등으로 간단히 대처할 수 있다.\n",
    "    - 널이 대부분이라면 오히려 해당 피처는 드롭하는 것이 더 좋다.\n",
    "2. 사이킷런의 머신러닝 알고리즘은 문자열 값을 입력값으로 허용하지 않는다. 그래서 모든 문자열 값은 인코딩돼서 숫자 형으로 변환해야 한다.\n",
    "    - 카테고리형 피처 -> 코드 값으로 표현\n",
    "    - 텍스트형 피처 -> 피처 벡터화 등의 기법으로 벡터화하거나 불필요한 피처라고 판단되면 삭제한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 인코딩\n",
    "#### 레이블 인코딩\n",
    ": 카테고리 피처를 코드형 숫자 값으로 변환하는 것이다. 즉, 문자열 값을 숫자형 카테고리 값으로 변환한다.\n",
    "- 주의점 : '01', '02' 같은 코드값 역시 문자열이므로 1, 2와 같은 숫자형값으로 변환돼야 한다.\n",
    "- LabelEncoder 클래스로 구현하며, 이를 객체로 생성한 후 fit과 transform을 호출해 레이블 인코딩을 수행한다.\n",
    "- 레이블 인코딩은 선형 회귀와 같은 ML 알고리즘에는 적용하지 않아야한다.\n",
    "    -  숫자값으로 변환되면서 위와 같은 알고리즘에는 이를 적용하면 숫자 값의 경우 크고 작음에 대한 특성이 작용하여 예측 성능이 떨어지는 경우가 발생하기 때문이다.\n",
    "    - 원핫 인코딩은 레이블 인코딩의 이러한 문제점을 해결한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "인코딩 반환값: [0 1 4 5 3 3 2 2]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "items = ['TV', '냉장고', '전자레인지', '컴퓨터', '선풍기', '선풍기', '믹서', '믹서']\n",
    "\n",
    "# LabelEncoder객체로 생성한 후 fit과 transform을 호출해 레이블 인코딩을 수행한다.\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(items)\n",
    "labels = encoder.transform(items)\n",
    "print('인코딩 반환값:', labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- classes_ 속성 : 문자열 값이 어떤 숫자 값으로 인코딩 됐는지 알 수 있다.\n",
    "    - 0번부터 순서대로 변환된 인코딩 값에 대한 원본 값을 가지고 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['TV' '냉장고' '믹서' '선풍기' '전자레인지' '컴퓨터']\n"
     ]
    }
   ],
   "source": [
    "print(encoder.classes_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- inverse_transform()을 통해 인코딩된 값을 다시 디코딩할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['전자레인지' '컴퓨터' '믹서' 'TV' '냉장고' '냉장고' '선풍기' '선풍기']\n"
     ]
    }
   ],
   "source": [
    "print(encoder.inverse_transform([4, 5, 2, 0, 1, 1, 3, 3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 원-핫 인코딩(One-Hot Encoding)\n",
    ": 피처 값의 유형에 따라 새로운 피처를 추가해 고유 값에 해당하는 칼럼에만 1을 표시하고 나머지 칼럼에는 0을 표시하는 방식이다.\n",
    "- 즉, 행 형태로 돼 있는 피처의 고유 값을 열 형태로 차원을 변환한 뒤, 고유 값에 해당하는 칼럼에만 1을 표시하고 나머지 칼럼에는 0을 표시한다.\n",
    "    - 원-핫 : (여러개의 속성 중 단 한 개의 속성만 1로 표시)\n",
    "- OneHotEncoder 클래스로 쉽게 변환이 가능하다.\n",
    "- 주의점\n",
    "    1. OneHotEncoder로 변환하기 전에 모든 문자열 값이 숫자형 값으로 변환돼야 한다.\n",
    "    2. 입력 값으로 2차원 데이터가 필요하다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원 핫 인코딩 데이터\n",
      "[[1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]]\n",
      "\n",
      "원 핫 인코딩 데이터 차원\n",
      "(8, 6)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import numpy as np\n",
    "\n",
    "items = ['TV', '냉장고', '전자레인지', '컴퓨터', '선풍기', '선풍기', '믹서', '믹서']\n",
    "\n",
    "# 먼저 숫자 값으로 변환을 위해 LabelEncoder로 변환한다.\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(items)\n",
    "labels = encoder.transform(items)\n",
    "# 2차원 데이터로 변환\n",
    "labels = labels.reshape(-1, 1)\n",
    "\n",
    "# 원핫 인코딩 적용\n",
    "oh_encoder = OneHotEncoder()\n",
    "oh_encoder.fit(labels)\n",
    "oh_labels = oh_encoder.transform(labels)\n",
    "\n",
    "print('원 핫 인코딩 데이터')\n",
    "print(oh_labels.toarray()) # return an ndarray\n",
    "print('\\n원 핫 인코딩 데이터 차원')\n",
    "print(oh_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- get_dummies() : 원-핫 인코딩을 더 쉽게 지원하는 API. 문자열 카테고리 값을 숫자 형으로 변환할 필요 없이 바로 변환할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_TV</th>\n",
       "      <th>item_냉장고</th>\n",
       "      <th>item_믹서</th>\n",
       "      <th>item_선풍기</th>\n",
       "      <th>item_전자레인지</th>\n",
       "      <th>item_컴퓨터</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   item_TV  item_냉장고  item_믹서  item_선풍기  item_전자레인지  item_컴퓨터\n",
       "0        0         0        0         0           1         0\n",
       "1        0         0        0         0           0         1\n",
       "2        0         0        1         0           0         0\n",
       "3        1         0        0         0           0         0\n",
       "4        0         1        0         0           0         0\n",
       "5        0         1        0         0           0         0\n",
       "6        0         0        0         1           0         0\n",
       "7        0         0        0         1           0         0"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'item':['전자레인지', '컴퓨터', '믹서', 'TV', '냉장고', '냉장고', '선풍기', '선풍기']})\n",
    "pd.get_dummies(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 피처 스케일링과 정규화\n",
    "피처 스케일링 : 서로 다른 변수의 값 범위를 일정한 수준으로 맞추는 작업. 대표적인 방법으로는 표준화와 정규화가 있다.\n",
    "- 표준화 : 데이터의 피처 각각이 평균이 0이고 분산이 1인 가우시안 정규 분포를 가진 값으로 변환하는 것\n",
    "    - 원래 값에서 피처 x의 평균을 뺀 값을 피처 x의 표준편차로 나눈 값으로 계산\n",
    "- 정규화 : 서로 다른 피처의 크기를 통일하기 위해 크기를 변환해주는 개념. 변수를 모두 동일한 크기 단위로 비교하기 위해 값을 모두 최소 0 ~ 최대 1의 값으로 변환하는 것이다. 즉, 개별 데이터의 크기를 모두 똑같은 단위로 변경하는 것\n",
    "    - 원래 값에서 피처 x의 최솟값을 뺸 값을 피처 x의 최댓값과 최솟값의 차이로 나눈값으로 변환"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 사이킷런 Nomalizer 모듈 : 선형대수에서의 정규화 개념이 적용됐으며, 개별 벡터의 크기를 맞추기 위해 변환하는 것. 즉, 개별 벡터를 모든 피처 벡터의 크기로 나눠준다.\n",
    "    - 일반적인 정규화와는 차이가 있다.\n",
    "    - 새로운 데이터는 원래 값에서 세개의 피처의 i번째 피처 값에 해당하는 크기를 합한 값으로 나눠준다.\n",
    "- 혼선을 방지하기 위해 일반적인 의미의 표준화와 정규화를 피처 스케일링으로 통칭하고 선형대수 개념의 정규화를 벡터 정규화라 지칭한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### StandardScaler\n",
    ": 표준화를 쉽게 지원하기 위한 클래스이다. 즉, 개별 피처를 평균이 0이고, 분산이 1인 값으로 반환해준다.\n",
    "- 이렇게 가우시안 정규 분포를 가질 수 있도록 데이터를 변환하는 것은 몇몇 알고리즘에서 매우 중요하다.\n",
    "- 특히 사이킷런에서 구현한 RBF 커널을 이용하는 서포트벡터머신이나 선형회귀, 로지스틱 회귀는 데이터가 가우시안 분포를 가지고 있다고 가정하고 구현됐기 때문에 사전에 표준화를 적용하는 것은 예측 성능 향상에 중요한 요소가 될 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature 들의 평균값\n",
      " sepal length (cm)    5.843333\n",
      "sepal width (cm)     3.057333\n",
      "petal length (cm)    3.758000\n",
      "petal width (cm)     1.199333\n",
      "dtype: float64\n",
      "\n",
      "feature 들의 분산 값\n",
      " sepal length (cm)    0.685694\n",
      "sepal width (cm)     0.189979\n",
      "petal length (cm)    3.116278\n",
      "petal width (cm)     0.581006\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "import pandas as pd\n",
    "# 붓꽃 데이터 세트를 로딩하고 데이터프레임으로 변환\n",
    "iris = load_iris()\n",
    "iris_data = iris.data\n",
    "iris_df = pd.DataFrame(data=iris_data, columns=iris.feature_names)\n",
    "\n",
    "print('feature 들의 평균값\\n', iris_df.mean())\n",
    "print('\\nfeature 들의 분산 값\\n', iris_df.var())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature 들의 평균값\n",
      " sepal length (cm)   -1.690315e-15\n",
      "sepal width (cm)    -1.842970e-15\n",
      "petal length (cm)   -1.698641e-15\n",
      "petal width (cm)    -1.409243e-15\n",
      "dtype: float64\n",
      "\n",
      "feature 들의 분산 값\n",
      " sepal length (cm)    1.006711\n",
      "sepal width (cm)     1.006711\n",
      "petal length (cm)    1.006711\n",
      "petal width (cm)     1.006711\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# standardScaler 객체 생성\n",
    "scaler = StandardScaler()\n",
    "# StandardScaler로 데이터 세트 변환. fit과 transform 호출\n",
    "scaler.fit(iris_df)\n",
    "iris_scaled = scaler.transform(iris_df)\n",
    "\n",
    "# transform()시 스케일 변환된 데이터 세트가 numpy ndarray로 반환돼 이를 데이터프레임으로 변환\n",
    "iris_df_scaled = pd.DataFrame(data=iris_scaled, columns=iris.feature_names)\n",
    "print('feature 들의 평균값\\n', iris_df_scaled.mean())\n",
    "print('\\nfeature 들의 분산 값\\n', iris_df_scaled.var())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MinMaxScaler\n",
    ": 데이터값을 0과 1사이의 범위 값으로 변환한다.(음수값이 있으면 -1에서 1값으로 변환한다). 데이터의 분포가 가우시안 분포가 아닐 경우에 min, max scale을 적용해볼 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature 들의 최솟값\n",
      " sepal length (cm)    0.0\n",
      "sepal width (cm)     0.0\n",
      "petal length (cm)    0.0\n",
      "petal width (cm)     0.0\n",
      "dtype: float64\n",
      "\n",
      "feature 들의 최댓값\n",
      " sepal length (cm)    1.0\n",
      "sepal width (cm)     1.0\n",
      "petal length (cm)    1.0\n",
      "petal width (cm)     1.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# MinMaxScaler 객체 생성\n",
    "scaler = MinMaxScaler()\n",
    "# MinMaxScaler로 데이터 세트 변환. fit과 transform 호출\n",
    "scaler.fit(iris_df)\n",
    "iris_scaled = scaler.transform(iris_df)\n",
    "\n",
    "# transform()시 스케일 변환된 데이터 세트가 numpy ndarray로 반환돼 이를 데이터프레임으로 변환\n",
    "iris_df_scaled = pd.DataFrame(data=iris_scaled, columns=iris.feature_names)\n",
    "print('feature 들의 최솟값\\n', iris_df_scaled.min())\n",
    "print('\\nfeature 들의 최댓값\\n', iris_df_scaled.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 학습 데이터와 테스트 데이터의 스케일링 변환시 유의점\n",
    "- fit( )은 데이터 변환을 위한 기준 정보 설정을 적용\n",
    "- transform( )은 이렇게 설정된 정보를 이용해 데이터를 변환\n",
    "- fit과 transform을 적용할때 주의점\n",
    "    - 학습 데이터로 fit이 적용된 스케일링 기준 정보를 그대로 테스트 데이터에 적용해야한다.\n",
    "    - 그렇지 않고 테스트 데이터로 다시 새로운 스케일링 기준 정보를 만들게 되면 학습데이터와 테스트 데이터의 스케일링 기준 정보가 서로 달라지기 때문에 올바른 예측 결과를 도출하지 못할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트 데이터에 fit을 적용할 때 문제 일어나는지 알아보기\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "\n",
    "# 학습 데이터는 0부터 10까지, 테스트 데이터는 0부터 5까지 값을 가지는 데이터 세트로 생성\n",
    "# scaler클래스의 fit, transform은 2차원 이상 데이터만 가능하므로 reshape로 차원 변경\n",
    "train_array = np.arange(0, 11).reshape(-1, 1)\n",
    "test_array = np.arange(0, 6). reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원본 train_array 데이터: [ 0  1  2  3  4  5  6  7  8  9 10]\n",
      "scale된 train_array 데이터: [0.  0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1. ]\n"
     ]
    }
   ],
   "source": [
    "# MinMaxScaler 객체에 별도의 feature_range 파라미터 값을 지정하지 않으면 0 ~ 1값으로 변환\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# fit()하게 되면 train_array 데이터 최솟값이 0, 최댓값이 10으로 설정\n",
    "scaler.fit(train_array)\n",
    "\n",
    "# 1/10 scale로 train_array 데이터 변환함. 원본 10 -> 1로 변환됨\n",
    "train_scaled = scaler.transform(train_array)\n",
    "\n",
    "print('원본 train_array 데이터:', np.round(train_array.reshape(-1),2))\n",
    "print('scale된 train_array 데이터:', np.round(train_scaled.reshape(-1),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원본 test_array 데이터: [0 1 2 3 4 5]\n",
      "scale된 test_array 데이터: [0.  0.2 0.4 0.6 0.8 1. ]\n"
     ]
    }
   ],
   "source": [
    "# MinMaxScaler에 test_array를 fit하게 되면 원본 데이터의 최솟값이 0, 최댓값이 5로 설정됨\n",
    "scaler.fit(test_array)\n",
    "\n",
    "# 1/5 scale로 test_array 데이터 변환함. 원본 5 -> 1로 변환됨\n",
    "test_scaled = scaler.transform(test_array)\n",
    "\n",
    "print('원본 test_array 데이터:', np.round(test_array.reshape(-1),2))\n",
    "print('scale된 test_array 데이터:', np.round(test_scaled.reshape(-1),2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "학습 데이터와 테스트 데이터의 서로 다른 원본값이 동일한 값으로 변환되는 결과를 초래한다.\n",
    "- 머신러닝 모델은 학습 데이터를 기반으로 학습되기 떄문에 반드시 테스트 데이터는 학습 데이터의 스케일링 기준에 따라야 한다. \n",
    "\n",
    "따라서 테스트 데이터에 다시 fit을 적용해서는 안되며 학습 데이터로 이미 fit이 적용된 scaler객체를 이용해 transform으로 변환해야한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원본 train_array 데이터: [ 0  1  2  3  4  5  6  7  8  9 10]\n",
      "scale된 train_array 데이터: [0.  0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1. ]\n",
      "원본 test_array 데이터: [0 1 2 3 4 5]\n",
      "scale된 test_array 데이터: [0.  0.1 0.2 0.3 0.4 0.5]\n"
     ]
    }
   ],
   "source": [
    "scaler = MinMaxScaler()\n",
    "scaler.fit(train_array)\n",
    "train_scaled = scaler.transform(train_array)\n",
    "print('원본 train_array 데이터:', np.round(train_array.reshape(-1),2))\n",
    "print('scale된 train_array 데이터:', np.round(train_scaled.reshape(-1),2))\n",
    "\n",
    "# test_array에 Scale 변환을 할 떄는 반드시 fit을 호출하지 않고 transform만으로 변환해야 함\n",
    "test_scaled = scaler.transform(test_array)\n",
    "print('원본 test_array 데이터:', np.round(test_array.reshape(-1),2))\n",
    "print('scale된 test_array 데이터:', np.round(test_scaled.reshape(-1),2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- fit_transform( )을 적용할때도 마찬가지. fit_transform()은 fit과 transform을 순차적으로 수행하는 메소드이므로 학습데이터에서는 상관없지만 !!!! 테스트 데이터에서는 절대 사용해서는 안된다. !!!!\n",
    "- 학습과 테스트 데이터 세트로 분리하기 전에 먼저 전체 데이터 세트에 스케일링을 적용한 뒤 학습과 테스트 데이터 세트로 분리하는 것이 더 바람직하다.\n",
    "    - 이게 여의치 않다면 테스트 변환시에는 fit이나 fit_transform을 적용하지 않고 학습데이터로 이미 fit이 된 scaler객체를 이용해 transform으로 변환\n",
    "- 이 유의 사항은 사이킷런 기반의 PCA 같은 차원축소변환이나 텍스트의 피처 벡터화 변환 작업시에도 동일하게 적용된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 06. 사이킷런으로 수행하는 타이타닉 생존자 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# 브라우저 내부(inline)에 바로 그려지도록 하는 코드\n",
    "%matplotlib inline \n",
    "\n",
    "titanic_df = pd.read_csv('/Users/wizdom/Desktop/data_analysis/Kaggle_titanic/titanic/train.csv')\n",
    "titanic_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- info( ) 메서드 : 로딩된 데이터 칼럼 타입 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ###학습 데이터 정보### \n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int64  \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Name         891 non-null    object \n",
      " 4   Sex          891 non-null    object \n",
      " 5   Age          714 non-null    float64\n",
      " 6   SibSp        891 non-null    int64  \n",
      " 7   Parch        891 non-null    int64  \n",
      " 8   Ticket       891 non-null    object \n",
      " 9   Fare         891 non-null    float64\n",
      " 10  Cabin        204 non-null    object \n",
      " 11  Embarked     889 non-null    object \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.7+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print('\\n ###학습 데이터 정보### \\n')\n",
    "print(titanic_df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RangeIndex를 통해 전체 로우 수를 알 수 있다. 891로우와 12개의 칼럼으로 구성되어 있음을 알 수 있다\n",
    "- object 타입은 string 타입으로 봐도 무방하다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- fillna( ) : 간단하게 Null 값을 다른 값으로 변경해준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터 세트 null 값 개수 : 0\n"
     ]
    }
   ],
   "source": [
    "# Age 열은 평균 나이, Cabin, Embarked는 'N'으로 채워준다.\n",
    "\n",
    "titanic_df['Age'].fillna(titanic_df['Age'].mean(), inplace=True)\n",
    "titanic_df['Cabin'].fillna('N', inplace=True)\n",
    "titanic_df['Embarked'].fillna('N', inplace=True)\n",
    "print('데이터 세트 null 값 개수 :', titanic_df.isnull().sum().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sex 값 분포 :\n",
      " male      577\n",
      "female    314\n",
      "Name: Sex, dtype: int64\n",
      "\n",
      " Cabin 값 분포 :\n",
      " N              687\n",
      "C23 C25 C27      4\n",
      "B96 B98          4\n",
      "G6               4\n",
      "E101             3\n",
      "              ... \n",
      "C90              1\n",
      "A6               1\n",
      "B38              1\n",
      "E68              1\n",
      "D28              1\n",
      "Name: Cabin, Length: 148, dtype: int64\n",
      "\n",
      " Embarked 값 분포 :\n",
      " S    644\n",
      "C    168\n",
      "Q     77\n",
      "N      2\n",
      "Name: Embarked, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 각 문자열 칼럼들의 값의 건수와 유형 확인\n",
    "\n",
    "print('Sex 값 분포 :\\n', titanic_df['Sex'].value_counts())\n",
    "print('\\n Cabin 값 분포 :\\n', titanic_df['Cabin'].value_counts())\n",
    "print('\\n Embarked 값 분포 :\\n', titanic_df['Embarked'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    N\n",
      "1    C\n",
      "2    N\n",
      "Name: Cabin, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Cabin의 선실 등급을 나타내는 첫번째 알파벳 추출\n",
    "\n",
    "titanic_df['Cabin'] = titanic_df['Cabin'].str[:1]\n",
    "print(titanic_df['Cabin'].head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sex     Survived\n",
       "female  0            81\n",
       "        1           233\n",
       "male    0           468\n",
       "        1           109\n",
       "Name: Survived, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 성별에 따른 생존자 수 비교\n",
    "\n",
    "titanic_df.groupby(['Sex', 'Survived'])['Survived'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "여자 : 74.2% 생존, 남자 : 18.8% 생존. 따라서 여자가 더 생존률이 높다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- seaborn 패키지를 이용하여 시각화하기\n",
    "- barplot() : 가로 막대 차트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='Sex', ylabel='Survived'>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.barplot(x='Sex', y='Survived', data=titanic_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='Pclass', ylabel='Survived'>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 객실 등급별 성별에 따른 생존확률\n",
    "\n",
    "sns.barplot(x='Pclass', y='Survived', hue='Sex', data=titanic_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Age에 따른 생존확률\n",
    "\n",
    "# 입력 age에 따라 구분 값을 반환하는 함수 설정\n",
    "def get_category(age):\n",
    "    cat = ''\n",
    "    if age <= -1: cat = 'Unknown'\n",
    "    elif age <= 5: cat = 'Baby'\n",
    "    elif age <= 12: cat = 'Child'\n",
    "    elif age <= 18: cat = 'Teenager'\n",
    "    elif age <= 25: cat = 'Student'\n",
    "    elif age <= 35: cat = 'Young Adult'\n",
    "    elif age <= 60: cat = 'Adult'\n",
    "    else : cat = 'Elderly'\n",
    "    \n",
    "    return cat\n",
    "\n",
    "# 막대그래프의 크기 figure를 더 크게 설정\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# X축의 값을 순차적으로 표시하기 위한 설정\n",
    "# 안하면 제멋대로 순서 나옴\n",
    "group_names = ['Unknown', 'Baby', 'Child', 'Teenager', 'Student', 'Young Adult', 'Adult', 'Elderly']\n",
    "\n",
    "# lambda 식에 위에서 생성한 get_category()함수를 반환값으로 지정.\n",
    "# get_category(x)는 입력값으로 'Age'칼럼 값을 받아서 해당하는 cat 반환\n",
    "titanic_df['Age_cat'] = titanic_df['Age'].apply(lambda x : get_category(x))\n",
    "sns.barplot(x='Age_cat', y='Survived', hue='Sex', data=titanic_df, order=group_names)\n",
    "titanic_df.drop('Age_cat', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "baby와 여성 elderly의 경우는 생존 확률이 높은 것을 알 수 있다. 하지만 여자 child 경우는 다른 연령대에 비해 생존확률이 낮다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>1</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name  Sex   Age  SibSp  Parch  \\\n",
       "0                            Braund, Mr. Owen Harris    1  22.0      1      0   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...    0  38.0      1      0   \n",
       "2                             Heikkinen, Miss. Laina    0  26.0      0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)    0  35.0      1      0   \n",
       "4                           Allen, Mr. William Henry    1  35.0      0      0   \n",
       "\n",
       "             Ticket     Fare  Cabin  Embarked  \n",
       "0         A/5 21171   7.2500      7         3  \n",
       "1          PC 17599  71.2833      2         0  \n",
       "2  STON/O2. 3101282   7.9250      7         3  \n",
       "3            113803  53.1000      2         3  \n",
       "4            373450   8.0500      7         3  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 레이블 인코딩 적용하기(문자열값 -> 숫자형 카테고리)\n",
    "from sklearn import preprocessing\n",
    "\n",
    "def encode_features(dataDF):\n",
    "    features = ['Cabin', 'Sex', 'Embarked']\n",
    "    for feature in features :\n",
    "        le = preprocessing.LabelEncoder()\n",
    "        le = le.fit(dataDF[feature])\n",
    "        dataDF[feature] = le.transform(dataDF[feature])\n",
    "    \n",
    "    return dataDF\n",
    "    \n",
    "titanic_df = encode_features(titanic_df)\n",
    "titanic_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 지금까지 피처를 가공한 내역 정리 및 이를 함수로 만들어 쉽게 재사용하도록 만들자\n",
    "\n",
    "# Null 처리 함수\n",
    "def fillna(df):\n",
    "    df['Age'].fillna(df['Age'].mean(), inplace=True)\n",
    "    df['Cabin'].fillna('N', inplace=True)\n",
    "    df['Embarked'].fillna('N', inplace=True)\n",
    "    df['Fare'].fillna(0, inplace=True)\n",
    "    return df\n",
    "\n",
    "# 머신러닝 알고리즘에 불필요한 속성 제거\n",
    "def drop_features(df):\n",
    "    df.drop(['PassengerId', 'Name', 'Ticket'], axis=1, inplace=True)\n",
    "    return df\n",
    "\n",
    "# 레이블 인코딩 수행\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "def format_features(df):\n",
    "    df['Cabin'] = df['Cabin'].str[:1] # 방 첫번째 알파벳 추출\n",
    "    features = ['Cabin', 'Sex', 'Embarked']\n",
    "    for feature in features :\n",
    "        le = LabelEncoder()\n",
    "        le = le.fit(df[feature])\n",
    "        df[feature] = le.transform(df[feature])\n",
    "    return df\n",
    "\n",
    "# 앞에서 설정한 데이터 전처리 함수 호출\n",
    "def transform_features(df):\n",
    "    df = fillna(df)\n",
    "    df = drop_features(df)\n",
    "    df = format_features(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Survived 속성만 별도 분리해 클래스 결정값 데이터 세트로 만들고, \n",
    "# Survived 속성을 드롭해 피처 데이터 세트 만든다.\n",
    "titanic_df = pd.read_csv('/Users/wizdom/Desktop/data_analysis/Kaggle_titanic/titanic/train.csv')\n",
    "y_titanic_df = titanic_df['Survived']\n",
    "X_titanic_df = titanic_df.drop('Survived', axis=1)\n",
    "\n",
    "X_titanic_df = transform_features(X_titanic_df) # 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_test_split()을 이용해 별도의 테스트 데이터 세트 추출\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_titanic_df, y_titanic_df, test_size=0.2, random_state=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "결정트리 정확도: 0.7877\n",
      "랜덤포레스트 정확도: 0.8547\n",
      "로지스틱회귀 정확도: 0.8492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# ML 알고리즘을 이용해 타이타닉 생존자 예측해보기\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier # 결정트리\n",
    "from sklearn.ensemble import RandomForestClassifier # 랜덤포레스트\n",
    "from sklearn.linear_model import LogisticRegression # 로지스틱회귀\n",
    "from sklearn.metrics import accuracy_score # 예측 성능 평가는 정확도로 ㅎㅏ자\n",
    "\n",
    "# 위의 ML 알고리즘을 위한 사이킷런 Classifier 클래스 생성\n",
    "dt_clf = DecisionTreeClassifier(random_state=11)\n",
    "rf_clf = RandomForestClassifier(random_state=11)\n",
    "lr_clf = LogisticRegression()\n",
    "\n",
    "# 결정트리 학습/예측/평가\n",
    "dt_clf.fit(X_train, y_train)\n",
    "dt_pred = dt_clf.predict(X_test)\n",
    "print('결정트리 정확도: {0:.4f}'.format(accuracy_score(y_test, dt_pred)))\n",
    "\n",
    "# 랜덤포레스트 학습/예측/평가\n",
    "rf_clf.fit(X_train, y_train)\n",
    "rf_pred = rf_clf.predict(X_test)\n",
    "print('랜덤포레스트 정확도: {0:.4f}'.format(accuracy_score(y_test, rf_pred)))\n",
    "\n",
    "# 로지스틱회귀 학습/예측/평가\n",
    "lr_clf.fit(X_train, y_train)\n",
    "lr_pred = lr_clf.predict(X_test)\n",
    "print('로지스틱회귀 정확도: {0:.4f}'.format(accuracy_score(y_test, lr_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "최적화 작업 수행하지 않았고, 데이터 양도 충분하지 않기 떄문에 어떤 알고리즘이 가장 성능이 좋다고 평가할 수 없다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "교차 검증으로 결정 트리 모델 평가하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "교차 검증 0 정확도: 0.7542\n",
      "교차 검증 1 정확도: 0.7809\n",
      "교차 검증 2 정확도: 0.7865\n",
      "교차 검증 3 정확도: 0.7697\n",
      "교차 검증 4 정확도: 0.8202\n",
      "평균 정확도: 0.7823\n"
     ]
    }
   ],
   "source": [
    "# KFold 클래스를 이용한 교차검증\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "def exec_kfold(clf, folds=5):\n",
    "    # 폴드 세트를 5개인 KFold객체 생성, 폴드 수만큼 예측 결과 저장을 위한 리스틑 객체 생성\n",
    "    kfold = KFold(n_splits=folds)\n",
    "    scores = []\n",
    "    \n",
    "    # KFold 교차 검증 수행.\n",
    "    for iter_count, (train_index, test_index) in enumerate(kfold.split(X_titanic_df)):\n",
    "        # X_titanic_df 데이터에서 교차 검증별로 학습과 검증 데이터 가리키는 index 생성\n",
    "        X_train, X_test = X_titanic_df.values[train_index], X_titanic_df.values[test_index]\n",
    "        y_train, y_test = y_titanic_df.values[train_index], y_titanic_df.values[test_index]\n",
    "        # Classifier 학습/예측/정확도 계산\n",
    "        clf.fit(X_train, y_train)\n",
    "        predictions = clf.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, predictions)\n",
    "        scores.append(accuracy)\n",
    "        print('교차 검증 {0} 정확도: {1:.4f}'.format(iter_count, accuracy))\n",
    "        \n",
    "    # 5개 fold에서의 평균 정확도 계산\n",
    "    mean_score = np.mean(scores)\n",
    "    print('평균 정확도: {0:.4f}'.format(mean_score))\n",
    "\n",
    "# 호출\n",
    "exec_kfold(dt_clf, folds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "교차 검증 0 정확도: 0.7430\n",
      "교차 검증 1 정확도: 0.7753\n",
      "교차 검증 2 정확도: 0.7921\n",
      "교차 검증 3 정확도: 0.7865\n",
      "교차 검증 4 정확도: 0.8427\n",
      "평균 정확도: 0.7879\n"
     ]
    }
   ],
   "source": [
    "# cross_val_score( )를 이용해 교차검증하기(StratifiedKFold)\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(dt_clf, X_titanic_df, y_titanic_df, cv=5)\n",
    "for iter_count, accuracy in enumerate(scores):\n",
    "    print('교차 검증 {0} 정확도: {1:.4f}'.format(iter_count, accuracy))\n",
    "    \n",
    "print('평균 정확도: {0:.4f}'.format(np.mean(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV 최적 하이퍼 파라미터:  {'max_depth': 3, 'min_samples_leaf': 5, 'min_samples_split': 2}\n",
      "GridSearchCV 최고 정확도: 0.7992\n",
      "테스트 세트에서의 결정나무 정확도: 0.8715\n"
     ]
    }
   ],
   "source": [
    "# GridSearchCV를 이용해 결정나무 최적 하이퍼 파라미터를 찾고 예측 성능 측정하기\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "parameters = {'max_depth':[2, 3, 5, 10],\n",
    "             'min_samples_split':[2, 3, 5], \n",
    "             'min_samples_leaf':[1, 5, 8]}\n",
    "\n",
    "grid_dclf = GridSearchCV(dt_clf, param_grid=parameters, scoring='accuracy', cv=5)\n",
    "grid_dclf.fit(X_train, y_train)\n",
    "\n",
    "print('GridSearchCV 최적 하이퍼 파라미터: ', grid_dclf.best_params_)\n",
    "print('GridSearchCV 최고 정확도: {0:.4f}'.format(grid_dclf.best_score_))\n",
    "best_dclf = grid_dclf.best_estimator_\n",
    "\n",
    "# GridSearchCV의 최적 하이퍼 파라미터로 학습된 Estimator로 예측 및 평가 수행\n",
    "dpredictions = best_dclf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, dpredictions)\n",
    "print('테스트 세트에서의 결정나무 정확도: {0:.4f}'.format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "약 8% 이상이 증가했는데, 일반적으로 하이퍼 파라미터를 튜닝하더라도 이정도 수준으로 증가하기는 매우 어렵다. 테스트용 데이터 세트가 작기 때문에 수치상으로 예측 성능이 많이 증가한것처럼 보임."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 어떤 하이퍼파라미터 값을 지정해야 할지 모를때는 연속된 10의 거듭제곱 수로 시도해보는것이 좋다. 세밀하게 하려면 더 작은값 지정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9859550561797753"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_forest = RandomForestClassifier(n_estimators = 100) # 나무의수=100\n",
    "\n",
    "random_forest.fit(X_train, y_train)\n",
    "\n",
    "y_pred = random_forest.predict(X_test)\n",
    "\n",
    "random_forest.score(X_train, y_train)\n",
    "# 훈련 정확도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8268156424581006"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_forest.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8268156424581006"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred)\n",
    "# 테스트 정확도"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "score source를 보면 안에 from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy_score(y, self.predict(X), sample_wieght=sample_weight) 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
